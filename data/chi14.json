[
    {
        "title": "Metaphone: machine aesthetics meets interaction design",
        "authors": "Vygandas Šimbelis, Anders Lundström, Kristina Höök, Jordi Solsona, Vincent Lewandowski",
        "abstract": "Through our art project, Metaphone, we explored a particular form of aesthetics referred to in the arts tradition as machine aesthetics. The Metaphone machine collects the participant's bio-data, Galvanic Skin Response (GSR) and Heart Rate (HR), creating a process of movement, painting and sound. The machine behaves in machine-like, aesthetically evocative ways: a shaft on two large wheels rotates on the floor, carrying paint that is dripped onto a large sheet of aquarelle paper on the floor according to bio-sensor data. A soundscape rhythmically follows the bio-sensor data, but also has its own machine-like sounds. Six commentators were invited to interact with the machine. They reported a strangely relaxing atmosphere induced by the machine. Based on these experiences we discuss how different art styles can help to describe aesthetics in interaction design generally, and how machine aesthetics in particular can be used to create interesting, sustained, stylistically coherent interactions.",
        "session": "SESSION: Visualization and aesthetics"
    },
    {
        "title": "Quantifying visual preferences around the world",
        "authors": "Katharina Reinecke, Krzysztof Z. Gajos",
        "abstract": "Website aesthetics have been recognized as an influential moderator of people's behavior and perception. However, what users perceive as \"good design\" is subject to individual preferences, questioning the feasibility of universal design guidelines. To better understand how people's visual preferences differ, we collected 2.4 million ratings of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds. We address several gaps in the knowledge about design preferences of previously understudied groups. Among other findings, our results show that the level of colorfulness and visual complexity at which visual appeal is highest strongly varies: Females, for example, liked colorful websites more than males. A high education level generally lowers this preference for colorfulness. Russians preferred a lower visual complexity, and Macedonians liked highly colorful designs more than any other country in our dataset. We contribute a computational model and estimates of peak appeal that can be used to support rapid evaluations of website design prototypes for specific target groups.",
        "session": "SESSION: Visualization and aesthetics"
    },
    {
        "title": "The influence of aesthetics in usability testing: the case of dual-domain products",
        "authors": "Andreas Sonderegger, Andreas Uebelbacher, Manuela Pugliese, Juergen Sauer",
        "abstract": "An experimental study examined whether the effects of aesthetic appeal on usability test outcomes are moderated by usage domain. The aesthetic appeal of a cell phone was experimentally manipulated in both home- and work-based usage domains. The two usage domains were modeled in a usability laboratory. 60 participants completed a series of typical cell phone user tasks. Dependent measures such as performance, perceived usability, and emotion were taken. The results showed that aesthetic appeal had a positive effect on perceived usability but a negative effect on performance. The effects of aesthetic appeal on usability test outcomes were not moderated by usage domain. The results of this study imply that it may be sufficient to test dual-domain products in only one of their usage domains.",
        "session": "SESSION: Visualization and aesthetics"
    },
    {
        "title": "Extracting references between text and charts via crowdsourcing",
        "authors": "Nicholas Kong, Marti A. Hearst, Maneesh Agrawala",
        "abstract": "News articles, reports, blog posts and academic papers often include graphical charts that serve to visually reinforce arguments presented in the text. To help readers better understand the relation between the text and the chart, we present a crowdsourcing pipeline to extract the references between them. Specifically, we give crowd workers paragraph-chart pairs and ask them to select text phrases as well as the corresponding visual marks in the chart. We then apply automated clustering and merging techniques to unify the references generated by multiple workers into a single set. Comparing the crowdsourced references to a set of gold standard references using a distance measure based on the F1 score, we find that the average distance between the raw set of references produced by a single worker and the gold standard is 0.54 (out of a max of 1.0). When we apply clustering and merging techniques the average distance between the unified set of references and the gold standard reduces to 0.39; an improvement of 27%. We conclude with an interactive document viewing application that uses the extracted references; readers can select phrases in the text and the system highlights the related marks in the chart.",
        "session": "SESSION: Visualization and aesthetics"
    },
    {
        "title": "Stress and multitasking in everyday college life: an empirical study of online activity",
        "authors": "Gloria Mark, Yiran Wang, Melissa Niiya",
        "abstract": "While HCI has focused on multitasking with information workers, we report on multitasking among Millennials who grew up with digital media - focusing on college students. We logged computer activity and used biosensors to measure stress of 48 students for 7 days for all waking hours, in their in situ environments. We found a significant positive relationship with stress and daily time spent on computers. Stress is positively associated with the amount of multitasking. Conversely, stress is negatively associated with Facebook and social media use. Heavy multitaskers use significantly more social media and report lower positive affect than light multitaskers. Night habits affect multitasking the following day: late-nighters show longer duration of computer use and those ending their activities earlier in the day multitask less. Our study shows that college students multitask at double the frequency compared to studies of information workers. These results can inform designs for stress management of college students.",
        "session": "SESSION: Stress"
    },
    {
        "title": "Under pressure: sensing stress of computer users",
        "authors": "Javier Hernandez, Pablo Paredes, Asta Roseway, Mary Czerwinski",
        "abstract": "Recognizing when computer users are stressed can help reduce their frustration and prevent a large variety of negative health conditions associated with chronic stress. However, measuring stress non-invasively and continuously at work remains an open challenge. This work explores the possibility of using a pressure-sensitive keyboard and a capacitive mouse to discriminate between stressful and relaxed conditions in a laboratory study. During a 30 minute session, 24 participants performed several computerized tasks consisting of expressive writing, text transcription, and mouse clicking. During the stressful conditions, the large majority of the participants showed significantly increased typing pressure (>79% of the participants) and more contact with the surface of the mouse (75% of the participants). We discuss the potential implications of this work and provide recommendations for future work.",
        "session": "SESSION: Stress"
    },
    {
        "title": "MouStress: detecting stress from mouse motion",
        "authors": "David Sun, Pablo Paredes, John Canny",
        "abstract": "Stress causes and exacerbates many physiological and mental health problems. Routine and unobtrusive monitoring of stress would enable a variety of treatments, from break-taking to calming exercises. It may also be a valuable tool for assessing effects (frustration, difficulty) of using interfaces or applications. Custom sensing hardware is a poor option, because of the need to buy/wear/use it continuously, even before stress-related problems are evident. Here we explore stress measurement from common computer mouse operations. We use a simple model of arm-hand dynamics that captures muscle stiffness during mouse movement. We show that the within-subject mouse-derived stress measure is quite strong, even compared to concurrent physiological sensor measurements. While our study used fixed mouse tasks, the stress signal was still strong even when averaged across widely varying task geometries. We argue that mouse sensing \"in the wild\" may be feasible, by analyzing frequently-performed operations of particular geometries.",
        "session": "SESSION: Stress"
    },
    {
        "title": "Investigating the effects of using biofeedback as visual stress indicator during video-mediated collaboration",
        "authors": "Chiew Seng Sean Tan, Johannes Schöning, Kris Luyten, Karin Coninx",
        "abstract": "During remote video-mediated assistance, instructors often guide workers through problems and instruct them to perform unfamiliar or complex operations. However, the workers' performance might deteriorate due to stress. We argue that informing biofeedback to the instructor, can improve communication and lead to lower stress. This paper presents a thorough investigation on mental workload and stress perceived by twenty participants, paired up in an instructor-worker scenario, performing remote video-mediated tasks. The interface conditions differ in task, facial and biofeedback communication. Two self-report measures are used to assess mental workload and stress. Results show that pairs reported lower mental workload and stress when instructors are using the biofeedback as compared to using interfaces with facial view. Significant correlations were found on task performance with reducing stress (i.e. increased task engagement and decreased worry) for instructors and declining mental workload (i.e. increased performance) for workers. Our findings provide insights to advance video-mediated interfaces for remote collaborative work.",
        "session": "SESSION: Stress"
    },
    {
        "title": "Let's do it at my place instead?: attitudinal and behavioral study of privacy in client-side personalization",
        "authors": "Alfred Kobsa, Bart P. Knijnenburg, Benjamin Livshits",
        "abstract": "Many users welcome personalized services, but are reluctant to provide the information about themselves that personalization requires. Performing personalization exclusively at the client side (e.g., on one's smartphone) may conceptually increase privacy, because no data is sent to a remote provider. But does client-side personalization (CSP) also increase users' perception of privacy? We developed a causal model of privacy attitudes and behavior in personalization, and validated it in an experiment that contrasted CSP with personalization at three remote providers: Amazon, a fictitious company, and the \"Cloud\". Participants gave roughly the same amount of personal data and tracking permissions in all four conditions. A structural equation modeling analysis reveals the reasons: CSP raises the fewest privacy concerns, but does not lead in terms of perceived protection nor in resulting self-anticipated satisfaction and thus privacy-related behavior. Encouragingly, we found that adding certain security features to CSP is likely to raise its perceived protection significantly. Our model predicts that CSP will then also sharply improve on all other privacy measures.",
        "session": "SESSION: Social local mobile"
    },
    {
        "title": "The effect of developer-specified explanations for permission requests on smartphone user behavior",
        "authors": "Joshua Tan, Khanh Nguyen, Michael Theodorides, Heidi Negrón-Arroyo, Christopher Thompson, Serge Egelman, David Wagner",
        "abstract": "In Apple's iOS 6, when an app requires access to a protected resource (e.g., location or photos), the user is prompted with a permission request that she can allow or deny. These permission request dialogs include space for developers to optionally include strings of text to explain to the user why access to the resource is needed. We examine how app developers are using this mechanism and the effect that it has on user behavior. Through an online survey of 772 smartphone users, we show that permission requests that include explanations are significantly more likely to be approved. At the same time, our analysis of 4,400 iOS apps shows that the adoption rate of this feature by developers is relatively small: around 19% of permission requests include developer-specified explanations. Finally, we surveyed 30 iOS developers to better understand why they do or do not use this feature.",
        "session": "SESSION: Social local mobile"
    },
    {
        "title": "Reflection or action?: how feedback and control affect location sharing decisions",
        "authors": "Sameer Patil, Roman Schlegel, Apu Kapadia, Adam J. Lee",
        "abstract": "Owing to the ever-expanding size of social and professional networks, it is becoming cumbersome for individuals to configure information disclosure settings. We used location sharing systems to unpack the nature of discrepancies between a person's disclosure settings and contextual choices. We conducted an experience sampling study (N = 35) to examine various factors contributing to such divergence. We found that immediate feedback about disclosures without any ability to control the disclosures evoked feelings of oversharing. Moreover, deviation from specified settings did not always signal privacy violation; it was just as likely that settings prevented information disclosure considered permissible in situ. We suggest making feedback more actionable or delaying it sufficiently to avoid a knee-jerk reaction. Our findings also make the case for proactive techniques for detecting potential mismatches and recommending adjustments to disclosure settings, as well as selective control when sharing location with socially distant recipients and visiting atypical locations.",
        "session": "SESSION: Social local mobile"
    },
    {
        "title": "Effects of security warnings and instant gratification cues on attitudes toward mobile websites",
        "authors": "Bo Zhang, Mu Wu, Hyunjin Kang, Eun Go, S. Shyam Sundar",
        "abstract": "In order to address the increased privacy and security concerns raised by mobile communications, designers of mobile applications and websites have come up with a variety of warnings and appeals. While some interstitials warn about potential risk to personal information due to an untrusted security certificate, others attempt to take users' minds away from privacy concerns by making tempting, time-sensitive offers. How effective are they? We conducted an online experiment (N = 220) to find out. Our data show that both these strategies raise red flags for users - appeals to instant gratification make users more leery of the site and warnings make them perceive greater threat to personal data. Yet, users tend to reveal more information about their social media accounts when warned about an insecure site. This is probably because users process these interstitials based on cognitive heuristics triggered by them. These findings hold important implications for the design of cues in mobile interfaces.",
        "session": "SESSION: Social local mobile"
    },
    {
        "title": "Social media participation and performance at work: a longitudinal study",
        "authors": "N. Sadat Shami, Jeffrey Nichols, Jilin Chen",
        "abstract": "The use of social media at work is gaining traction, and there is evidence to suggest that various benefits accrue from its use. Yet the relationship between using social media at work and employee performance is not clear. Through a study of 75,747 employees of a large global company over the course of 3 years, we find that some social media usage (number of forum posts, forum post length, and status update length) was positively associated with performance ratings. This study is one of the first to show the relationship among different forms of social media use and employee performance ratings.",
        "session": "SESSION: Social local mobile"
    },
    {
        "title": "The doing of doing stuff: understanding the coordination of social group-activities",
        "authors": "Richard P. Schuler, Sukeshini A. Grandhi, Julia M. Mayer, Stephen T. Ricken, Quentin Jones",
        "abstract": "This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how group coordination is currently performed as well as the challenges people face. Our findings highlight that people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. Yet the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating individuals. This in turn often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.",
        "session": "SESSION: Coordination and collaboration"
    },
    {
        "title": "Effects of implicit sharing in collaborative analysis",
        "authors": "Nitesh Goyal, Gilly Leshed, Dan Cosley, Susan R. Fussell",
        "abstract": "When crime analysts collaborate to solve crime cases, they need to share insights in order to connect the clues, identify a pattern, and attribute the crime to the right culprit. We designed a collaborative analysis tool to explore the value of implicitly sharing insights and notes, without requiring analysts to explicitly push information or request it from each other. In an experiment, pairs of remote individuals played the role of crime analysts solving a set of serial killer crimes with both partners having some, but not all, relevant clues. When implicit sharing of notes was available, participants remembered more clues related to detecting the serial killer, and they perceived the tool as more useful compared to when implicit sharing was not available.",
        "session": "SESSION: Coordination and collaboration"
    },
    {
        "title": "Effects of simultaneous and sequential work structures on distributed collaborative interdependent tasks",
        "authors": "Paul André, Robert E. Kraut, Aniket Kittur",
        "abstract": "Distributed online groups have great potential for generating interdependent and complex products like encyclopedia articles or product design. However, coordinating multiple group members to work together effectively while minimizing process losses remains an open challenge. We conducted an experiment comparing the effectiveness of two coordination strategies (simultaneous vs. sequential work) on a complex creative task as the number of group members increased. Our results indicate that, contrary to prior work, a sequential work structure was more effective than a simultaneous work structure as the size of the group increased. A mediation analysis suggests that social processes such as territoriality partially accounts for these results. A follow up experiment giving workers specific roles mitigated the detrimental effects of the simultaneous work structure. These results have implications for small group theory and crowdsourcing research.",
        "session": "SESSION: Coordination and collaboration"
    },
    {
        "title": "Necessary, unpleasant, and disempowering: reputation management in the internet age",
        "authors": "Allison Woodruff",
        "abstract": "In this paper, we report on a qualitative study of how users manage their reputation online. We focus particularly on people who are bothered by content online about themselves and how they manage reputation damage and repair. We describe how users view reputation management chores as necessary but unpleasant, and how they feel disempowered to repair their online reputation. Participants were unable to identify feasible repair mechanisms and ultimately failed to resolve their problems. Given the current state of dysfunction indicated by our findings, we advocate for increased HCI research attention to this area.",
        "session": "SESSION: Coordination and collaboration"
    },
    {
        "title": "Duet: exploring joint interactions on a smart phone and a smart watch",
        "authors": "Xiang 'Anthony' Chen, Tovi Grossman, Daniel J. Wigdor, George Fitzmaurice",
        "abstract": "The emergence of smart devices (e.g., smart watches and smart eyewear) is redefining mobile interaction from the solo performance of a smart phone, to a symphony of multiple devices. In this paper, we present Duet -- an interactive system that explores a design space of interactions between a smart phone and a smart watch. Based on the devices' spatial configurations, Duet coordinates their motion and touch input, and extends their visual and tactile output to one another. This transforms the watch into an active element that enhances a wide range of phone-based interactive tasks, and enables a new class of multi-device gestures and sensing techniques. A technical evaluation shows the accuracy of these gestures and sensing techniques, and a subjective study on Duet provides insights, observations, and guidance for future work.",
        "session": "SESSION: Watches and small devices"
    },
    {
        "title": "Interaction on the edge: offset sensing for small devices",
        "authors": "Ian Oakley, Doyoung Lee",
        "abstract": "The touch screen interaction paradigm, currently dominant in mobile devices, begins to fail when very small systems are considered. Specifically, \"fat fingers\", a term referring to the fact that users' extremities physically obstruct their view of screen content and feedback, become particularly problematic. This paper presents a novel solution for this issue based on sensing touches to the perpendicular edges of a device featuring a front-mounted screen. The use of such offset contact points ensures that both a user's fingers and the device screen remain clearly in view throughout a targeting operation. The configuration also supports a range of novel interaction scenarios based on the touch, grip and grasp patterns it affords. To explore the viability of this concept, this paper describes EdgeTouch, a small (6 cm) hardware prototype instantiating this multi-touch functionality. User studies characterizing targeting performance, typical user grasps and exploring input affordances are presented. The results show that targets of 7.5-22.5 degrees in angular size are acquired in 1.25-1.75 seconds and with accuracy rates of 3%-18%, promising results considering the small form factor of the device. Furthermore, grasps made with between two and five fingers are robustly identifiable. Finally, we characterize the types of input users envisage performing with EdgeTouch, and report occurrence rates for key interactions such as taps, holds, strokes and multi-touch and compound input. The paper concludes with a discussion of the interaction scenarios enabled by offset sensing.",
        "session": "SESSION: Watches and small devices"
    },
    {
        "title": "More than touch: understanding how people use skin as an input surface for mobile computing",
        "authors": "Martin Weigel, Vikram Mehta, Jürgen Steimle",
        "abstract": "This paper contributes results from an empirical study of on-skin input, an emerging technique for controlling mobile devices. Skin is fundamentally different from off-body touch surfaces, opening up a new and largely unexplored interaction space. We investigate characteristics of the various skin-specific input modalities, analyze what kinds of gestures are performed on skin, and study what are preferred input locations. Our main findings show that (1) users intuitively leverage the properties of skin for a wide range of more expressive commands than on conventional touch surfaces; (2) established multi-touch gestures can be transferred to on-skin input; (3) physically uncomfortable modalities are deliberately used for irreversible commands and expressing negative emotions; and (4) the forearm and the hand are the most preferred locations on the upper limb for on-skin input. We detail on users' mental models and contribute a first consolidated set of on-skin gestures. Our findings provide guidance for developers of future sensors as well as for designers of future applications of on-skin input.",
        "session": "SESSION: Watches and small devices"
    },
    {
        "title": "TouchSense: expanding touchscreen input vocabulary using different areas of users' finger pads",
        "authors": "Da-Yuan Huang, Ming-Chang Tsai, Ying-Chao Tung, Min-Lun Tsai, Yen-Ting Yeh, Liwei Chan, Yi-Ping Hung, Mike Y. Chen",
        "abstract": "We present TouchSense, which provides additional touchscreen input vocabulary by distinguishing the areas of users' finger pads contacting the touchscreen. It requires minimal touch input area and minimal movement, making it especially ideal for wearable devices such as smart watches and smart glasses. For example, users of a calculator application on a smart watch could tap normally to enter numbers, and tap with the right side of their fingers to enter the operators (e.g. , -, =). Results from two human-factor studies showed that users could tap a touchscreen with five or more distinct areas of their finger pads. Also, they were able to tap with more distinct areas closer to their fingertips. We developed a TouchSense smart watch prototype using inertial measurement sensors, and developed two example applications: a calculator and a text editor. We also collected user feedback via an explorative study.",
        "session": "SESSION: Watches and small devices"
    },
    {
        "title": "Expanding the input expressivity of smartwatches with mechanical pan, twist, tilt and click",
        "authors": "Robert Xiao, Gierad Laput, Chris Harrison",
        "abstract": "Smartwatches promise to bring enhanced convenience to common communication, creation and information retrieval tasks. Due to their prominent placement on the wrist, they must be small and otherwise unobtrusive, which limits the sophistication of interactions we can perform. This problem is particularly acute if the smartwatch relies on a touchscreen for input, as the display is small and our fingers are relatively large. In this work, we propose a complementary input approach: using the watch face as a multi-degree-of-freedom, mechanical interface. We developed a proof of concept smartwatch that supports continuous 2D panning and twist, as well as binary tilt and click. To illustrate the potential of our approach, we developed a series of example applications, many of which are cumbersome -- or even impossible -- on today's smartwatch devices.",
        "session": "SESSION: Watches and small devices"
    },
    {
        "title": "The use of surrounding visual context in handheld AR: device vs. user perspective rendering",
        "authors": "Klen Čopič Pucihar, Paul Coulton, Jason Alexander",
        "abstract": "The magic lens paradigm, a commonly used descriptor for handheld Augmented Reality (AR), presents the user with dual views: the augmented view (magic lens) that appears on the device, and the real view of the surroundings (what the user can see around the perimeter of the device). The augmented view is typically implemented by rendering the video captured by the rear-facing camera directly onto the device's screen. This results in dual perspectives - the real world being captured from the device's perspective rather than the user's perspective (what an observer would see looking through a transparent glass pane). These differences manifest themselves in misaligned and/or incorrectly scaled transparency resulting in the dual-view problem. This paper presents two user studies comparing (a) device-perspective and (b) fixed Point-of-View (POV) user-perspective magic lenses to analyze the effect of the dual-view problem on the use of the surrounding visual context. The results confirm that the dual-view problem, a result of dual perspective, has a significant effect on the use of information from the surrounding visual context. The study also highlights that magnification and not the dual-view problem is the key factor explaining the correlation between magic lens size and the increased intensity of the magic lens type effect. From the results, we derive design guidelines for future magic lenses.",
        "session": "SESSION: The third dimension"
    },
    {
        "title": "Altering gameplay behavior using stereoscopic 3D vision-based video game design",
        "authors": "Jonas Schild, Joseph J. LaViola, Jr., Maic Masuch",
        "abstract": "We explore the potential of stereoscopic 3D (S3D) vision in offering distinct gameplay using an S3D-specific game called Deepress3D. Our game utilizes established S3D design principles for optimizing GUI design, visual comfort and game mechanics which rely on depth perception in time-pressured spatial conflicts. The game collects detailed S3D player metrics and allows players to choose between different, evenly matched strategies. We conducted a between subjects study comparing S3D and monoscopic versions of Deepress3D that examined player behavior and performance and measured user-reported data on presence, simulator sickness, and game experience. Confirming previous results, stereo users reported higher spatial presence. More importantly, for the first time, our game metrics indicate that S3D vision can measurably change player behavior depending on actual game content and level design, without necessarily affecting performance or emotional experience. These findings indicate the potential for optimizing applications for stereo users distinguishing them as a distinct group in HCI research.",
        "session": "SESSION: The third dimension"
    },
    {
        "title": "Depth perception with gaze-contingent depth of field",
        "authors": "Michael Mauderer, Simone Conte, Miguel A. Nacenta, Dhanraj Vishwanath",
        "abstract": "Blur in images can create the sensation of depth because it emulates an optical property of the eye; namely, the limited depth of field created by the eye's lens. When the human eye looks at an object, this object appears sharp on the retina, but objects at different distances appear blurred. Advances in gaze-tracking technologies enable us to reproduce dynamic depth of field in regular displays, providing an alternative way of conveying depth. In this paper we investigate gaze-contingent depth of field as a method to produce realistic 3D images, and analyze how effectively people can use it to perceive depth. We found that GC DOF increases subjective perceived realism and depth and can contribute to the perception of ordinal depth and distance between objects, but it is limited in its accuracy.",
        "session": "SESSION: The third dimension"
    },
    {
        "title": "Imperceptible depth shifts for touch interaction with stereoscopic objects",
        "authors": "Dimitar Valkov, Alexander Giesler, Klaus H. Hinrichs",
        "abstract": "While touch technology has proven its usability for 2D interaction and has already become a standard input modality for many devices, the challenges to exploit its applicability with stereoscopically rendered content have barely been studied. In this paper we exploit the properties of the visual perception to allow users to touch stereoscopically displayed objects when the input is constrained to a 2D surface. Therefore, we have extended and generalized recent evaluations on the user's ability to discriminate small induced object shifts while reaching out to touch a virtual object, and we propose a practical interaction technique, the attracting shift technique, suitable for numerous application scenarios where shallow depth interaction is sufficient. In addition, our results indicate that slight object shifts during touch interaction make the virtual scene appear perceptually more stable compared to a static scene. As a consequence, applications have to manipulate the virtual objects to make them appear static for the user.",
        "session": "SESSION: The third dimension"
    },
    {
        "title": "SonicExplorer: fluid exploration of audio parameters",
        "authors": "Alexander Travis Adams, Berto Gonzalez, Celine Latulipe",
        "abstract": "In digital music production, the phrase \"in the box\" refers to the increasing replacement of extraneous hardware devices with compatible software components. As controls move from hard to soft, we have seen an increase in usability issues for musicians and sound engineers dealing with a large number of temporal inputs and both continuous and discrete controls. We present the SonicExplorer application, which we developed to give users a new interface for exploring and manipulating audio. SonicExplorer leverages users' spatial and color perception to enhance exploration by visualizing the parameter space and providing implicit memory cues. The application also leverages bimanual input to aid in fluid exploration of multidimensional audio parameter spaces, and to minimize the need for switching between parameters.",
        "session": "SESSION: Audio interaction"
    },
    {
        "title": "The boomRoom: mid-air direct interaction with virtual sound sources",
        "authors": "Jörg Müller, Matthias Geier, Christina Dicke, Sascha Spors",
        "abstract": "In this paper we present a system that allows to \"touch\", grab and manipulate sounds in mid-air. Further, arbitrary objects can seem to emit sound. We use spatial sound reproduction for sound rendering and computer vision for tracking. Using our approach, sounds can be heard from anywhere in the room and always appear to originate from the same (possibly moving) position, regardless of the listener's position. We demonstrate that direct \"touch\" interaction with sound is an interesting alternative to indirect interaction mediated through controllers or visual interfaces. We show that sound localization is surprisingly accurate (11.5 cm), even in the presence of distractors. We propose to leverage the ventriloquist effect to further increase localization accuracy. Finally, we demonstrate how affordances of real objects can create synergies of auditory and visual feedback. As an application of the system, we built a spatial music mixing room.",
        "session": "SESSION: Audio interaction"
    },
    {
        "title": "ISSE: an interactive source separation editor",
        "authors": "Nicholas J. Bryan, Gautham J. Mysore, Ge Wang",
        "abstract": "Traditional audio editing tools do not facilitate the task of separating a single mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal, etc.). Such ability, however, would be very useful for a wide variety of audio applications such as music remixing, audio denoising, and audio-based forensics. To address this issue, we present ISSE - an interactive source separation editor. ISSE is a new open-source, freely available, and cross-platform audio editing tool that enables a user to perform source separation by painting on time-frequency visualizations of sound, resulting in an interactive machine learning system. The system brings to life our previously proposed interaction paradigm and separation algorithm that learns from user-feedback to perform separation. For evaluation, we conducted user studies and compared results between inexperienced and expert users. For a variety of real-world tasks, we found that inexperienced users can achieve good separation quality with minimal instruction and expert users can achieve state-of-the-art separation quality.",
        "session": "SESSION: Audio interaction"
    },
    {
        "title": "Evaluation of hear-through sound localization",
        "authors": "Georgios Marentakis, Rudolfs Liepins",
        "abstract": "Listening and interacting with audio commonly relies on using earphones which limit the ability of users to perceive their auditory environment. Earphone sets that integrate miniature microphones on their exterior can, however, be used to hear-through the auditory environment. We present an evaluation study in which sound localization when wearing such a hear-through system is compared to normal earphones, open headphones and unblocked ears. Although localization performance is improved compared to open headphones, we find that it is compromised in comparison to listening without earphones because confusions of sound direction increase and localization judgment distributions are more dispersed and show a weaker correlation to the test directions. The implications of the results to human computer interaction and possible improvements to hear-through system design are discussed.",
        "session": "SESSION: Audio interaction"
    },
    {
        "title": "Performativity in sustainable interaction: the case of seasonal grocery shopping in ecofriends",
        "authors": "Maria Normark, Jakob Tholander",
        "abstract": "The EcoFriends application was developed as an attempt to support grocery shopping adjusted to vegetables? seasonality through a performative approach to interaction and interactive applications. The design aimed at critical reflection and inspiration among users, rather than achieving a certain kind of persuasion. This guided the practical design to be modelled around open-endedness and social voices to challenge ideas and points of view. We argue that research addressing design for interactions about value-laden concepts such as sustainable action need to find ways of supporting various knowledge discourses, by distinguishing between performative and representational technologies. The approach allowed us to identify a number of design challenges regarding interactive technology and interaction design in relation to aspects of knowledge and truth, trust, negotiation and responsibility.",
        "session": "SESSION: Sustainability and everyday practices"
    },
    {
        "title": "The impact of membership overlap on the survival of online communities",
        "authors": "Haiyi Zhu, Robert E. Kraut, Aniket Kittur",
        "abstract": "If the people belong to multiple online communities, their joint membership can influence the survival of each of the communities to which they belong. Communities with many joint memberships may struggle to get enough of their members' time and attention, but find it easy to import best practices from other communities. In this paper, we study the effects of membership overlap on the survival of online communities. By analyzing the historical data of 5673 Wikia communities, we find that higher levels of membership overlap are positively associated with higher survival rates of online communities. Furthermore, we find that it is beneficial for young communities to have shared members who play a central role in other mature communities. Our contributions are two-fold. Theoretically, by examining the impact of membership overlap on the survival of online communities we identified an important mechanism underlying the success of online communities. Practically, our findings may guide community creators on how to effectively manage their members, and tool designers on how to support this task.",
        "session": "SESSION: Studying online communities"
    },
    {
        "title": "Goals and perceived success of online enterprise communities: what is important to leaders & members?",
        "authors": "Tara Matthews, Jilin Chen, Steve Whittaker, Aditya Pal, Haiyi Zhu, Hernan Badenes, Barton Smith",
        "abstract": "Online communities are successful only if they achieve their goals, but there has been little direct study of goals. We analyze novel data characterizing the goals of enterprise online communities, assessing the importance of goals for leaders, how goals influence member perceptions of community value, and how goals relate to success measures proposed in the literature. We find that most communities have multiple goals and common goals are learning, reuse of resources, collaboration, networking, influencing change, and innovation. Leaders and members agree that all of these goals are important, but their perceptions of success on goals do not align with each other, or with commonly used behavioral success measures. We conclude that simple behavioral measures and leader perceptions are not good success metrics, and propose alternatives based on specific goals members and leaders judge most important.",
        "session": "SESSION: Studying online communities"
    },
    {
        "title": "Selecting an effective niche: an ecological view of the success of online communities",
        "authors": "Haiyi Zhu, Jilin Chen, Tara Matthews, Aditya Pal, Hernan Badenes, Robert E. Kraut",
        "abstract": "Online communities serve various important functions, but many fail to thrive. Research on community success has traditionally focused on internal factors. In contrast, we take an ecological view to understand how the success of a community is influenced by other communities. We measured a community's relationship with other communities - its \"niche\" - through four dimensions: topic overlap, shared members, content linking, and shared offline organizational affiliation. We used a mixed-method approach, combining the quantitative analysis of 9495 online enterprise communities and interviews with community members. Our results show that too little or too much overlap in topic with other communities causes a community's activity to suffer. We also show that this main result is moderated in predictable ways by whether the community shares members with, links to content in, or shares an organizational affiliation with other communities. These findings provide new insight on community success, guiding online community designers on how to effectively position their community in relation to others.",
        "session": "SESSION: Studying online communities"
    },
    {
        "title": "Snuggle: designing for efficient socialization and ideological critique",
        "authors": "Aaron Halfaker, R. Stuart Geiger, Loren G. Terveen",
        "abstract": "Wikipedia, the encyclopedia \"anyone can edit\", has become increasingly less so. Recent academic research and popular discourse illustrates the often aggressive ways newcomers are treated by veteran Wikipedians. These are complex sociotechnical issues, bound up in infrastructures based on problematic ideologies. In response, we worked with a coalition of Wikipedians to design, develop, and deploy Snuggle, a new user interface that served two critical functions: making the work of newcomer socialization more effective, and bringing visibility to instances in which Wikipedians? current practice of gatekeeping socialization breaks down. Snuggle supports positive socialization by helping mentors quickly find newcomers whose good-faith mistakes were reverted as damage. Snuggle also supports ideological critique and reflection by bringing visibility to the consequences of viewing newcomers through a lens of suspiciousness.",
        "session": "SESSION: Studying online communities"
    },
    {
        "title": "Offline painted media for digital animation authoring",
        "authors": "Makoto Nakajima, Daisuke Sakamoto, Takeo Igarashi",
        "abstract": "We present an animation creation workflow for integrating offline physical, painted media into the digital authoring of Flash-style animations. Generally, animators create animations with standardized digital authoring software. However, the results tend to lack the individualism or atmosphere of physical media. In contrast, illustrators have skills in painting physical media but have limited experience in animation. To incorporate their skills, we present a workflow that integrates the offline painting and digital animation creation processes in a labor-saving manner. First, a user makes a rough sketch of the visual elements and defines their movements using our digital authoring software with a sketch interface. Then these images are exported to printed pages, and users can paint using offline physical media. Finally, the work is scanned and imported back into the digital content, forming a composite animation that combines digital and physical media. We present an implementation of this system to demonstrate its workflow. We also discuss the advantages of using physical media in digital animations through design evaluations.",
        "session": "SESSION: Image and animation authoring"
    },
    {
        "title": "Supporting informal design with interactive whiteboards",
        "authors": "Nicolas Mangano, Thomas D. LaToza, Marian Petre, André van der Hoek",
        "abstract": "Whiteboards serve an important role in supporting informal design, providing a fluid and flexible medium for collaborative design. Interactive whiteboards offer the potential for enhanced support for manipulating content, managing sketches, and distributed work, but little is known about how this support affects the practice of informal design. To understand the opportunities and challenges, we first conducted a literature review, identifying 14 behaviors that occur during informal design. We then designed an interactive whiteboard system to support all of these behaviors and deployed the system to three groups of designers. Through usage logs and interviews, we examined the effects of interactivity on whiteboard use across a wide spectrum of design behaviors, identifying ways in which interactive whiteboards support the practices used in physical whiteboards and where they enable designers to work more effectively.",
        "session": "SESSION: Image and animation authoring"
    },
    {
        "title": "Juxtapoze: supporting serendipity and creative expression in clipart compositions",
        "authors": "William Benjamin, Senthil Chandrasegaran, Devarajan Ramanujan, Niklas Elmqvist, SVN Vishwanathan, Karthik Ramani",
        "abstract": "Juxtapoze is a clipart composition workflow that supports creative expression and serendipitous discoveries in the shape domain. We achieve creative expression by supporting a workflow of searching, editing, and composing: the user queries the shape database using strokes, selects the desired search result, and finally modifies the selected image before composing it into the overall drawing. Serendipitous discovery of shapes is facilitated by allowing multiple exploration channels, such as doodles, shape filtering, and relaxed search. Results from a qualitative evaluation show that Juxtapoze makes the process of creating image compositions enjoyable and supports creative expression and serendipity.",
        "session": "SESSION: Image and animation authoring"
    },
    {
        "title": "Draco: bringing life to illustrations with kinetic textures",
        "authors": "Rubaiat Habib Kazi, Fanny Chevalier, Tovi Grossman, Shengdong Zhao, George Fitzmaurice",
        "abstract": "We present Draco, a sketch-based interface that allows artists and casual users alike to add a rich set of animation effects to their drawings, seemingly bringing illustrations to life. While previous systems have introduced sketch-based animations for individual objects, our contribution is a unified framework of motion controls that allows users to seamlessly add coordinated motions to object collections. We propose a framework built around kinetic textures, which provide continuous animation effects while preserving the unique timeless nature of still illustrations. This enables many dynamic effects difficult or not possible with previous sketch-based tools, such as a school of fish swimming, tree leaves blowing in the wind, or water rippling in a pond. We describe our implementation and illustrate the repertoire of animation effects it supports. A user study with professional animators and casual users demonstrates the variety of animations, applications and creative possibilities our tool provides.",
        "session": "SESSION: Image and animation authoring"
    },
    {
        "title": "A user study of different gameplay visualizations",
        "authors": "Simone Kriglstein, Günter Wallner, Margit Pohl",
        "abstract": "With the rising interest in multiplayer gaming, gameplay statistics have become an increasingly important aspect of the overall game experience for many players. As a part of this trend, visualizations have gained great popularity among players, in particular heatmaps since they allow them to reenact the course of a game and to develop new strategies. In this paper we report results of a user study conducted with 29 players (i) to investigate how players use heatmaps and two further graphical representations that use clustering algorithms to interpret gameplay and (ii) to assess the three representations in regard to time efficiency, correctness, suitability, and player preference. Our results show that heatmaps were mainly used to detect hot spots while the cluster representations proved useful to compare variables, allowing the players to uncover relationships between them and in turn allowing a deeper insight into the gameplay data.",
        "session": "SESSION: Studying and designing gameplay"
    },
    {
        "title": "The influence of controllers on immersion in mobile games",
        "authors": "Paul Cairns, Jing Li, Wendy Wang, A. Imran Nordin",
        "abstract": "The controls for digital games understandably have an important part in building up the gaming experiences that people have. Whilst there is substantial work on innovative controllers for consoles, like the XBox Kinect, relatively little has been done to understand the effect of the different control mechanisms that can be used to play games on mobile devices like smartphones. A well-defined framework of naturalness has emerged as potentially useful concept in area of game controllers. This paper reports two experiments that look at how the naturalness of the game controls influences the experience of immersion in mobile games. It seems that where there is an a prior natural mapping, this will improve immersion in the game but in the absence of a prior mapping, naturalness alone is not sufficient to account for immersion. This opens up the need for a more thorough investigation of this area.",
        "session": "SESSION: Studying and designing gameplay"
    },
    {
        "title": "Combining think-aloud and physiological data to understand video game experiences",
        "authors": "Chek Tien Tan, Tuck Wah Leong, Songjia Shen",
        "abstract": "Think-aloud protocols are commonly used to evaluate player experiences of video games but suffer from a lack of objectivity and timeliness. On the other hand, quantitative captures of physiological data are effective; providing detailed, unbiased and continuous responses of players, but lack contexts for interpretation. This paper documents how both approaches could be used together in practice by comparing video-cued retrospective think-aloud data and physiological data collected during a video gameplay experiment. We observed that many interesting physiological responses did not feature in participants' think-aloud data, and conversely, reports of interesting experiences were sometimes not observed in the collected physiological data. Through learnings from our experiment, we present some of the challenges when combining these approaches and offer some guidelines as to how qualitative and quantitative data can be used together to gain deeper insights into player experiences.",
        "session": "SESSION: Studying and designing gameplay"
    },
    {
        "title": "The MOY framework for collaborative play design in integrated shared and private interactive spaces",
        "authors": "Wooi Boon Goh, Ming Chen, Cuong Hong Trinh, Jacquelyn Tan, Wei Shou",
        "abstract": "A novel Mine-Ours-Yours (MOY) interaction design framework is proposed for designing collaborative play activities in environments that combine both private and shared interactive spaces. A collaborative game designed on a system that integrates multiple mobile devices with an interactive tabletop was presented to demonstrate the implementation of the proposed MOY framework. Observations from field trials involving two groups of children were used to summarize the collaborative behaviors that are likely to be observed under the different interaction design configurations.",
        "session": "SESSION: Studying and designing gameplay"
    },
    {
        "title": "Transient and transitional states: pressure as an auxiliary input modality for bimanual interaction",
        "authors": "Ross McLachlan, Daniel Boland, Stephen Brewster",
        "abstract": "A novel investigation of pressure input is presented where it is characterised as a transient modality, one that has a natural inverse, bounce-back and a state that only persists during interaction. Three empirical studies are described that evaluate pressure for use as a non-dominant hand input modality, where the ability to target and maintain pressure while simultaneously performing a dominant-hand targeting task is investigated. Pressure accuracy was high (93%) and the impact on dominant-hand targeting was low. Mean pressure accuracy when selecting targets by releasing pressure was also high (89%) as was selecting targets by applying pressure from a non-zero starting point (94.4%). The ability to accurately maintain pressure over time was better with larger target pressures. Example applications and design guidelines are presented that enable designers to exploit the transient properties of pressure input in interaction design.",
        "session": "SESSION: Force input and haptic feedback"
    },
    {
        "title": "VacuumTouch: attractive force feedback interface for haptic interactive surface using air suction",
        "authors": "Taku Hachisu, Masaaki Fukumoto",
        "abstract": "We present VacuumTouch, a novel haptic interface architecture for touch screens that provides attractive force feedback to the user's finger. VacuumTouch consists of an air pump and solenoid air valves that connect to the surface of the touch screen and suck the air above the surface where the user's finger makes contact. VacuumTouch does not require the user to hold or attach additional devices to provide the attractive force, which allows for easy interaction with the surface. This paper introduces the implementation of the VacuumTouch architecture and some applications for enhancement of the graphical user interface, namely a suction button, a suction slider, and a suction dial. The quantitative evaluation was conducted with the suction dial and showed that the attractive force provided by VacuumTouch improved the performance of the dial menu interface and its potential effects. At the end of this paper, we discuss the current prototype's advantages and limitations, as well as possible improvements and potential capabilities.",
        "session": "SESSION: Force input and haptic feedback"
    },
    {
        "title": "Expressive touch: studying tapping force on tabletops",
        "authors": "Esben Warming Pedersen, Kasper Hornbæk",
        "abstract": "This paper investigates users' ability to perform force-sensitive tapping and explores its potential as an input modality in touch-based systems. We study force-sensitive tapping using Expressive Touch, a tabletop interface that infers tapping force from the sound waves created by the users' finger upon impact. The first part of the paper describes the implementation details of Expressive Touch and shows how existing tabletop interfaces can be augmented to reliably detect tapping force across the entire surface. The second part of the paper reports on the results of three studies of force-sensitive tapping. First, we use a classic psychophysic task to gain insights into participants' perception of tapping force (Study 1). Results show that although participants tap with different absolute tapping forces, they have a similar perception of relative tapping force. Second, we investigate participants' ability to control tapping force (Study 2) and find that users can produce two force levels with 99% accuracy. For six levels of force, accuracy drops to 58%. Third, we investigate the usability of force tapping by studying participants' reactions to seven force-sensitive touch applications (Study 3).",
        "session": "SESSION: Force input and haptic feedback"
    },
    {
        "title": "Presstures: exploring pressure-sensitive multi-touch gestures on trackpads",
        "authors": "Christian Rendl, Patrick Greindl, Kathrin Probst, Martin Behrens, Michael Haller",
        "abstract": "In this paper, we present Presstures, an extension to current multi-touch operations that enriches common multi-finger gestures with pressure information. By using the initially applied pressure level for implicit mode switching, a gesture can be enhanced with different functionalities to enlarge the interaction space for multi-touch. To evaluate the feasibility of our concept, we conducted an experiment, which indicates good human sensorimotor skills for performing multi-touch gestures with a few number of pressure levels and without any additional feedback. Based on the experimental results, we discuss implications for the design of pressure-sensitive multi-touch gestures, and propose application scenarios that make optimal use of our concept.",
        "session": "SESSION: Force input and haptic feedback"
    },
    {
        "title": "Gaze gestures and haptic feedback in mobile devices",
        "authors": "Jari Kangas, Deepak Akkil, Jussi Rantala, Poika Isokoski, Päivi Majaranta, Roope Raisamo",
        "abstract": "Anticipating the emergence of gaze tracking capable mobile devices, we are investigating the use of gaze as an input modality in handheld mobile devices. We conducted a study of combining gaze gestures with vibrotactile feedback. Gaze gestures were used as an input method in a mobile device and vibrotactile feedback as a new alternative way to give confirmation of interaction events. Our results show that vibrotactile feedback significantly improved the use of gaze gestures. The tasks were completed faster and rated easier and more comfortable when vibrotactile feedback was provided.",
        "session": "SESSION: Force input and haptic feedback"
    },
    {
        "title": "Emerging sites of HCI innovation: hackerspaces, hardware startups & incubators",
        "authors": "Silvia Lindtner, Garnet D. Hertz, Paul Dourish",
        "abstract": "In this paper, we discuss how a flourishing scene of DIY makers is turning visions of tangible and ubiquitous computing into products. Drawing on long-term multi-sited ethnographic research and active participation in DIY making, we provide insights into the social, material, and economic processes that undergird this transition from prototypes to products. The contribution of this paper is three-fold. First, we show how DIY maker practice is illustrative of a broader \"return to\" and interest in physical materials. This has implications for HCI research that investigates questions of materiality. Second, we shed light on how hackerspaces and hardware start-ups are experimenting with new models of manufacturing and entrepreneurship. We argue that we have to take seriously these maker practices, not just as hobbyist or leisure practice, but as a professionalizing field functioning in parallel to research and industry labs. Finally, we end with reflections on the role of HCI researchers and designers as DIY making emerges as a site of HCI innovation. We argue that HCI is positioned to provide critical reflection, paired with a sensibility for materials, tools and design methods.",
        "session": "SESSION: Hackerspaces, making and breaking"
    },
    {
        "title": "Breakdown, obsolescence and reuse: HCI and the art of repair",
        "authors": "Steven J. Jackson, Laewoo Kang",
        "abstract": "This paper describes an integrated program of theoretical, ethnographic, and building work meant to explore post-humanist alternatives to questions around HCI creativity and design. We review recent theories in the humanities, social sciences, and HCI that argue for different ways of framing the relationship between human agents and the object world around them. We then describe a program of ethnographic work with artists who feature found and broken technologies as central methods and topics of work. Finally, we describe an installation and self-study project of our own, 'Scale,' that extends these lines of analysis through collaborative acts of building with broken and discarded technologies. We argue that such integrated programs of work offer one useful model for leveraging the theoretical, ethnographic and material dimensions of HCI work; and that the distinct 'propensities' of found and broken objects can challenge and extend HCI notions of creativity and design itself.",
        "session": "SESSION: Hackerspaces, making and breaking"
    },
    {
        "title": "Printing teddy bears: a technique for 3D printing of soft interactive objects",
        "authors": "Scott E. Hudson",
        "abstract": "This paper considers the design, construction, and example use of a new type of 3D printer which fabricates three-dimensional objects from soft fibers (wool and wool blend yarn). This printer allows the substantial advantages of additive manufacturing techniques (including rapid turn-around prototyping of physical objects and support for high levels of customization and configuration) to be employed with a new class of material. This material is a form of loose felt formed when fibers from an incoming feed of yarn are entangled with the fibers in layers below it. The resulting objects recreate the geometric forms specified in the solid models which specify them, but are soft and flexible -- somewhat reminiscent in character to hand knitted materials. This extends 3D printing from typically hard and precise forms into a new set of forms which embody a different aesthetic of soft and imprecise objects, and provides a new capability for researchers to explore the use of this class of materials in interactive devices.",
        "session": "SESSION: Hackerspaces, making and breaking"
    },
    {
        "title": "Taking things apart: reaching common ground and shared material understanding",
        "authors": "Martin Murer, Mattias Jacobsson, Siri Skillgate, Petra Sundström",
        "abstract": "In this note we discuss and argue about how taking things apart and disassembling can be meaningful practices in explorative design projects. In particular, we report on an explorative design exercise about taking apart an unfamiliar device. Relating to this design situation, we provide accounts for how collaborative hands-on experience can support reaching common ground and acquiring shared material understanding in an interdisciplinary design team through establishing a material brief. In the end we reflect and discuss how this may complement our practices regarding materials and interaction design.",
        "session": "SESSION: Hackerspaces, making and breaking"
    },
    {
        "title": "\"now that's definitely a proper hack\": self-made tools in hackerspaces",
        "authors": "Jeffrey Bardzell, Shaowen Bardzell, Austin Toombs",
        "abstract": "Cultures of making - that is, social practices of hacking, DIY, tinkering, repair, and craft - continue to rise in prominence, and design researchers have taken note, because of their implications for sustainability, democratization, and alternative models of innovation, design, participation, and education. We contribute to this agenda by exploring our findings on self-made tools, which we encountered in a 9-month ethnographic study of a hackerspace. Self-made tools embody issues raised in two discourses that are of interest in design research on making: tools and adhocism. In this paper, we explore ways that tools and adhocism interface with each other, using our findings as a material to think with. We find that this juxtaposition of concepts helps explain a highly generative creative practice - tool-making - within the hackerspace we studied.",
        "session": "SESSION: Hackerspaces, making and breaking"
    },
    {
        "title": "Toss 'n' turn: smartphone as sleep and sleep quality detector",
        "authors": "Jun-Ki Min, Afsaneh Doryab, Jason Wiese, Shahriyar Amini, John Zimmerman, Jason I. Hong",
        "abstract": "The rapid adoption of smartphones along with a growing habit for using these devices as alarm clocks presents an opportunity to use this device as a sleep detector. This adds value to UbiComp and personal informatics in terms of user context and new performance data to collect and visualize, and it benefits healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06% accuracy, daily sleep quality with 83.97% accuracy, and overall sleep quality with 81.48% accuracy. Individual models performed better than generally trained models, where the individual models require 3 days of ground truth data and 3 weeks of ground truth data to perform well on detecting sleep and sleep quality, respectively. Finally, the features of noise and movement were useful to infer sleep quality.",
        "session": "SESSION: Activity recognition"
    },
    {
        "title": "Persuasive technology in the real world: a study of long-term use of activity sensing devices for fitness",
        "authors": "Thomas Fritz, Elaine M. Huang, Gail C. Murphy, Thomas Zimmermann",
        "abstract": "Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly \"in the wild\" contexts and understand how practices evolve over long-term, naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings, which both support and contrast with those of previous research, paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.",
        "session": "SESSION: Activity recognition"
    },
    {
        "title": "Predictors of life satisfaction based on daily activities from mobile sensor data",
        "authors": "Onur Yürüten, Jiyong Zhang, Pearl H.Z. Pu",
        "abstract": "In recent years much research work has been dedicated to detecting user activity patterns from sensor data such as location, movement and proximity. However, how daily activities are correlated to people's happiness (such as their satisfaction from work and social lives) is not well explored. In this work, we propose an approach to investigate the relationship between users' daily activity patterns and their life satisfaction level. From a well-known longitudinal dataset collected by mobile devices, we extract various activity features through location and proximity information, and compute the entropies of these data to capture the regularities of the behavioral patterns of the participants. We then perform component analysis and structural equation modeling to identify key behavior contributors to self-reported satisfaction scores. Our results show that our analytical procedure can identify meaningful assumptions of causality between activities and satisfaction. Particularly, keeping regularity in daily activities can significantly improve the life satisfaction.",
        "session": "SESSION: Activity recognition"
    },
    {
        "title": "Pay or delay: the role of technology when managing a low income",
        "authors": "John Vines, Paul Dunphy, Andrew Monk",
        "abstract": "This paper reports on a qualitative study of 38 low-income individuals living in the North East of England. The participants' experiences of money, banking and the role digital technology plays in their financial practices were identified through semi-structured interviews in people's homes and group workshops. A grounded theory analysis of these data characterises how technology both helped and hindered participants to keep close control of their finances. These findings suggest design opportunities for future digital banking technologies that extend the already sophisticated practices of individuals managing a low income, focusing on: delaying, prioritising, planning, watching, and hiding monetary transactions.",
        "session": "SESSION: Managing income"
    },
    {
        "title": "Poverty on the cheap: estimating poverty maps using aggregated mobile communication networks",
        "authors": "Christopher Smith-Clarke, Afra Mashhadi, Licia Capra",
        "abstract": "Governments and other organisations often rely on data collected by household surveys and censuses to identify areas in most need of regeneration and development projects. However, due to the high cost associated with the data collection process, many developing countries conduct such surveys very infrequently and include only a rather small sample of the population, thus failing to accurately capture the current socio-economic status of the country's population. In this paper, we address this problem by means of a methodology that relies on an alternative source of data from which to derive up to date poverty indicators, at a very fine level of spatio-temporal granularity. Taking two developing countries as examples, we show how to analyse the aggregated call detail records of mobile phone subscribers and extract features that are strongly correlated with poverty indexes currently derived from census data.",
        "session": "SESSION: Managing income"
    },
    {
        "title": "Money talks: tracking personal finances",
        "authors": "Joseph Jofish Kaye, Mary McCuistion, Rebecca Gulotta, David A. Shamma",
        "abstract": "How do people keep track of their money? In this paper we present a preliminary scoping study of how 14 individuals in the San Francisco Bay Area earn, save, spend and understand money and their personal and family finances. We describe the practices we developed for exploring the sensitive topic of money, and then discuss three sets of findings. The first is the emotional component of the relationship people have with their finances. Second, we discuss the tools and processes people used to keep track of their financial situation. Finally we discuss how people account for the unknown and unpredictable nature of the future through their financial decisions. We conclude by discussing the future of studies of money and finance in HCI, and reflect on the opportunities for improving tools to aid people in managing and planning their finances.",
        "session": "SESSION: Managing income"
    },
    {
        "title": "Fostering social capital in economically distressed communities",
        "authors": "Tawanna R. Dillahunt",
        "abstract": "Past Information and Communication Technology (ICT) literature suggests that engaging in meaningful activities with ICTs may be related to socio-economic security, social inclusion, empowerment, and increased social capital. However, we identify a pervasive lack of understanding in existing literature, which raises an important research question: how can we build social capital where little social capital exists? We conducted a preliminary study to explore whether and if so, how, individuals in an economically distressed population with limited social capital use technologies to increase social capital and achieve socio-economic security. We contribute details about barriers affecting social capital (e.g., difficulties finding and making the right connections and an overall lack of trust within communities). We also suggest ways in which ICTs can assist populations that could benefit most from increased social capital and economic security.",
        "session": "SESSION: Managing income"
    },
    {
        "title": "Automatic generation of semantic icon encodings for visualizations",
        "authors": "Vidya Setlur, Jock D. Mackinlay",
        "abstract": "Authors use icon encodings to indicate the semantics of categorical information in visualizations. The default icon libraries found in visualization tools often do not match the semantics of the data. Users often manually search for or create icons that are more semantically meaningful. This process can hinder the flow of visual analysis, especially when the amount of data is large, leading to a suboptimal user experience. We propose a technique for automatically generating semantically relevant icon encodings for categorical dimensions of data points. The algorithm employs natural language processing in order to find relevant imagery from the Internet. We evaluate our approach on Mechanical Turk by generating large libraries of icons using Tableau Public workbooks that represent real analytical effort by people out in the world. Our results show that the automatic algorithm does nearly as well as the manually created icons, and particularly has higher user satisfaction for larger cardinalities of data.",
        "session": "SESSION: Designing and understanding visualizations"
    },
    {
        "title": "Task-driven evaluation of aggregation in time series visualization",
        "authors": "Danielle Albers, Michael Correll, Michael Gleicher",
        "abstract": "Many visualization tasks require the viewer to make judgments about aggregate properties of data. Recent work has shown that viewers can perform such tasks effectively, for example to efficiently compare the maximums or means over ranges of data. However, this work also shows that such effectiveness depends on the designs of the displays. In this paper, we explore this relationship between aggregation task and visualization design to provide guidance on matching tasks with designs. We combine prior results from perceptual science and graphical perception to suggest a set of design variables that influence performance on various aggregate comparison tasks. We describe how choices in these variables can lead to designs that are matched to particular tasks. We use these variables to assess a set of eight different designs, predicting how they will support a set of six aggregate time series comparison tasks. A crowd-sourced evaluation confirms these predictions. These results not only provide evidence for how the specific visualizations support various tasks, but also suggest using the identified design variables as a tool for designing visualizations well suited for various types of tasks.",
        "session": "SESSION: Designing and understanding visualizations"
    },
    {
        "title": "Dive in!: enabling progressive loading for real-time navigation of data visualizations",
        "authors": "Michael Glueck, Azam Khan, Daniel J. Wigdor",
        "abstract": "We introduce Splash, a framework reducing development overhead for both data curators and visualization developers of client-server visualization systems. Splash streamlines the process of creating a multiple level-of-detail version of the data and facilitates progressive data download, thereby enabling real-time, on-demand navigation with existing visualization toolkits. As a result, system responsiveness is increased and the user experience is improved. We demonstrate the benefit of progressive loading for user interaction on slower networks. Additionally, case study evaluations of Splash with real-world data curators suggest that Splash supports iterative refinement of visualizations and promotes the use of exploratory data analysis.",
        "session": "SESSION: Designing and understanding visualizations"
    },
    {
        "title": "Sample-oriented task-driven visualizations: allowing users to make better, more confident decisions",
        "authors": "Nivan Ferreira, Danyel Fisher, Arnd Christian Konig",
        "abstract": "We often use datasets that reflect samples, but many visualization tools treat data as full populations. Uncertain visualizations are good at representing data distributions emerging from samples, but are more limited in allowing users to carry out decision tasks. This is because tasks that are simple on a traditional chart (e.g. \"compare two bars\") become a complex probabilistic task on a chart with uncertainty. We present guidelines for creating visual annotations for solving tasks with uncertainty, and an implementation that addresses five core tasks on a bar chart. A preliminary user study shows promising results: that users have a justified confidence in their answers with our system.",
        "session": "SESSION: Designing and understanding visualizations"
    },
    {
        "title": "Learning to fail: experiencing public failure online through crowdfunding",
        "authors": "Michael D. Greenberg, Elizabeth M. Gerber",
        "abstract": "Online crowdfunding platforms like Kickstarter are gaining attention among novice creatives as an effective platform for funding their ventures and engaging in creative work with others. However, a focus on financial success of crowdfunding has obscured the fact that over 58% of crowdfunding projects fail to achieve their funding goals. This population of failed creatives however, gives us an audience to study public creative failure in an online environment. We draw inspiration from work in organizational behavior on failure, and work in Human Computer Interaction (HCI) on online behavior, to study online public failure. Using a mixed-methods approach with data scraped from Kickstarter and interview data with failed crowdfunding project creators, we answer the following question: What do project creators on crowdfunding platforms learn and change through the process of failing? We find that creators who relaunch their projects succeed 43% of the time, and that most individuals find failure to be a positive experience. We conclude the paper with a series of design implications for future creative platforms where public failure is part of the creative process.",
        "session": "SESSION: Crowdfunding and crowd storage"
    },
    {
        "title": "Show me the money!: an analysis of project updates during crowdfunding campaigns",
        "authors": "Anbang Xu, Xiao Yang, Huaming Rao, Wai-Tat Fu, Shih-Wen Huang, Brian P. Bailey",
        "abstract": "Hundreds of thousands of crowdfunding campaigns have been launched, but more than half of them have failed. To better understand the factors affecting campaign outcomes, this paper targets the content and usage patterns of project updates -- communications intended to keep potential funders aware of a campaign's progress. We analyzed the content and usage patterns of a large corpus of project updates on Kickstarter, one of the largest crowdfunding platforms. Using semantic analysis techniques, we derived a taxonomy of the types of project updates created during campaigns, and found discrepancies between the design intent of a project update and the various uses in practice (e.g. social promotion). The analysis also showed that specific uses of updates had stronger associations with campaign success than the project's description. Design implications were formulated from the results to help designers better support various uses of updates in crowdfunding campaigns.",
        "session": "SESSION: Crowdfunding and crowd storage"
    },
    {
        "title": "Crowd storage: storing information on existing memories",
        "authors": "Jeffrey P. Bigham, Walter S. Lasecki",
        "abstract": "This paper introduces the concept of crowd storage, the idea that digital files can be stored and retrieved later from the memories of people in the crowd. Similar to human memory, crowd storage is ephemeral, which means that storage is temporary and the quality of the stored information degrades over time. Crowd storage may be preferred over storing information directly in the cloud, or when it is desirable for information to degrade inline with normal human memories. To explore and validate this idea, we created WeStore, a system that stores and then later retrieves digital files in the existing memories of crowd workers. WeStore does not store information directly, but rather encrypts the files using details of the existing memories elicited from individuals within the crowd as cryptographic keys. The fidelity of the retrieved information is tied to how well the crowd remembers the details of the memories they provided. We demonstrate that crowd storage is feasible using an existing crowd marketplace (Amazon Mechanical Turk), explore design considerations important for building systems that use crowd storage, and outline ideas for future research in this area.",
        "session": "SESSION: Crowdfunding and crowd storage"
    },
    {
        "title": "Walk this way: musically guided walking experiences",
        "authors": "Adrian Hazzard, Steve Benford, Gary Burnett",
        "abstract": "Musical soundtracks will be important features of future locative experiences from tours to games. We present a study designed to uncover potential relationships between higher-level musical structures such as harmony, melody, timbre, dynamic intensity and punctuation and users' spatial experiences. We observed twenty-two participants exploring an open field while listening to four contrasting musical compositions, and then interviewed them afterwards. We report their different approaches to interpreting the music, strategies for mapping zones, choice of stopping destinations, and their awareness and appreciation of the music. Our discussion of these findings in relation to the literature leads us to propose six initial principles to guide the composition of mobile and locative soundtracks, and also to articulate a three-layer framework of global, regional and local attachment to help guide the attachment of musical features to different regions within a locative experience.",
        "session": "SESSION: Novel approaches to navigation"
    },
    {
        "title": "Simplifying orientation measurement for mobile audio augmented reality applications",
        "authors": "Florian Heller, Aaron Krämer, Jan Borchers",
        "abstract": "Audio augmented reality systems overlay the physical world with a virtual audio space. Today's smartphones provide enough processing power to create the impression of virtual sound sources being located in the real world. To achieve this, information about the user's location and orientation is necessary which requires additional hardware. In a real-world installation, however, we observed that instead of turning their head to localize sounds, users tend to turn their entire body. Therefore, we suggest to simply measure orientation of the user's body - or even just the mobile device she is holding - to generate the spatial audio. To verify this approach, we present two studies: Our first study in examines the user's head, body, and mobile device orientation when moving through an audio augmented reality system in a lab setting. Our second study analyzes the user experience in a real-world installation when using head, body, or device orientation to control the audio spatialization. We found that when navigating close to sound sources head tracking is necessary, but that it can potentially be replaced by device tracking in larger or more explorative usage scenarios. These findings help reduce the technical complexity of mobile audio augmented reality systems (MAARS), and enable their wider dissemination as mobile software-only apps.",
        "session": "SESSION: Novel approaches to navigation"
    },
    {
        "title": "Gifting personal interpretations in galleries",
        "authors": "Lesley Fosh, Steve Benford, Stuart Reeves, Boriana Koleva",
        "abstract": "The designers of mobile guides for museums and galleries face three major challenges: fostering rich interpretation, delivering deep personalization, and enabling a coherent social visit. We propose an approach to tackling all three simultaneously by inviting visitors to design an interpretation that is specifically tailored for a friend or loved one that they then experience together. We describe a trial of this approach at a contemporary art gallery, revealing how visitors designed personal and sometimes provocative experiences for people they knew well. We reveal how pairs of visitors negotiated these experiences together, showing how our approach could deliver intense experiences for both, but also required them to manage social risk. By interpreting our findings through the lens of 'gift giving' we shed new light on ongoing explorations of interpretation, personalization and social visiting within HCI.",
        "session": "SESSION: Novel approaches to navigation"
    },
    {
        "title": "Visual recognition in museum guide apps: do visitors want it?",
        "authors": "Leonard Wein",
        "abstract": "In this paper, visual recognition (VisRec) is evaluated as a method to access background information on artworks in mobile museum guide applications (apps) by means of a field experiment. While museums and previous research have explored technical aspects, it is unclear whether visitors actually want to use VisRec. A prototype featuring VisRec, QR codes and number codes was developed and assessed with a usability study in two museums (N=89). The prototype confirms the efficacy of the recently introduced ORB-algorithm for VisRec. Compared to previous literature, the results highlight the context-dependency of perceived usability and variability in the importance of usability factors. The results reveal a clear preference for VisRec among participants (53%); only 14% preferred QR codes. Ease of use, enjoyability and distance are identified as the main factors. This provides strong evidence to further explore the potential of VisRec to improve visitors' museum experiences.",
        "session": "SESSION: Novel approaches to navigation"
    },
    {
        "title": "A billion signposts: repurposing barcodes for indoor navigation",
        "authors": "Simon Robinson, Jennifer S. Pearson, Matt Jones",
        "abstract": "Barcodes are all around us--on books, groceries and other products--but these everyday markers are typically used for a single focused purpose. In this paper we explore the concept of \"piggybacking\" on ubiquitous markers to facilitate indoor navigation. Our initial probe--BookMark--allows library visitors to scan any nearby book to provide a custom map to the location of a desired item. In contrast to previous indoor navigation systems, our approach repurposes existing markers on physical items that are already in the navigation space, meaning that no additional infrastructure is required. We evaluated the BookMark probe in a large university library, showing its potential with real library users. In addition, we illustrate how the general technique shows further potential in other similar barcode-rich environments.",
        "session": "SESSION: Novel approaches to navigation"
    },
    {
        "title": "Taking part: role-play in the design of therapeutic systems",
        "authors": "Mark Matthews, Geri Gay, Gavin Doherty",
        "abstract": "Gaining an understanding of user needs is a central component of HCI design approaches such as user-centred design and participatory design. In some settings, such as mental health care, access to end-users is often constrained. This is a particular difficulty given that the experience of those with mental illness can be difficult for researchers to understand, and is further complicated by its associated stigma. In addition, the therapeutic setting is outside the common experience of most people and protected from outside intrusion. Although role-play has been used in varied ways in HCI, rarely has it been defined with sufficient clarity to enable others to deploy it in a nuanced manner. We argue that role-play is particularly suited for use in mental healthcare settings and, when used judiciously, can address some of the difficulties associated with working in this setting. This paper details a range of role-play formats appropriated from therapeutic role-play, drawing upon the HCI and mental health literature, therapist input and our experience of using role-play for a number of purposes at different stages of the development process. We consider how and why role-play can be used to generate empathy, gain understanding of therapy, provide feedback on designs before clinical use and help train therapists in using technology in the treatment room.",
        "session": "SESSION: Interfaces for care and support"
    },
    {
        "title": "Staccato social support in mobile health applications",
        "authors": "Phil Adams, Eric PS Baumer, Geri Gay",
        "abstract": "Social support plays an important role in health systems. While significant work has explored the role of social support in CMC environments, less analysis has considered social support in mobile health systems. This paper describes socially supportive messages in VERA, a mobile application for sharing health decisions and behaviors. The short and bursty interactions in social awareness streams [36] afford a particular style of social support, for which we offer the label staccato social support. Results indicate that, in comparison to previous work, staccato social support is characterized by a greater prevalence of esteem support, which builds respect and confidence. We further note the presence of 'following up', a positive behavior that contributes to supportive interactions, likely via social pressure and accountability [7,38]. These findings suggest design recommendations to developers of mobile social support systems and contribute to understanding technologically mediated social support for health.",
        "session": "SESSION: Interfaces for care and support"
    },
    {
        "title": "My journey compass: a preliminary investigation of a mobile tool for cancer patients",
        "authors": "Maia L. Jacobs, James Clawson, Elizabeth D. Mynatt",
        "abstract": "Health information management for cancer care is a challenging and personal process that changes over time based on one's needs, goals, and health status. While technologies supporting health information management appear promising, we do not fully understand how health information tools fit into patients? daily lives. To better understand the opportunities and usage barriers of these tools, we designed and deployed a mobile, tablet-based health management aid: My Journey Compass. After one month of use, we interviewed twelve breast cancer patients to investigate their initial patterns of adoption, adaptation, use and non-use. We found that developing a tool that was customizable, mobile, and integrated into the patients' healthcare system resulted in a set of surprising uses by breast cancer patients for a wide variety of tasks. Our study demonstrates the potential for health management tools to improve the cancer care experience and for HCI research to influence existing healthcare systems.",
        "session": "SESSION: Interfaces for care and support"
    },
    {
        "title": "An assistive robotic table for older and post-stroke adults: results from participatory design and evaluation activities with clinical staff",
        "authors": "Anthony L. Threatt, Jessica Merino, Keith Evan Green, Ian Walker, Johnell O. Brooks, Stan Healy",
        "abstract": "An inevitable new frontier for the CHI community is the development of complex, larger-scale, cyber-physical artifacts where advancements in design, computing and robotics converge. Presented here is a design exemplar: the Assistive, Robotic Table (ART), the key component of our envisioned home suite of networked, robotic furnishings for hospitals and homes, promoting wellbeing and independent living. We begin with the motivations for ART, and present our iterative, five-phase, participatory design-and-evaluation process involving clinicians at a rehabilitation hospital, focusing here on the final usability study. From our wide-ranging design-research activities, which may be characterized as research through design, we found ART to be promising but also challenging. As a design exemplar, ART offers invaluable lessons to the CHI community as it comes to design larger-scale, cyber-physical artifacts cultivating interactions across people and their surroundings that define places of social, cultural and psychological significance.",
        "session": "SESSION: Interfaces for care and support"
    },
    {
        "title": "Experience design theatre: exploring the role of live theatre in scaffolding design dialogues",
        "authors": "John Vines, Tess Denman-Cleaver, Paul Dunphy, Peter Wright, Patrick Olivier",
        "abstract": "While theatre has been used in HCI as a tool for engaging participants in design processes, the specific benefits of using live theatre over other communicative mediums, remains underexplored. In this paper we introduce Experience Design Theatre (EDT) as an approach to undertaking experience-centered design with multiple parties in the early stages of design. EDT was motivated by a need to involve several diverse groups of people in the design of a digitally coordinated care service - NetCarers. We used live theatre as a way to engage small groups of participants in dialogues around the design of NetCarers, to qualify their contributions in a refined performance, and to communicate their concerns and aspirations to domain experts. We highlight key benefits to using live theatre in experience-centered design and offer insights for researchers undertaking similar work in the future.",
        "session": "SESSION: Research through design"
    },
    {
        "title": "Non-finito products: a new design space of user creativity for personal user experience",
        "authors": "Jin-min Seok, Jong-bum Woo, Youn-kyung Lim",
        "abstract": "Conventional wisdom says that to be successful, an idea must be concrete, complete, and certain. However, what if unfinished ideas work? This CHI paper proposes a new design space we call non-finito products for the HCI community. This new design space is about intentionally unfinished products and how they foster new creations by end-users as they are actually used to help people solve their own problems. The central idea comes from the background of the growing complexity associated with IT advancement and from the new way of dealing with it, with the assistance of user creativity in the actual use of the products. This paper begins with the exploration of non-finito products as a new design space for the end-user's creativity in the personal user experience. We then defined and proposed non-finito products. We discussed three case studies that will help to understand the design space of non-finito products, and we framed the new design space by revealing the beneficial contexts and values. Finally, we suggested the implications of designing non-finito products. We believe that non-finito products will open a new design space in HCI, prompt a new means of replacing value-destroying complexity with value-creating version, and help to make a product better fit to user experience.",
        "session": "SESSION: Research through design"
    },
    {
        "title": "Research through design fiction: narrative in real and imaginary abstracts",
        "authors": "Mark Blythe",
        "abstract": "This paper reflects on the uses of prototypes in \"Research through Design\" and considers \"Design Fiction\" as a technique for exploring the potential value of new design work. It begins with an analysis of Research through Design abstracts in the ACM digital library and identifies an emerging language and structure of papers in this emerging field. The abstracts: frame a problem space, introduce a study, often involving the deployment of a prototype, and conclude with considerations, reflections and discussion. This format is then pastiched in a series of design fictions written for a project investigating new and emerging forms of reproduction in Art. The fictions take the form of \"imaginary abstracts\" which summarize findings of papers that have not been written about prototypes that do not exist. It is argued that framing concept designs as fictional studies can provide a space for research focused critique and development.",
        "session": "SESSION: Research through design"
    },
    {
        "title": "Research on research: design research at the margins: academia, industry and end-users",
        "authors": "Juri Dachtera, Dave Randall, Volker Wulf",
        "abstract": "Design research processes often take place in publicly funded projects. Besides designers and users, public funding increasingly requires industry partners to participate in such projects. We present empirical insights from a joint research project in order to assess the claims connected with such funding structures and to report on challenges for design research within them. We identify three themes of conflict between academic and industry partners and elaborate on the sources of them. The presentation of our results builds on the distinction between 'academia' and 'industry', which is frequently applied by political funding agencies. The analysis of the respective stakeholders' actual interests, however, will prove such a dichotomy to be misleading and simplistic.",
        "session": "SESSION: Research through design"
    },
    {
        "title": "Impact of form factors and input conditions on absolute indirect-touch pointing tasks",
        "authors": "Jérémie Gilliot, Géry Casiez, Nicolas Roussel",
        "abstract": "Absolute indirect interaction maps the absolute position of a device's end-effector to the absolute position of a remote on-screen object.Despite its long-time use with graphics tablets and growing use in research prototypes, little is known on the influence of form factors and input conditions on pointing performance with such a mapping. The input and display can have different sizes and aspect ratios, for example. The on-screen targets can vary in size. Users can look solely at the display or at the input device as well. They can also hold the input device in certain cases, or let it rest on a table. This paper reports on two experiments designed to investigate the influence of all these factors on absolute indirect-touch pointing performance. We also provide design guidelines for interaction in these situations based on the observed impacting factors.",
        "session": "SESSION: Pointing and cursors"
    },
    {
        "title": "Beating the bubble: using kinematic triggering in the bubble lens for acquiring small, dense targets",
        "authors": "Martez E. Mott, Jacob O. Wobbrock",
        "abstract": "We present the Bubble Lens, a new target acquisition technique that remedies the limitations of the Bubble Cursor to increase the speed and accuracy of acquiring small, dense targets--precisely those targets for which the Bubble Cursor degenerates to a point cursor. When targets are large and sparse, the Bubble Lens behaves like the Bubble Cursor. But when targets are small and dense, the Bubble Lens automatically magnifies nearby targets, making them larger in both visual- and motor-space. Importantly, magnification is not governed by an explicit user-invoked mode-switch. Rather, magnification is activated through kinematic triggering, a technique that continuously examines an unfolding velocity profile to automatically trigger mode changes based on observed features. In a first study, we found the Bubble Cursor performed poorly when targets had an effective size smaller than 10 pixels. Using this threshold for the Bubble Lens in a second study, we found that the Bubble Lens significantly outperformed the Bubble Cursor, decreasing movement time by 10.2% and error rates by 37.9%, making the Bubble Lens the fastest current pointing technique.",
        "session": "SESSION: Pointing and cursors"
    },
    {
        "title": "Mouse pointing endpoint prediction using kinematic template matching",
        "authors": "Phillip T. Pasqual, Jacob O. Wobbrock",
        "abstract": "We present a new method of predicting the endpoints of mouse movements. While prior approaches to endpoint prediction have relied upon normative kinematic laws, regression, or control theory, our approach is straightforward but kinematically rich. Our key insight is to regard the unfolding velocity profile of a pointing movement as a 2-D stroke gesture and to use template matching to predict the endpoint based on prior observed movements. We call our technique kinematic template matching (KTM), which is simple to implement, user-adaptable, and kinematically expressive. In a study of 17 able-bodied participants evaluated over movement amplitudes ranging from 100-800 pixels, we found KTM to predict endpoints that were within 83 pixels of the true endpoint at 50% of the way through the movement, within 48 pixels at 75%, and within 39 pixels at 90%, using 1000 templates per participant. These accuracies make KTM as successful an approach to endpoint prediction as any prior technique, while being easier to implement and understand than most.",
        "session": "SESSION: Pointing and cursors"
    },
    {
        "title": "The implicit fan cursor: a velocity dependent area cursor",
        "authors": "Xiaojun Su, Oscar Kin-Chung Au, Rynson W.H. Lau",
        "abstract": "We present the Implicit Fan Cursor (IFC) - a novel target pointing technique using a cursor with a fan-shape activation area. The IFC couples the cursor's activation area with its velocity, i.e., the speed and direction of the mouse motion, behaving like a 2D spotlight cursor at low speed and a circular area cursor at high speed. Thus, it enables the user to precisely acquire distant targets at low speed and easily acquire nearest targets at high speed, without explicit mode switching. This technique minimizes cursor movement, while taking into consideration of the precision of cursor movement at different speeds. It also ensures that only one target is captured at any time. The results of our controlled experiments show that the IFC outperforms the point cursor and the area cursor techniques, particularly in terms of cursor moving distance, and that its performance can be accurately modeled using the Fitts' law.",
        "session": "SESSION: Pointing and cursors"
    },
    {
        "title": "The product of availability: understanding the economic underpinnings of constant connectivity",
        "authors": "Melissa Mazmanian, Ingrid Erickson",
        "abstract": "Constant connectivity and total availability to clients is the rule rather than the exception in many contemporary workplaces. Enabled by developments in information and communication technologies (ICTs), total availability of employees is possible and presumed. Scholars have explored how new technological affordances, cultural shifts, individual personality traits, and/or the development of social expectations that reinforce norms of constant connectivity have led to this state of affairs. We argue that a key factor has been overlooked in current scholarship about stress, intensive work, and constant connectivity. That is, current economic conditions are creating a marketplace in which firms increasing sell the availability of their employees as part of the services offered by the firm. In this paper we use qualitative data to illustrate how total availability is an integral aspect of the 'product' offered by professional service firms and is becoming increasingly prevalent in other service industries. We conclude with a discussion of how the HCI community might address this situation as a design challenge. Drawing on the work of Goffman and Perlow, we suggest that designers attend to the ways in which organizations might maintain front stage impressions of total availability while collectively managing individual time to restrict total availability behind the scenes.",
        "session": "SESSION: Always connected: email and social media"
    },
    {
        "title": "Giving up Twitter for Lent: how and why we take breaks from social media",
        "authors": "Sarita Yardi Schoenebeck",
        "abstract": "Social media use is widespread, but many people worry about overuse. This paper explores how and why people take breaks from social media. Using a mixed methods approach, we pair data from users who tweeted about giving up Twitter for Lent with an interview study of social media users. We find that 64% of users who proclaim that they are giving up Twitter for Lent successfully do so. Among those who fail, 31% acknowledge their failure; the other 69% simply return. We observe hedging patterns (e.g. \"I thought about giving up Twitter for Lent but\"?) that surfaced uncertainty about social media behavior. Interview participants were concerned about the tradeoffs of spending time on social media versus doing other things and of spending time on social media rather than in \"real life.\" We discuss gaps in related theory that might help reduce users' anxieties and open design problems related to designing systems and services that can help users manage their own social media use.",
        "session": "SESSION: Always connected: email and social media"
    },
    {
        "title": "MinEMail: SMS alert system for managing critical emails",
        "authors": "Kyle Rector, Joshua Hailpern",
        "abstract": "Email is the primary method of digital communication for most people, but the overwhelming quantity has led to a poverty of attention. Existing manual and automatic solutions that aim to save important emails from falling through the cracks have begun to address this problem, but may increase user workload, sacrifice efficiency, or fail to identify high value communications. In response, we developed MinEMail, an alert system that uses a text message (SMS) to remind and notify users of critical emails that may have been missed or forgotten. MinEMail provides an alert infrastructure as well as accurately labeling and predicting which emails are critical, and when and how they need to be addressed. To motivate our system, we also present an up-front study with 777 participants that aims to understand the state and limitations of email and SMS in enterprise. We conduct an experience sampling study of over 3000 emails in order to construct MinEMail's predictive models. Finally, we present the results from a 15 user ecologically valid real-world deployment of MinEMail in enterprise.",
        "session": "SESSION: Always connected: email and social media"
    },
    {
        "title": "Overload is overloaded: email in the age of Gmail",
        "authors": "Catherine Grevet, David Choi, Debra Kumar, Eric Gilbert",
        "abstract": "The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Google's Gmail. We find that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) updating the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research.",
        "session": "SESSION: Always connected: email and social media"
    },
    {
        "title": "Practical trigger-action programming in the smart home",
        "authors": "Blase Ur, Elyse McManus, Melwyn Pak Yong Ho, Michael L. Littman",
        "abstract": "We investigate the practicality of letting average users customize smart-home devices using trigger-action (\"if, then\") programming. We find trigger-action programming can express most desired behaviors submitted by participants in an online study. We identify a class of triggers requiring machine learning that has received little attention. We evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com, finding that real users have written a large number of unique trigger-action interactions. Finally, we conduct a 226-participant usability test of trigger-action programming, finding that inexperienced users can quickly learn to create programs containing multiple triggers or actions.",
        "session": "SESSION: Smart homes and sustainability"
    },
    {
        "title": "Doing the laundry with agents: a field trial of a future smart energy system in the home",
        "authors": "Enrico Costanza, Joel E. Fischer, James A. Colley, Tom Rodden, Sarvapali D. Ramchurn, Nicholas R. Jennings",
        "abstract": "Future energy systems that rely on renewable energy may bring about a radical shift in how we use energy in our homes. We developed and prototyped a future scenario with highly variable, real-time electricity prices due to a grid that mainly relies on renewables. We designed and deployed an agent-based interactive system that enables users to effectively operate the washing machine in this scenario. The system is used to book timeslots of washing machine use so that the agent can help to minimize the cost of a wash by charging a battery at times when electricity is cheap. We carried out a deployment in 10 households in order to uncover the socio-technical challenges around integrating new technologies into everyday routines. The findings reveal tensions that arise when deploying a rationalistic system to manage contingently and socially organized domestic practices. We discuss the trade-offs between utility and convenience inherent in smart grid applications; and illustrate how certain design choices position applications along this spectrum.",
        "session": "SESSION: Smart homes and sustainability"
    },
    {
        "title": "Making sustainability sustainable: challenges in the design of eco-interaction technologies",
        "authors": "Rayoung Yang, Mark W. Newman, Jodi Forlizzi",
        "abstract": "The smart home is here. One area where smart home devices promise to deliver great benefits is in the control of home heating, ventilation, and cooling (HVAC) systems. In this paper, we seek to inform the design of future heating and cooling systems by investigating users' experiences with the Nest Learning Thermostat, a commercially available smart home device. We conducted a qualitative study where we compared people's interactions with conventional thermostats with interactions with the Nest. A key finding was that the Nest impacted users' pattern of HVAC control, but only for a while, and caused new problems in unrealized energy savings. In leveraging these findings, we create a set of design implications for Eco-Interaction, the design of features and human-system interactions with the goal of saving energy.",
        "session": "SESSION: Smart homes and sustainability"
    },
    {
        "title": "Global connectivity and multilinguals in the Twitter network",
        "authors": "Scott A. Hale",
        "abstract": "This article analyzes the global connectivity of the Twitter retweet and mentions network and the role of multilingual users engaging with content in multiple languages. The network is heavily structured by language with most mentions and retweets directed to users writing in the same language. Users writing in multiple languages are more active, authoring more tweets than monolingual users. These multilingual users play an important bridging role in the global connectivity of the network. The mean level of insularity from speakers in each language does not correlate straightforwardly with the size of the user base as predicted by previous research. Finally, the English language does play more of a bridging role than other languages, but the role played collectively by multilingual users across different languages is the largest bridging force in the network.",
        "session": "SESSION: Multilingual communication"
    },
    {
        "title": "Effects of public vs. private automated transcripts on multiparty communication between native and non-native english speakers",
        "authors": "Ge Gao, Naomi Yamashita, Ari MJ Hautasaari, Andy Echenique, Susan R. Fussell",
        "abstract": "Real-time transcripts generated by automated speech recognition (ASR) technologies have the potential to facilitate communication between native speakers (NS) and non-native speakers (NNS). Previous studies of ASR have focused on how transcripts aid NNS speech comprehension. In this study, we examine whether transcripts benefit multiparty real-time conversation between NS and NNS. We hypothesized that ASR transcripts would be more beneficial when the transcripts were publicly shared by all group members as opposed to when they were seen only by the NNS. To test our hypothesis, we conducted a lab experiment in which 14 groups of native and non-native speakers engaged in a story-telling task. Half of the groups received private transcripts that were available only to the NNS; the other half received publicly shared transcripts that were available to all group members. NS spoke more clearly, and both NS and NNS rated the quality of communication higher, when transcripts were publicly shared. These findings inform the design of future tools to support multilingual group communication.",
        "session": "SESSION: Multilingual communication"
    },
    {
        "title": "Smart subtitles for vocabulary learning",
        "authors": "Geza Kovacs, Robert C. Miller",
        "abstract": "Language learners often use subtitled videos to help them learn. However, standard subtitles are geared more towards comprehension than vocabulary learning, as translations are nonliteral and are provided only for phrases, not vocabulary. This paper presents Smart Subtitles, which are interactive subtitles tailored towards vocabulary learning. Smart Subtitles can be automatically generated from common video sources such as subtitled DVDs. They provide features such as vocabulary definitions on hover, and dialog-based video navigation. In our pilot study with intermediate learners studying Chinese, participants correctly defined over twice as many new words in a post-viewing vocabulary test when they used Smart Subtitles, compared to dual Chinese-English subtitles. Learners spent the same amount of time watching clips with each tool, and enjoyed viewing videos with Smart Subtitles as much as with dual subtitles. Learners understood videos equally well using either tool, as indicated by self-assessments and independent evaluations of their summaries.",
        "session": "SESSION: Multilingual communication"
    },
    {
        "title": "Using annotations in online group chats",
        "authors": "Na Li, Mary Beth Rosson",
        "abstract": "Annotating documents has long been a widely used strategy for distilling important contents and externalizing related thoughts and ideas in context. No one has studied the activity of annotating dynamic texts, such as online chat, although online conversation is an important communication media for global companies. In this paper, we investigate Instant Annotation (IA), a real-time annotation-enhanced chat tool. We contrast the use of the enhanced chat tool to a standard chat tool for multilingual groups doing a brainstorming and decision-making task. Results show that group satisfaction and perceived control of the conversation are enhanced for the participants who used IA. We also report new patterns of annotation use and discuss design implications for group chat tools.",
        "session": "SESSION: Multilingual communication"
    },
    {
        "title": "Visualizing dynamic networks with matrix cubes",
        "authors": "Benjamin Bach, Emmanuel Pietriga, Jean-Daniel Fekete",
        "abstract": "Designing visualizations of dynamic networks is challenging, both because the data sets tend to be complex and because the tasks associated with them are often cognitively demand- ing. We introduce the Matrix Cube, a novel visual representation and navigation model for dynamic networks, inspired by the way people comprehend and manipulate physical cubes. Users can change their perspective on the data by rotating or decomposing the 3D cube. These manipulations can produce a range of different 2D visualizations that emphasize specific aspects of the dynamic network suited to particular analysis tasks. We describe Matrix Cubes and the interactions that can be performed on them in the Cubix system. We then show how two domain experts, an astronomer and a neurologist, used Cubix to explore and report on their own network data.",
        "session": "SESSION: Interactive visualization and visual elements"
    },
    {
        "title": "A table!: improving temporal navigation in soccer ranking tables",
        "authors": "Charles Perin, Romain Vuillemot, Jean-Daniel Fekete",
        "abstract": "This article introduces A Table!, an enhanced soccer ranking table providing temporal navigation by combining two novel interaction techniques. Ranking tables order soccer teams represented as rows, according to values of columns containing attributes e.g., accumulated points, or number of scored goals. Because they represent a snapshot of a championship at a time t, tables are regularly updated with new results. Such updates usually change the rows order, which makes the tracking of a specified team over time difficult. We observed that the tables available on the web do not support tracking such changes very well, are generally hard to read, and lack interactions. This contrasts with the extensive use of comments on temporal trends found in soccer analysts articles. To better support such analyzes, the two interactive techniques presented allow exploration of time, and are designed to preserve users' flow: DRAG-CELL is based on direct manipulation of values to browse ranks; VIZ-RANK uses a transient line chart of team ranks to visually explore a championship. An on-line evaluation with 143 participants shows that each technique efficiently supports a set of important temporal tasks not supported by current ranking tables. This paves the way for introducing efficient advanced visual exploration techniques to millions of soccer enthusiasts who use tables everyday.",
        "session": "SESSION: Interactive visualization and visual elements"
    },
    {
        "title": "Kinetica: naturalistic multi-touch data visualization",
        "authors": "Jeffrey M. Rzeszotarski, Aniket Kittur",
        "abstract": "Over the last several years there has been an explosion of powerful, affordable, multi-touch devices. This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry. In this paper we describe an approach for multivariate data visualization that uses physics-based affordances that are easy to intuit, constraints that are easy to apply and visualize, and a consistent view as data is manipulated in order to promote data exploration and interrogation. We provide a framework for exploring this problem space, and an example proof of concept system called Kinetica. We describe the results of a user study that suggest users of Kinetica were able to explore multiple dimensions of data at once, identify outliers, and discover trends with minimal training.",
        "session": "SESSION: Interactive visualization and visual elements"
    },
    {
        "title": "Traffigram: distortion for clarification via isochronal cartography",
        "authors": "Sungsoo (Ray) Hong, Yea-Seul Kim, Jong-Chul Yoon, Cecilia R. Aragon",
        "abstract": "Most geographic maps visually represent physical distance; however, travel time can in some cases be more important than distance because it directly indicates availability. The technique of creating maps from temporal data is known as isochronal cartography, and is a form of distortion for clarification. In an isochronal map, congestion expands areas, while ideal travel conditions make the map shrink in comparison to the actual distance scale of a traditional map. Although there have been many applications of this technique, detailed user studies of its efficacy remain scarce, and there are conflicting views on its practical value. To attempt to settle this issue, we utilized a user-centered design process to determine which features of isochronal cartography might be most usable in practice. We developed an interactive cartographic visualization system, Traffigram, that features a novel combination of efficient isochronal map algorithms and an interface designed to give map users a quick and seamless experience while preserving geospatial integrity and aesthetics. We validated our design choices with multiple usability studies. We present our results and discuss implications for design.",
        "session": "SESSION: Interactive visualization and visual elements"
    },
    {
        "title": "Understanding procedural content generation: a design-centric analysis of the role of PCG in games",
        "authors": "Gillian Smith",
        "abstract": "Games that use procedural content generation (PCG) do so in a wide variety of ways and for different reasons. One of the most common reasons cited by PCG system creators and game designers is improving replayability by providing a means for automatically creating near-infinite amounts of content, the player can come back and replay the game and refine her strategies over a long period. However, this notion of replayability is both overly broad and incomplete as a motivation. This paper contributes an analytical framework and associated common vocabulary for understanding the role of PCG in games from a design standpoint, with an aim of unpacking some of the broad justifications for PCG use in games, and bringing together technical concerns in designing PCG systems with design concerns related to creating engaging playable experiences.",
        "session": "SESSION: Understanding and designing games"
    },
    {
        "title": "A systematic review of quantitative studies on the enjoyment of digital entertainment games",
        "authors": "Elisa D. Mekler, Julia Ayumi Bopp, Alexandre N. Tuch, Klaus Opwis",
        "abstract": "Enjoyment has been identified as a central component of the player experience (PX), but various, overlapping concepts within PX make it difficult to develop valid measures and a common understanding of game enjoyment. We conducted a systematic review of 87 quantitative studies, analyzing different operationalizations and measures of game enjoyment, its determinants, and how these were related to other components of PX, such as flow, presence and immersion. Results suggest that game enjoyment describes the positive cognitive and affective appraisal of the game experience, and may in part be associated with the support of player needs and values. Further, we outline that enjoyment is distinct from flow in that it may occur independently of challenge and cognitive involvement, and argue that enjoyment may be understood as the valence of the player experience. We conclude with a discussion of methodological challenges and point out opportunities for future research on game enjoyment.",
        "session": "SESSION: Understanding and designing games"
    },
    {
        "title": "The effectiveness (or lack thereof) of aim-assist techniques in first-person shooter games",
        "authors": "Rodrigo Vicencio-Moreira, Regan L. Mandryk, Carl Gutwin, Scott Bateman",
        "abstract": "Aim-assistance techniques have been shown to work for player balancing in 2D environments, but little information exists about how well these techniques will work in a 3D FPS game. We carried out three studies of the performance of five different aim assists in an Unreal-based game world. The assists worked well in a target-range scenario (study 1), but their performance was reduced when game elements were introduced in a walkthrough map (study 2). We systematically examined the relationships between realistic game elements and assist performance (study 3). These studies show that two techniques -- bullet magnetism and area cursor -- worked well in a wide variety of situations. Other techniques that worked well were too perceptible, and some previously-successful techniques did not work well in any game-like scenario. Our studies are the first to provide empirical evidence of the performance of aim assist techniques in 3D environments, and the first to identify the complexities in using these techniques in real FPS games.",
        "session": "SESSION: Understanding and designing games"
    },
    {
        "title": "Design tactics for authentic interactive fiction: insights from alternate reality game designers",
        "authors": "Elizabeth Bonsignore, Vicki Moulder, Carman Neustaedter, Derek Hansen, Kari Kraus, Allison Druin",
        "abstract": "This paper presents insights from designers of Alternate Reality Games (ARGs) regarding the design tactics they employ to integrate participatory storytelling and \"authentic fiction\" into the transmedia experiences they create. Our approach was motivated by recent efforts in HCI to more closely align the development of interaction design theory to the craft knowledge and experiences of designers themselves. The resulting insights enhance our understanding of design approaches that a diverse group of ARG producers follow to create interactive, participatory narratives. We outline narrative-specific themes to support designers who craft similar interactive experiences.",
        "session": "SESSION: Understanding and designing games"
    },
    {
        "title": "Jump and shoot!: prioritizing primary and alternative body gestures for intense gameplay",
        "authors": "Chaklam Silpasuwanchai, Xiangshi Ren",
        "abstract": "Motion gestures enable natural and intuitive input in video games. However, game gestures designed by developers may not always be the optimal gestures for players. A key challenge in designing appropriate game gestures lies in the interaction-intensive nature of video games, i.e., several actions/commands may need to be executed concurrently using different body parts. This study analyzes user preferences in game gestures, with the aim of accommodating high interactivity during gameplay. Two user-elicitation studies were conducted: first, to determine user preferences, participants were asked to define gestures for common game actions/commands; second, to develop effective combined-gestures, participants were asked to define possible game gestures using each body part (one and two hands, one and two legs, head, eyes, and torso). Our study presents a set of suitable and alternative body parts for common game actions/commands. We also present some simultaneously applied game gestures that assist interaction in highly interactive game situations (e.g., selecting a weapon with the feet while shooting with the hand). Interesting design implications are further discussed, e.g., transferability between hand and leg gestures.",
        "session": "SESSION: Understanding and designing games"
    },
    {
        "title": "KnowMe and ShareMe: understanding automatically discovered personality traits from social media and user sharing preferences",
        "authors": "Liang Gou, Michelle X. Zhou, Huahai Yang",
        "abstract": "There is much recent work on using the digital footprints left by people on social media to predict personal traits and gain a deeper understanding of individuals. Due to the veracity of social media, imperfections in prediction algorithms, and the sensitive nature of one's personal traits, much research is still needed to better understand the effectiveness of this line of work, including users' preferences of sharing their computationally derived traits. In this paper, we report a two- part study involving 256 participants, which (1) examines the feasibility and effectiveness of automatically deriving three types of personality traits from Twitter, including Big 5 personality, basic human values, and fundamental needs, and (2) investigates users' opinions of using and sharing these traits. Our findings show there is a potential feasibility of automatically deriving one's personality traits from social media with various factors impacting the accuracy of models. The results also indicate over 61.5% users are willing to share their derived traits in the workplace and that a number of factors significantly influence their sharing preferences. Since our findings demonstrate the feasibility of automatically inferring a user's personal traits from social media, we discuss their implications for designing a new generation of privacy-preserving, hyper-personalized systems.",
        "session": "SESSION: Personal values and preferences"
    },
    {
        "title": "Faces engage us: photos with faces attract more likes and comments on Instagram",
        "authors": "Saeideh Bakhshi, David A. Shamma, Eric Gilbert",
        "abstract": "Photos are becoming prominent means of communication online. Despite photos' pervasive presence in social media and online world, we know little about how people interact and engage with their content. Understanding how photo content might signify engagement, can impact both science and design, influencing production and distribution. One common type of photo content that is shared on social media, is the photos of people. From studies of offline behavior, we know that human faces are powerful channels of non-verbal communication. In this paper, we study this behavioral phenomena online. We ask how presence of a face, it's age and gender might impact social engagement on the photo. We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors, likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to receive comments, even after controlling for social network reach and activity. We find, however, that the number of faces, their age and gender do not have an effect. This work presents the first results on how photos with human faces relate to engagement on large scale image sharing communities. In addition to contributing to the research around online user behavior, our findings offer a new line of future work using visual analysis.",
        "session": "SESSION: Personal values and preferences"
    },
    {
        "title": "Photo sharing of the subject, by the owner, for the viewer: examining the subject's preference",
        "authors": "Auk Kim, Gahgene Gweon",
        "abstract": "Photo sharing activities on social networking sites concern not only the person sharing the information (owner) and the person receiving the information (viewer) but also the person who is in the photo (subject). In our exploratory lab study, we asked 29 participants about their comfort level in allowing a photo owner to share a picture containing both the participant (subject) and the owner. Our results show that the photo subject feels more comfortable in sharing a photo when i) the \"closeness between the subject and the owner (SO closeness)\" is higher, and ii) the \"closeness between the subject and the viewer (SV closeness)\" is higher. In addition, we observed that both SV and SO closeness are important in determining the subject's picture sharing preference level.",
        "session": "SESSION: Personal values and preferences"
    },
    {
        "title": "Does content determine information popularity in social media?: a case study of youtube videos' content and their popularity",
        "authors": "Flavio Figueiredo, Jussara M. Almeida, Fabrício Benevenuto, Krishna P. Gummadi",
        "abstract": "We here investigate what drives the popularity of information on social media platforms. Focusing on YouTube, we seek to understand the extent to which content by itself determines a video's popularity. Using mechanical turk as experimental platform, we asked users to evaluate pairs of videos, and compared users' relative perception of the videos' content against their relative popularity reported by YouTube. We found that in most evaluations users could not reach consensus on which video had better content as their perceptions tend to be very subjective. Nevertheless, when consensus was reached, the video with preferred content almost always achieved greater popularity on YouTube, highlighting the importance of content in driving information popularity on social media.",
        "session": "SESSION: Personal values and preferences"
    },
    {
        "title": "You read what you value: understanding personal values and reading interests",
        "authors": "Gary Hsieh, Jilin Chen, Jalal U. Mahmud, Jeffrey Nichols",
        "abstract": "This paper presents an experiment on the relationship between personal values and reading interests of online articles. Results suggest that individuals' values can predict their topical interests. For example, holding stronger universalism values predict interests towards environmental articles, whereas holding stronger achievement values predict interest towards work-related articles. Findings demonstrate the possibility of targeting based on individuals' personal values, but also highlight certain challenges and limitations when applying this approach for online content.",
        "session": "SESSION: Personal values and preferences"
    },
    {
        "title": "Gaining empathy for non-routine mobile device use through autoethnography",
        "authors": "Aisling Ann O'Kane, Yvonne Rogers, Ann E. Blandford",
        "abstract": "In this paper, we report on autoethnography as a method to access non-routine usage of mobile devices, such as during business trips, vacations, etc. Autoethnography, a self-study method with the researcher as participant, was employed for the evaluation of a wrist blood pressure monitor used by people with conditions such as hypertension. The findings from the study were surprising, especially with respect to the environmental and social impact on the use of the technology. Although the autoethnographic method can be disruptive for the researcher, it enables them to understand and empathize with the experiences mobile device users can face in difficult to access contexts. This method allows HCI researchers to better understand user experiences with mobile devices, including mobile medical technology, especially during non-routine times that can be difficult to study in-situ with traditional user studies.",
        "session": "SESSION: Personal values and preferences"
    },
    {
        "title": "Designing for movement: evaluating computational models using LMA effort qualities",
        "authors": "Diego Silang Maranan, Sarah Fdili Alaoui, Thecla Schiphorst, Philippe Pasquier, Pattarawut Subyen, Lyn Bartram",
        "abstract": "While single-accelerometers are a common consumer embedded sensors, their use in representing movement data as an intelligent resource remains scarce. Accelerometers have been used in movement recognition systems, but rarely to assess expressive qualities of movement. We present a prototype of wearable system for the real-time detection and classification of movement quality using acceleration data. The system applies Laban Movement Analysis (LMA) to recognize Laban Effort qualities from acceleration input using a Machine Learning software that generates classifications in real time. Existing LMA-recognition systems rely on motion capture data and video data, and can only be deployed in controlled settings. Our single-accelerometer system is portable and can be used under a wide range of environmental conditions. We evaluate the performance of the system, present two applications using the system in the digital arts and discuss future directions.",
        "session": "SESSION: Enabling interactive performances"
    },
    {
        "title": "The vocal chorder: empowering opera singers with a large interactive instrument",
        "authors": "Carl Unander-Scharin, Åsa Unander-Scharin, Kristina Höök",
        "abstract": "With The Vocal Chorder, a large interactive instrument to create accompaniment, opera singers can get more power over the performance. The device allows performers to interactively accompany themselves through pushing, leaning on and bending steel wires. The design was guided by the unique needs of the solo-singer, explored through autobiographical design and material explorations, some on stage, and later tested by other singers. We discuss how designing for opera and for the stage requires extraordinary durability and how opera performances can change with a bodily-oriented instrument such as The Vocal Chorder. Through a designerly exploration, we arrived at a device that offered (1) a tool for singers to take control over the rhythmical pace and overall artistic and aesthetic outcome of their performances, (2) an enriched sense of embodiment between their voice and the overall performance; and (3) a means to empower opera singers on stage.",
        "session": "SESSION: Enabling interactive performances"
    },
    {
        "title": "Let me catch this!: experiencing interactive 3D cinema through collecting content with a mobile phone",
        "authors": "Jonna R. Häkkilä, Maaret Posti, Stefan Schneegass, Florian Alt, Kunter Gultekin, Albrecht Schmidt",
        "abstract": "The entertainment industry is going through a transformation, and technology development is affecting how we can enjoy and interact with the entertainment media content in new ways. In our work, we explore how to enable interaction with content in the context of 3D cinemas. This allows viewers to use their mobile phone to retrieve, for example, information on the artist of the soundtrack currently playing or a discount coupon on the watch the main actor is wearing. We are particularly interested in the user experience of the interactive 3D cinema concept, and how different interactive elements and interaction techniques are perceived. We report on the development of a prototype application utilizing smart phones and on an evaluation in a cinema context with 20 participants. Results emphasize that designing for interactive cinema experiences should drive for holistic and positive user experiences. Interactive content should be tied together with the actual video content, but integrated into contexts where it does not conflict with the immersive experience with the movie.",
        "session": "SESSION: Enabling interactive performances"
    },
    {
        "title": "Coding livecoding",
        "authors": "Ben Swift, Andrew Sorensen, Michael Martin, Henry Gardner",
        "abstract": "Livecoding is an artistic programming practice in which an artist's low-level interaction can be observed with sufficiently high fidelity to allow for transcription and analysis. This paper presents the first reported \"coding\" of livecoding videos. From an identified corpus of videos available on the web, we coded performances of two different livecoding artists, recording both the (textual) programming edit events and the musical effect of these edits. Our analysis includes a novel, transition-matrix visualisation of the textual and musical dimensions of this data to create a \"performer fingerprint\". We show how detailed transcriptions of livecoding videos can be made which, we hope, will provide a foundation for further research into describing and understanding livecoding.",
        "session": "SESSION: Enabling interactive performances"
    },
    {
        "title": "Exploring percussive gesture on iPads with ensemble metatone",
        "authors": "Charles Martin, Henry Gardner, Ben Swift",
        "abstract": "Percussionists are unique among western classical instrumentalists in that their artistic practice is defined by an approach to interaction rather than their instruments. While percussionists are accustomed to exploring non-traditional objects to create music, these objects have yet to encompass touch-screen computing devices to any great extent. The proliferation and popularity of these devices now presents an opportunity to explore their use in combining computer-generated sound together with percussive interaction in a musical ensemble. This paper examines Ensemble Metatone, a group formed to explore the \"infiltration\" of iPad-based musical instruments into a free-improvisation percussion ensemble. We discuss the design approach for two different iPad percussion instruments and the methodology for exploring them with the group over a series of rehearsals and performances. Qualitative analysis of discussions throughout this process shows that the musicians developed a vocabulary of gestures and musical interactions to make musical sense of these new instruments.",
        "session": "SESSION: Enabling interactive performances"
    },
    {
        "title": "How carat affects user behavior: implications for mobile battery awareness applications",
        "authors": "Kumaripaba Athukorala, Eemil Lagerspetz, Maria von Kügelgen, Antti Jylhä, Adam J. Oliner, Sasu Tarkoma, Giulio Jacucci",
        "abstract": "Mobile devices have limited battery life, and numerous battery management applications are available that aim to improve it. This paper examines a large-scale mobile battery awareness application, called Carat, to see how it changes user behavior with long-term use. We conducted a survey of current Carat Android users and analyzed their interaction logs. The results show that long-term Carat users save more battery, charge their devices less often, learn to manage their battery with less help from Carat, have a better understanding of how Carat works, and may enjoy competing against other users. Based on these findings, we propose a set of guidelines for mobile battery awareness applications: battery awareness applications should make the reasoning behind their recommendations understandable to the user, be tailored to retain long-term users, take the audience into account when formulating feedback, and distinguish third-party and system applications.",
        "session": "SESSION: Battery life and energy harvesting"
    },
    {
        "title": "EnergyBugs: energy harvesting wearables for children",
        "authors": "Kimiko Ryokai, Peiqi Su, Eungchan Kim, Bob Rollins",
        "abstract": "EnergyBugs are energy harvesting wearables with features that invite children to move their bodies to generate tiny, yet usable amounts of electricity. EnergyBugs not only convert children's kinetic energy into usable electrical energy, but also let children power a specially designed LED lamp with the energy the children have personally harvested. EnergyBugs therefore turn the electrical energy into a tangible object that children can manipulate and think with. Two studies of EnergyBugs with 34 elementary school children have revealed that children carefully observed and negotiated the use of personally harvested energy with their classmates, as well as developed emotional connections to energy. In particular, moving their own bodies to generate energy led the children to more actively ask questions about energy from new perspectives. We report our iterative design process and discuss the implications of our results for HCI.",
        "session": "SESSION: Battery life and energy harvesting"
    },
    {
        "title": "OJAS: open source bi-directional inductive power link",
        "authors": "Jussi Mikkonen, Ramyah Gowrishankar, Miia Oksanen, Harri Raittinen, Arto Kolinummi",
        "abstract": "We present the design, development and evaluation of a bi-directional inductive power transfer circuit for prototyping purposes in the watt-range. Our device does not require any configuration and is intended for the development of wearable and tangible systems. Our approach allows a bi-directional power flow without any change in the circuit, such that the same circuit can be used for charging and discharging a battery. The contribution of this work is an enabling technology for researchers and practitioners in the fields of Wearable Electronics, Ubiquitous Computing and Human-Computer Interaction interested in exploring new interactions powered by watt-range inductive links. It enables smaller battery sizes, and therefore lighter devices, as the power can be distributed in a way that has not been feasible before. We discuss the motivations, technical details and the workshop evaluating our inductive approach.",
        "session": "SESSION: Battery life and energy harvesting"
    },
    {
        "title": "Using asymmetric cores to reduce power consumption for interactive devices with bi-stable displays",
        "authors": "Jaeyeon Kihm, François V. Guimbretière, Julia Karl, Rajit Manohar",
        "abstract": "Low power \"helper\" cores have been increasingly included on application processors to accomplish low intensity tasks such as music playing and motion sensing with minimum energy consumption. Recently, Guimbretière et al. [1] demonstrated that such helper cores can also be used to execute simple user interface tasks. We revisit this approach by implementing a similar system on an off-the-shelf application processor (TI OMAP4). Our study shows that in the case of high event rate interactions (pen inking and virtual keyboard), significant battery life gains (×1.7 and ×2.3 respectively) can be achieved with the helper core executing the interface. Having the helper core only dis-patch input events incurs a 18% penalty relative to the maximum savings rate, but allows for simplified deployment since it merely requires a change in toolkit infrastructure.",
        "session": "SESSION: Battery life and energy harvesting"
    },
    {
        "title": "Consumed endurance: a metric to quantify arm fatigue of mid-air interactions",
        "authors": "Juan David Hincapié-Ramos, Xiang Guo, Paymahn Moghadasian, Pourang Irani",
        "abstract": "Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the upper limbs, a condition casually termed as the gorilla-arm effect. Designers have often associated limitations of their mid-air interactions with arm fatigue, but do not possess a quantitative method to assess and therefore mitigate it. In this paper we propose a novel metric, Consumed Endurance (CE), derived from the biomechanical structure of the upper arm and aimed at characterizing the gorilla-arm effect. We present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based skeleton tracking system, and demonstrate that CE correlates strongly with the Borg CR10 scale of perceived exertion. We show how designers can use CE as a complementary metric for evaluating existing and designing novel mid-air interactions, including tasks with repetitive input such as mid-air text-entry. Finally, we propose a series of guidelines for the design of fatigue-efficient mid-air interfaces.",
        "session": "SESSION: Mid-air gestures"
    },
    {
        "title": "Vulture: a mid-air word-gesture keyboard",
        "authors": "Anders Markussen, Mikkel Rønne Jakobsen, Kasper Hornbæk",
        "abstract": "Word-gesture keyboards enable fast text entry by letting users draw the shape of a word on the input surface. Such keyboards have been used extensively for touch devices, but not in mid-air, even though their fluent gestural input seems well suited for this modality. We present Vulture, a word-gesture keyboard for mid-air operation. Vulture adapts touch based word-gesture algorithms to work in mid-air, projects users' movement onto the display, and uses pinch as a word delimiter. A first 10-session study suggests text-entry rates of 20.6 Words Per Minute (WPM) and finds hand-movement speed to be the primary predictor of WPM. A second study shows that with training on a few phrases, participants do 28.1 WPM, 59% of the text-entry rate of direct touch input. Participants' recall of trained gestures in mid-air was low, suggesting that visual feedback is important but also limits performance. Based on data from the studies, we discuss improvements to Vulture and some alternative designs for mid-air text entry.",
        "session": "SESSION: Mid-air gestures"
    },
    {
        "title": "Understanding finger input above desktop devices",
        "authors": "Chat Wacharamanotham, Kashyap Todi, Marty Pye, Jan Borchers",
        "abstract": "Using the space above desktop input devices adds a rich new input channel to desktop interaction. Input in this elevated layer has been previously used to modify the granularity of a 2D slider, navigate layers of a 3D body scan above a multitouch table and access vertically stacked menus. However, designing these interactions is challenging because the lack of haptic and direct visual feedback easily leads to input errors. For bare finger input, the user's fingers needs to reliably enter and stay inside the interactive layer, and engagement techniques such as midair clicking have to be disambiguated from leaving the layer. These issues have been addressed for interactions in which users operate other devices in midair, but there is little guidance for the design of bare finger input in this space. In this paper, we present the results of two user studies that inform the design of finger input above desktop devices. Our studies show that 2 cm is the minimum thickness of the above-surface volume that users can reliably remain within. We found that when accessing midair layers, users do not automatically move to the same height. To address this, we introduce a technique that dynamically determines the height at which the layer is placed, depending on the velocity profile of the user's initial finger movement into midair. Finally, we propose a technique that reliably distinguishes clicking from homing movements, based on the user's hand shape. We structure the presentation of our findings using Buxton's three-state input model, adding additional states and transitions for above-surface interactions.",
        "session": "SESSION: Mid-air gestures"
    },
    {
        "title": "Exploring the usefulness of finger-based 3D gesture menu selection",
        "authors": "Arun Kulshreshth, Joseph J. LaViola, Jr.",
        "abstract": "Counting using one's fingers is a potentially intuitive way to enumerate a list of items and lends itself naturally to gesture-based menu systems. In this paper, we present the results of the first comprehensive study on Finger-Count menus to investigate its usefulness as a viable option for 3D menu selection tasks. Our study compares 3D gesture-based finger counting (Finger Count menus) with two gesture-based menu selection techniques (Hand-n-Hold, Thumbs-Up), derived from existing motion-controlled video game menu selection strategies, as well as 3D Marking menus. We examined selection time, selection accuracy and user preference for all techniques. We also examined the impact of different spatial layouts for menu items and different menu depths. Our results indicate that Finger-Count menus are significantly faster than the other menu techniques we tested and are the most liked by participants. Additionally, we found that while Finger-Count menus and 3D Marking menus have similar selection accuracy, Finger-Count menus are almost twice as fast compared to 3D Marking menus.",
        "session": "SESSION: Mid-air gestures"
    },
    {
        "title": "In the blink of an eye: investigating latency perception during stylus interaction",
        "authors": "Albert Ng, Michelle Annett, Paul Dietz, Anoop Gupta, Walter F. Bischof",
        "abstract": "While pen computing has become increasingly more popular, device responsiveness, or latency, still plagues such interaction. Although there have been advances in digitizer technology over the last few years, commercial end-to-end latencies are unfortunately similar to those found with touchscreens, i.e., 65 - 120 milliseconds. We report on a prototype stylus-enabled device, the High Performance Stylus System (HPSS), designed to display latencies as low as one millisecond while users ink or perform dragging tasks. To understand the role of latency while inking with a stylus, psychophysical just-noticeable difference experiments were conducted using the HPSS. While participants performed dragging and scribbling tasks, very low levels of latency could be discriminated, i.e., ~1 versus 2 milliseconds while dragging and ~7 versus 40 milliseconds while scribbling. The HPSS and our experimentation have provided further motivation for the implementation of latency saving measures in pen-based hardware and software systems.",
        "session": "SESSION: Touch and stylus interaction"
    },
    {
        "title": "Pinch-drag-flick vs. spatial input: rethinking zoom & pan on mobile displays",
        "authors": "Martin Spindler, Martin Schuessler, Marcel Martsch, Raimund Dachselt",
        "abstract": "The multi-touch-based pinch to zoom, drag and flick to pan metaphor has gained wide popularity on mobile displays, where it is the paradigm of choice for navigating 2D documents. But is finger-based navigation really the gold standard' In this paper, we present a comprehensive user study with 40 participants, in which we systematically compared the Pinch-Drag-Flick approach with a technique that relies on spatial manipulation, such as lifting a display up/down to zoom. While we solely considered known techniques, we put considerable effort in implementing both input strategies on popular consumer hardware (iPhone, iPad). Our results show that spatial manipulation can significantly outperform traditional Pinch-Drag-Flick. Given the carefully optimized prototypes, we are confident to have found strong arguments that future generations of mobile devices could rely much more on spatial interaction principles.",
        "session": "SESSION: Touch and stylus interaction"
    },
    {
        "title": "InkAnchor: enhancing informal ink-based note taking on touchscreen mobile phones",
        "authors": "Yi Ren, Yang Li, Edward Lank",
        "abstract": "Although touchscreen mobile phones are widely used for recording informal text notes (e.g., grocery lists, reminders and directions), the lack of efficient mechanisms for combining informal graphical content with text is a persistent challenge. In this paper, we present InkAnchor, a digital ink editor that allows users to easily create ink-based notes by finger drawing and writing on a mobile phone touchscreen. InkAnchor incorporates flexible anchoring, focus-plus-context input, content chunking, and lightweight editing mechanisms to support the capture of informal notes and annotations. We describe the design and evaluation of InkAnchor through a series of user studies, which revealed that the integrated support enabled by InkAnchor is a significant improvement over current mobile note taking applications on a range of mobile note-taking tasks.",
        "session": "SESSION: Touch and stylus interaction"
    },
    {
        "title": "Perception of ultrasonic haptic feedback on the hand: localisation and apparent motion",
        "authors": "Graham Wilson, Thomas Carter, Sriram Subramanian, Stephen A. Brewster",
        "abstract": "Ultrasonic haptic feedback is a promising means of providing tactile sensations in mid-air without encumbering the user with an actuator. However, controlled and rigorous HCI research is needed to understand the basic characteristics of perception of this new feedback medium, and so how best to utilise ultrasonic haptics in an interface. This paper describes two experiments conducted into two fundamental aspects of ultrasonic haptic perception: 1) localisation of a static point and 2) the perception of motion. Understanding these would provide insight into 1) the spatial resolution of an ultrasonic interface and 2) what forms of feedback give the most convincing illusion of movement. Results show an average localisation error of 8.5mm, with higher error along the longitudinal axis. Convincing sensations of motion were produced when travelling longer distances, using longer stimulus durations and stimulating multiple points along the trajectory. Guidelines for feedback design are given.",
        "session": "SESSION: Touch and stylus interaction"
    },
    {
        "title": "Understanding quantified-selfers' practices in collecting and exploring personal data",
        "authors": "Eun Kyoung Choe, Nicole B. Lee, Bongshin Lee, Wanda Pratt, Julie A. Kientz",
        "abstract": "Researchers have studied how people use self-tracking technologies and discovered a long list of barriers including lack of time and motivation as well as difficulty in data integration and interpretation. Despite the barriers, an increasing number of Quantified-Selfers diligently track many kinds of data about themselves, and some of them share their best practices and mistakes through Meetup talks, blogging, and conferences. In this work, we aim to gain insights from these \"extreme users,\" who have used existing technologies and built their own workarounds to overcome different barriers. We conducted a qualitative and quantitative analysis of 52 video recordings of Quantified Self Meetup talks to understand what they did, how they did it, and what they learned. We highlight several common pitfalls to self-tracking, including tracking too many things, not tracking triggers and context, and insufficient scientific rigor. We identify future research efforts that could help make progress toward addressing these pitfalls. We also discuss how our findings can have broad implications in designing and developing self-tracking technologies.",
        "session": "SESSION: Quantified self"
    },
    {
        "title": "BodyDiagrams: improving communication of pain symptoms through drawing",
        "authors": "Amy Jang, Diana L. MacLean, Jeffrey Heer",
        "abstract": "Thousands of people use the Internet to discuss pain symptoms. While communication between patients and physicians involves both verbal and physical interactions, online discussions of symptoms typically comprise text only. We present BodyDiagrams, an online interface for expressing symptoms via drawings and text. BodyDiagrams augment textual descriptions with pain diagrams drawn over a reference body and annotated with severity and temporal metadata. The resulting diagrams can easily be shared to solicit feedback and advice. We also conduct a two-phase user study to assess BodyDiagrams' communicative efficacy. In the first phase, users describe pain symptoms using BodyDiagrams and a text-only interface; in the second phase, medical professionals evaluate these descriptions. We find that patients are significantly more confident that their BodyDiagrams will be correctly interpreted, while medical professionals rated BodyDiagrams as significantly more informative than text descriptions. Both groups indicated a preference for using diagrams to communicate physical symptoms in the future.",
        "session": "SESSION: Quantified self"
    },
    {
        "title": "Personal tracking as lived informatics",
        "authors": "John Rooksby, Mattias Rost, Alistair Morrison, Matthew Chalmers Chalmers",
        "abstract": "This paper characterises the use of activity trackers as \"lived informatics\". This characterisation is contrasted with other discussions of personal informatics and the quantified self. The paper reports an interview study with activity tracker users. The study found: people do not logically organise, but interweave various activity trackers, sometimes with ostensibly the same functionality; that tracking is often social and collaborative rather than personal; that there are different styles of tracking, including goal driven tracking and documentary tracking; and that tracking information is often used and interpreted with reference to daily or short term goals and decision making. We suggest there will be difficulties in personal informatics if we ignore the way that personal tracking is enmeshed with everyday life and people's outlook on their future.",
        "session": "SESSION: Quantified self"
    },
    {
        "title": "Towards an holistic view of the energy and environmental impacts of domestic media and IT",
        "authors": "Oliver Bates, Mike Hazas, Adrian Friday, Janine Morley, Adrian K. Clear",
        "abstract": "To date, research in sustainable HCI has dealt with eco-feedback, usage and recycling of appliances within the home, and longevity of portable electronics such as mobile phones. However, there seems to be less awareness of the energy and greenhouse emissions impacts of domestic consumer electronics and information technology. Such awareness is needed to inform HCI sustainability researchers on how best to prioritise efforts around digital media and IT. Grounded in inventories, interview and plug energy data from 33 undergraduate student participants, our findings provide the context for assessing approaches to reducing the energy and carbon emissions of media and IT in the home. In the paper, we use the findings to discuss and inform more fruitful directions that sustainable HCI research might take, and we quantify how various strategies might have modified the energy and emissions impacts for our participants.",
        "session": "SESSION: Sustainability perspectives"
    },
    {
        "title": "Beyond ethnography: engagement and reciprocity as foundations for design research out here",
        "authors": "Margot Brereton, Paul Roe, Ronald Schroeter, Anita Lee Hong",
        "abstract": "This paper explores an emerging paradigm for HCI design research based primarily upon engagement, reciprocity and doing. Much HCI research begins with an investigatory and analytic ethnographic approach before translating to design. Design may come much later in the process and may never benefit the community that is researched. However in many settings it is difficult for researchers to access the privileged ethnographer position of observer and investigator. Moreover rapid ethnographic research often does not seem the best or most appropriate course of action. We draw upon a project working with a remote Australian Aboriginal community to illustrate an alternative approach in Indigenous research, where the notion of reciprocity is first and foremost. We argue that this can lead to sustainable designs, valid research and profound innovation.",
        "session": "SESSION: Sustainability perspectives"
    },
    {
        "title": "Visualization of personal history for video navigation",
        "authors": "Abir Al-Hajri, Gregor Miller, Matthew Fong, Sidney S. Fels",
        "abstract": "We present an investigation of two different visualizations of video history: Video Timeline and Video Tiles. Video Timeline extends the commonly employed list-based visualization for navigation history by applying size to indicate heuristics and occupying the full screen with a two-sided timeline. Video Tiles visualizes history items in a grid-based layout by following pre-defined templates based on items' heuristics and ordering, utilizing screen space more effectively at the expense of a clearer temporal location. The visualizations are compared against the state-of-the-art method (a filmstrip-based visualization), with ten participants tasked with sharing their previously-seen affective intervals. Our study shows that our visualizations are perceived as intuitive and both outperform and are strongly preferred to the current method. Based on these results, Video Timeline and Video Tiles provide an effective addition to video viewers to help manage the growing quantity of video. They provide users with insight into their navigation patterns, allowing them to quickly find previously-seen intervals, leading to efficient clip sharing, simpler authoring and video summarization.",
        "session": "SESSION: Navigating video"
    },
    {
        "title": "WaaZam!: supporting creative play at a distance in customized video environments",
        "authors": "Seth E. Hunter, Pattie Maes, Anthony Tang, Kori M. Inkpen, Susan M. Hessey",
        "abstract": "We present the design, and evaluation of WaaZam, a video mediated communication system designed to support creative play in customized environments. Users can interact together in virtual environments composed of digital assets layered in 3D space. The goal of the project is to support creative play and increase social engagement during video sessions of geographically separated families. We try to understand the value of customization for individual families with children ages 6-12. We present interviews with creativity experts, a pilot study and a formal evaluation of families playing together in four conditions: separate windows, merged windows, digital play sets, and customized digital environments. We found that playing in the same video space enables new activities and increases social engagement for families. Customization allows families to modify scenes for their needs and support more creative play activities that embody the imagination of the child.",
        "session": "SESSION: Navigating video"
    },
    {
        "title": "LACES: live authoring through compositing and editing of streaming video",
        "authors": "Dustin Freeman, Stephanie Santosa, Fanny Chevalier, Ravin Balakrishnan, Karan Singh",
        "abstract": "Video authoring activity typically consists of three phases: planning (pre-production), capture (production) and processing (post-production). The status quo is that these phases occur separately, and the latter two have a significant amount of \"slack time\", where the camera operator is watching the scene unfold during capture, and the editor is re-watching and navigating through recorded footage during post-production. While this process is well suited to creating polished or professional video, video clips produced by casual video makers as seen in online forums could benefit from some editing without the overhead of current authoring tools. We introduce LACES, a tablet-based system enabling simple video manipulations in the midst of filming. Seamless in-situ integration of video capture and manipulation forms a novel workflow, allowing greater spontaneity and exploration of video creation.",
        "session": "SESSION: Navigating video"
    },
    {
        "title": "ThumbReels: query sensitive web video previews based on temporal, crowdsourced, semantic tagging",
        "authors": "Barnaby Craggs, Myles Kilgallon Scott, Jason Alexander",
        "abstract": "During online search, the user's expectations often differ from those of the author. This is known as the \"intention gap\" and is particularly problematic when searching for and discriminating between online video content. An author uses description and meta-data tags to label their content, but often cannot predict alternate interpretations or appropriations of their work. To address this intention gap, we present ThumbReels, a concept for query-sensitive video previews generated from crowdsourced, temporally defined semantic tagging. Further, we supply an open-source tool that supports on-the-fly temporal tagging of videos, whose output can be used for later search queries. A first user study validates the tool and concept. We then present a second study that shows participants found ThumbReels to better represent search terms than contemporary preview techniques.",
        "session": "SESSION: Navigating video"
    },
    {
        "title": "Panopticon as an eLearning support search tool",
        "authors": "James Nicholson, Mark Huber, Daniel Jackson, Patrick Olivier",
        "abstract": "We present an evaluation of Panopticon, a video surrogate system, as an online eLearning support search tool for finding information within video lectures. A comparison was made with a standard video player (YouTube) in two scenarios with two classes of users: revision students and independent learners. Results showed that users of Panopticon were significantly faster at finding information within the lecture videos than users of the YouTube player. It was also found that videos predominantly featuring a talking lecturer took longest to navigate, presenting design implications for lectures to be uploaded to open eLearning platforms.",
        "session": "SESSION: Navigating video"
    },
    {
        "title": "Searching for analogical ideas with crowds",
        "authors": "Lixiu Yu, Aniket Kittur, Robert E. Kraut",
        "abstract": "Seeking solutions from one domain to solve problems in another is an effective process of innovation. This process of analogy searching is difficult for both humans and machines. In this paper, we present a novel approach for re-presenting a problem in terms of its abstract structure, and then allowing people to use this structural representation to find analogies. We propose a crowdsourcing process that helps people navigate a large dataset to find analogies. Through two experiments, we show the benefits of using abstract structural representations to search for ideas that are analogous to a source problem, and that these analogies result in better solutions than alternative approaches. This work provides a useful method for finding analogies, and can streamline innovation for both novices and professional designers.",
        "session": "SESSION: Crowds and creativity"
    },
    {
        "title": "skWiki: a multimedia sketching system for collaborative creativity",
        "authors": "Zhenpeng Zhao, Sriram Karthik Badam, Senthil Chandrasegaran, Deok Gun Park, Niklas L.E. Elmqvist, Lorraine Kisselburgh, Karthik Ramani",
        "abstract": "We present skWiki, a web application framework for collaborative creativity in digital multimedia projects, including text, hand-drawn sketches, and photographs. skWiki overcomes common drawbacks of existing wiki software by providing a rich viewer/editor architecture for all media types that is integrated into the web browser itself, thus avoiding dependence on client-side editors. Instead of files, skWiki uses the concept of paths as trajectories of persistent state over time. This model has intrinsic support for collaborative editing, including cloning, branching, and merging paths edited by multiple contributors. We demonstrate skWiki's utility using a qualitative, sketching-based user study.",
        "session": "SESSION: Crowds and creativity"
    },
    {
        "title": "Distributed analogical idea generation: inventing with crowds",
        "authors": "Lixiu Yu, Aniket Kittur, Robert E. Kraut",
        "abstract": "Harnessing crowds can be a powerful mechanism for increasing innovation. However, current approaches to crowd innovation rely on large numbers of contributors generating ideas independently in an unstructured way. We introduce a new approach called distributed analogical idea generation, which aims to make idea generation more effective and less reliant on chance. Drawing from the literature in cognitive science on analogy and schema induction, our approach decomposes the creative process in a structured way amenable to using crowds. In three experiments we show that distributed analogical idea generation leads to better ideas than example-based approaches, and investigate the conditions under which crowds generate good schemas and ideas. Our results have implications for improving creativity and building systems for distributed crowd innovation.",
        "session": "SESSION: Crowds and creativity"
    },
    {
        "title": "Frenzy: collaborative data organization for creating conference sessions",
        "authors": "Lydia B. Chilton, Juho Kim, Paul André, Felicia Cordeiro, James A. Landay, Daniel S. Weld, Steven P. Dow, Robert C. Miller, Haoqi Zhang",
        "abstract": "Organizing conference sessions around themes improves the experience for attendees. However, the session creation process can be difficult and time-consuming due to the amount of expertise and effort required to consider alternative paper groupings. We present a collaborative web application called Frenzy to draw on the efforts and knowledge of an entire program committee. Frenzy comprises (a) interfaces to support large numbers of experts working collectively to create sessions, and (b) a two-stage process that decomposes the session-creation problem into meta-data elicitation and global constraint satisfaction. Meta-data elicitation involves a large group of experts working simultaneously, while global constraint satisfaction involves a smaller group that uses the meta-data to form sessions. We evaluated Frenzy with 48 people during a deployment at the CSCW 2014 program committee meeting. The session making process was much faster than the traditional process, taking 88 minutes instead of a full day. We found that meta-data elicitation was useful for session creation. Moreover, the sessions created by Frenzy were the basis of the CSCW 2014 schedule.",
        "session": "SESSION: Crowds and creativity"
    },
    {
        "title": "End-users publishing structured information on the web: an observational study of what, why, and how",
        "authors": "Edward Benson, David R. Karger",
        "abstract": "End-users are accustomed to filtering and browsing styled collections of data on professional web sites, but they have few ways to create and publish such information architectures for themselves. This paper presents a full-lifecycle analysis of the Exhibit framework - an end-user tool which provides such functionality - to understand the needs, capabilities, and practices of this class of users. We include interviews, as well as analysis of over 1,800 visualizations and 200,000 web interactions with these visualizations. Our analysis reveals important findings about this user population which generalize to the task of providing better end-user structured content publication tools.",
        "session": "SESSION: Interacting with the web"
    },
    {
        "title": "Designing usable web forms: empirical evaluation of web form improvement guidelines",
        "authors": "Mirjam Seckler, Silvia Heinz, Javier A. Bargas-Avila, Klaus Opwis, Alexandre N. Tuch",
        "abstract": "This study reports a controlled eye tracking experiment (N = 65) that shows the combined effectiveness of 20 guidelines to improve interactive online forms when applied to forms found on real company websites. Results indicate that improved web forms lead to faster completion times, fewer form submission trials, and fewer eye movements. Data from subjective questionnaires and interviews further show increased user satisfaction. Overall, our findings highlight the importance for web designers to improve their web forms using UX guidelines.",
        "session": "SESSION: Interacting with the web"
    },
    {
        "title": "Choice overload in search engine use?",
        "authors": "Pawitra Chiravirakul, Stephen J. Payne",
        "abstract": "Search engines typically return so many results that choosing from the list might be predicted to suffer from the effects of \"choice overload\". Preliminary work has reported just such an effect [12]. In this paper a series of three experiments was conducted to investigate the choice overload effect in search engine use. Participants were given search tasks and presented with either six or twenty-four returns to choose from. The results revealed that the choice behaviour was strongly influenced by the ranking of returns, and that choice satisfaction was affected by the number of options and the decision time. The main results, from the third experiment, showed that large sets of options yielded a positive effect on participants' satisfaction when they made a decision without time limit. When time was more strongly constrained, choices from small sets led to relatively higher satisfaction. Our studies show how user satisfaction with found information can be affected by processing strategies that are influenced by search engine design features.",
        "session": "SESSION: Interacting with the web"
    },
    {
        "title": "Coming in from the margins: amateur musicians in the online age",
        "authors": "Michaela Hoare, Steve Benford, Rachel Jones, Natasa Milic-Frayling",
        "abstract": "HCI is increasingly interested in amateurism, but the wider literature suggests that the amateur is a complex and distinctive phenomenon. An interview study reveals the nature of the amateur in the digital age. Even though operating non-professionally at a micro-scale, amateur musicians employ a plethora of online services to sustain local fanbases, reach out to new fans, collaborate internationally, and actively promote both digital and material products. Our findings lead to recommendations for event-oriented promotion tools; community-oriented analytics; tangible and embedded products; and limited-edition digital experiences. We conclude that HCI needs to recognise the amateur as an important class of user, one who is serious about their leisure, and who is also distinct from the professional as from the novice and hobbyist.",
        "session": "SESSION: Music, dance, and television"
    },
    {
        "title": "Watching the footwork: second screen interaction at a dance and music performance",
        "authors": "Louise Barkhuus, Arvid Engström, Goranka Zoric",
        "abstract": "Interactive mobile technologies have become part of audience experiences of live performances in terms of both general media sharing and specific (sometimes official) extra content. At the same time, high bandwidth affords streaming of live events to mobile devices. We take advantage of these technologies in our high resolution, panoramic image video stream and study a scenario of audience members viewing the very same live event they are watching on a tablet. The video stream on the tablet is navigational and enables audience members to pan and zoom in the real-time video feed. We studied audience interaction and impressions in three performances of a dance and music show and found distinct uses of the second screen video stream. We emphasize that despite initial reluctance, the observed utilization of the technology opened up for new potential practices. Our study shows how working with perceived conflict in technology can still open up design space for interactive technologies.",
        "session": "SESSION: Music, dance, and television"
    },
    {
        "title": "Streaming on twitch: fostering participatory communities of play within live mixed media",
        "authors": "William A. Hamilton, Oliver Garretson, Andruid Kerne",
        "abstract": "Previously, video streaming sites were at the fringes of online social media. In the past two years, live streams of video games, on sites such as Twitch.tv, have become very popular. Live streams serve as meeting grounds for player communities. The Twitch streaming medium combines broadcast video with open IRC chat channels. In conjunction with gameplay, viewer participation and community building gain emphasis. Twitch streams range in size and nature, from intimate communities with fifty viewers, to massive broadcasts with tens of thousands. In this paper, we present an ethnographic investigation of the live streaming of video games on Twitch. We find that Twitch streams act as virtual third places, in which informal communities emerge, socialize, and participate. Over time, stream communities form around shared identities drawn from streams? contents and participants? shared experiences. We describe processes through which stream communities form, the motivations of members, and emergent issues in the medium. Finally, we draw from our findings to derive implications for design of live mixed-media environments to support participatory online communities.",
        "session": "SESSION: Music, dance, and television"
    },
    {
        "title": "Long tail TV revisited: from ordinary camera phone use to pro-am video production",
        "authors": "Oskar Juhlin, Arvid Engström, Elin Önnevall",
        "abstract": "Pro-Am live video producers broadcast events on a regular basis. They are here selected for an ethnographic study since their continuous content generation can teach us something of what it takes for amateurs, who currently struggle with mastering the video medium, to become proficient producers. We learn from media theory that Pro-Ams are distinguished from professionals in terms of inherent skills and identities, and have therefore focused on these characteristics. We add to this research by showing on-going challenges that the former face in their production, i.e. how their learning practices, such as learning through instructions, are situated and related to particular settings. Learning and development of skills were done as organizations, rather than as individuals. Furthermore, the recurrent nature of both events and broadcasts appears to be an important condition for establishing the terms needed to carry out a production, and to learn the skills of a producer. This understanding may explain in part why accounts in previous research, of single users struggling with the affordances of live video, point to such difficulties in mastering the medium. The findings guide design to better support activities contiguous with the set-up of the production, rather than the broadcast per se.",
        "session": "SESSION: Music, dance, and television"
    },
    {
        "title": "Estimating county health statistics with twitter",
        "authors": "Aron Culotta",
        "abstract": "Understanding the relationships among environment, behavior, and health is a core concern of public health researchers. While a number of recent studies have investigated the use of social media to track infectious diseases such as influenza, little work has been done to determine if other health concerns can be inferred. In this paper, we present a large-scale study of 27 health-related statistics, including obesity, health insurance coverage, access to healthy foods, and teen birth rates. We perform a linguistic analysis of the Twitter activity in the top 100 most populous counties in the U.S., and find a significant correlation with 6 of the 27 health statistics. When compared to traditional models based on demographic variables alone, we find that augmenting models with Twitter-derived information improves predictive accuracy for 20 of 27 statistics, suggesting that this new methodology can complement existing approaches.",
        "session": "SESSION: Social media and health"
    },
    {
        "title": "Unraveling abstinence and relapse: smoking cessation reflected in social media",
        "authors": "Elizabeth L. Murnane, Scott Counts",
        "abstract": "Analysis of smokers' posts and behaviors on Twitter reveals factors impacting abstinence and relapse during cessation attempts. Combining automatic and crowdsourced techniques, we detect users trying to quit smoking and analyze tweet and network data from a sample of 653 individuals over a two-year window of quitting. Guided by theory and practice, we derive behavioral, social, and emotional measures to compare users who abstain and relapse. We also examine the cessation process, demonstrating that Twitter can help chronicle how some people go about quitting. Among other results, we show that those who fail in their smoking cessation are far heavier posters and use relatively less positive language, while those who succeed are more social in both network ties and in directed communication. We conclude with insights on how intelligent intervention systems can harness these signals to provide tailored behavior change support.",
        "session": "SESSION: Social media and health"
    },
    {
        "title": "Weaving clinical expertise in online health communities",
        "authors": "Jina Huh, Wanda Pratt",
        "abstract": "Many patients visit online health communities to receive support. In face-to-face support groups, health professionals facilitate peer-patients exchanging experience while adding their clinical expertise when necessary. However, the large scale of online health communities makes it challenging for such health professional moderators' involvement to happen. To address this challenge of delivering clinical expertise to where patients need them, we explore the idea of semi-automatically providing clinical expertise in online health communities. We interviewed 14 clinicians showing them example peer-patient conversation threads. From the interviews, we examined the ideal practice of clinicians providing expertise to patients. The clinicians continuously assessed when peer-patients were providing appropriate support, what kinds of clinical help they could give online, and when to defer to patients' healthcare providers. The findings inform requirements for building a semi-automated system delivering clinical expertise in online health communities.",
        "session": "SESSION: Social media and health"
    },
    {
        "title": "Seeking and sharing health information online: comparing search engines and social media",
        "authors": "Munmun De Choudhury, Meredith Ringel Morris, Ryen W. White",
        "abstract": "Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.",
        "session": "SESSION: Social media and health"
    },
    {
        "title": "RetroDepth: 3D silhouette sensing for high-precision input on and above physical surfaces",
        "authors": "David Kim, Shahram Izadi, Jakub Dostal, Christoph Rhemann, Cem Keskin, Christopher Zach, Jamie Shotton, Timothy Large, Steven Bathiche, Matthias Nießner, D. Alex Butler, Sean Fanello, Vivek Pradeep",
        "abstract": "We present RetroDepth, a new vision-based system for accurately sensing the 3D silhouettes of hands, styluses, and other objects, as they interact on and above physical surfaces. Our setup is simple, cheap, and easily reproducible, comprising of two infrared cameras, diffuse infrared LEDs, and any off-the-shelf retro-reflective material. The retro-reflector aids image segmentation, creating a strong contrast between the surface and any object in proximity. A new highly efficient stereo matching algorithm precisely estimates the 3D contours of interacting objects and the retro-reflective surfaces. A novel pipeline enables 3D finger, hand and object tracking, as well as gesture recognition, purely using these 3D contours. We demonstrate high-precision sensing, allowing robust disambiguation between a finger or stylus touching, pressing or interacting above the surface. This allows many interactive scenarios that seamlessly mix together freehand 3D interactions with touch, pressure and stylus input. As shown, these rich modalities of input are enabled on and above any retro-reflective surface, including custom \"physical widgets\" fabricated by users. We compare our system with Kinect and Leap Motion, and conclude with limitations and future work.",
        "session": "SESSION: On and above the surface"
    },
    {
        "title": "SurfaceLink: using inertial and acoustic sensing to enable multi-device interaction on a surface",
        "authors": "Mayank Goel, Brendan Lee, Md. Tanvir Islam Aumi, Shwetak Patel, Gaetano Borriello, Stacie Hibino, Bo Begole",
        "abstract": "We present SurfaceLink, a system where users can make natural surface gestures to control association and information transfer among a set of devices that are placed on a mutually shared surface (e.g., a table). SurfaceLink uses a combination of on-device accelerometers, vibration motors, speakers and microphones (and, optionally, an off-device contact microphone for greater sensitivity) to sense gestures performed on the shared surface. In a controlled evaluation with 10 participants, SurfaceLink detected the presence of devices on the same surface with 97.7% accuracy, their relative arrangement with 89.4% accuracy, and various single- and multi-touch surface gestures with an average accuracy of 90.3%. A usability analysis showed that SurfaceLink has advantages over current multi-device interaction techniques in a number of situations.",
        "session": "SESSION: On and above the surface"
    },
    {
        "title": "Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction",
        "authors": "Ye Pan, William Steptoe, Anthony Steed",
        "abstract": "We report on two experiments that investigate the influence of display type and viewing angle on how people place their trust during avatar-mediated interaction. By monitoring advice seeking behavior, our first experiment demonstrates that if participants observe an avatar at an oblique viewing angle on a flat display, they are less able to discriminate between expert and non-expert advice than if they observe the avatar face-on. We then introduce a novel spherical display and a ray-traced rendering technique that can display an avatar that can be seen correctly from any viewing direction. We expect that a spherical display has advantages over a flat display because it better supports non-verbal cues, particularly gaze direction, since it presents a clear and undistorted viewing aspect at all angles. Our second experiment compares the spherical display to a flat display. Whilst participants can discriminate expert advice regardless of display, a negative bias towards the flat screen emerges at oblique viewing angles. This result emphasizes the ability of the spherical display to be viewed qualitatively similarly from all angles. Together the experiments demonstrate how trust can be altered depending on how one views the avatar.",
        "session": "SESSION: On and above the surface"
    },
    {
        "title": "PrintSense: a versatile sensing technique to support multimodal flexible surface interaction",
        "authors": "Nan-Wei Gong, Jürgen Steimle, Simon Olberding, Steve Hodges, Nicholas Edward Gillian, Yoshihiro Kawahara, Joseph A. Paradiso",
        "abstract": "We present a multimodal on-surface and near-surface sensing technique for planar, curved and flexible surfaces. Our technique leverages temporal multiplexing of signals coming from a universal interdigitated electrode design, which is printed as a single conductive layer on a flexible substrate. It supports sensing of touch and proximity input, and moreover is capable of capturing several levels of pressure and flexing. We leverage recent developments in conductive inkjet printing as a way to prototype electrode patterns, and combine this with our hardware module for supporting the full range of sensing methods. As the technique is low-cost and easy to implement, it is particularly well-suited for prototyping touch- and hover-based user interfaces, including curved and deformable ones.",
        "session": "SESSION: On and above the surface"
    },
    {
        "title": "Let's kick it: how to stop wasting the bottom third of your large screen display",
        "authors": "Ricardo Jota, Pedro Lopes, Daniel Wigdor, Joaquim Jorge",
        "abstract": "Large-scale touch surfaces have been widely studied in literature and adopted for public installations such as interactive billboards. However, current designs do not take into consideration that touching the interactive surface at different heights is not the same; for body-height displays, the bottom portion of the screen is within easier reach of the foot than the hand. We explore the design space of foot input on vertical surfaces, and propose three distinct interaction modalities: hand, foot tapping, and foot gesturing. Our design exploration pays particular attention to areas of the touch surface that were previously overlooked: out of hand's reach and close to the floor. We instantiate our design space with a working prototype of an interactive surface, in which we are able to distinguish between finger and foot tapping and extend the input area beyond the bottom of the display to support foot gestures.",
        "session": "SESSION: On and above the surface"
    },
    {
        "title": "Communiplay: a field study of a public display mediaspace",
        "authors": "Jörg Müller, Dieter Eberle, Konrad Tollmar",
        "abstract": "We present Communiplay, a public display media space. People passing by see their own contour mirrored on a public display and can start to play with virtual objects. At the same time, they see others playing at remote displays within the same virtual space. We are interested whether people would use such a public display media space, and if so, how and why. We evaluate Communiplay in a field study in six connected locations and find a remote honey-pot effect, i.e. people interacting at one location attract people at other locations. The conversion rate (percentage of passers-by starting to interact) rose by +136% when people saw others playing at remote locations. We also provide the first quantification of the (local) honey-pot effect (in our case it raised the conversion rate by +604% when people saw others playing at the same location). We conclude that the integration of multiple public displays into a media space is a promising direction for public displays and can make them more attractive and valuable.",
        "session": "SESSION: Interactive whiteboards and public displays"
    },
    {
        "title": "Posting for community and culture: considerations for the design of interactive digital bulletin boards",
        "authors": "Claude Fortin, Carman Neustaedter, Kate Hennessy",
        "abstract": "The next decade is likely to see a shift in digital public displays moving from non-interactive to interactive content. This will likely create a need for digital bulletin boards and for a better understanding of how such displays should be designed to encourage community members to interact with them. Our study addresses this by exploring community bulletin boards as a ubiquitous type of participatory non-digital display \"in the wild\". Our results highlight how they are used for content of local and contextual relevance, and how cultures of participation, personalization, location, the tangible character of architecture, access, control and flexibility might affect community members' level of engagement with them. Our analysis suggests entry points as design considerations intrinsically linked to the users' sense of agency within a delineated space. Overlaps with related work are identified throughout to provide further validation of previous findings in this area of research.",
        "session": "SESSION: Interactive whiteboards and public displays"
    },
    {
        "title": "I can wait a minute: uncovering the optimal delay time for pre-moderated user-generated content on public displays",
        "authors": "Miriam Greis, Florian Alt, Niels Henze, Nemanja Memarovic",
        "abstract": "Public displays have advanced from isolated and non interactive \"ad\" displays which show images and videos to displays that are networked, interactive, and open to a wide variety of content and applications. Prior work has shown large potential of user-generated content on public displays. However, one of the problems with user-generated content on public displays is moderation as content may be explicit or troublesome for a particular location. In this work we explore the expectations of users with regard to content moderation on public displays. An online survey revealed that people not only think that display content should be moderated but also that a delay of up to 10 minutes is acceptable if display content is moderated. In a subsequent in the wild deployment we compared different moderation delays. We found that a moderation delay significantly decreases the number of user-generated posts while at the same time there is no significant effect on users' decision to repeatedly post on the display.",
        "session": "SESSION: Interactive whiteboards and public displays"
    },
    {
        "title": "Design patterns for exploring and prototyping human-robot interactions",
        "authors": "Allison Sauppé, Bilge Mutlu",
        "abstract": "Robotic products are envisioned to offer rich interactions in a range of environments. While their specific roles will vary across applications, these products will draw on fundamental building blocks of interaction, such as greeting people, narrating information, providing instructions, and asking and answering questions. In this paper, we explore how such building blocks might serve as interaction design patterns that enable design exploration and prototyping for human-robot interaction. To construct a pattern library, we observed human interactions across different scenarios and identified seven patterns, such as question-answer pairs. We then designed and implemented Interaction Blocks, a visual authoring environment that enabled prototyping of robot interactions using these patterns. Design sessions with designers and developers demonstrated the promise of using a pattern language for designing robot interactions, confirmed the usability of our authoring environment, and provided insights into future research on tools for human-robot interaction design.",
        "session": "SESSION: Human-robot interaction"
    },
    {
        "title": "Improving social presence in human-agent interaction",
        "authors": "André Pereira, Rui Prada, Ana Paiva",
        "abstract": "Humans have a tendency to consider media devices as social beings. Social agents and artificial opponents can be examined as one instance of this effect. With today's technology it is already possible to create artificial agents that are perceived as socially present. In this paper, we start by identifying the factors that influence perceptions of social presence in human-agent interactions. By taking these factors into account and by following previously defined guidelines for building socially present artificial opponents, a case study was created in which a social robot plays the Risk board game against three human players. An experiment was performed to ascertain whether the agent created in this case study is perceived as socially present. The experiment suggested that by following the guidelines for creating socially present artificial board game opponents, the perceived social presence of users towards the artificial agent improves.",
        "session": "SESSION: Human-robot interaction"
    },
    {
        "title": "Robot gestures make difficult tasks easier: the impact of gestures on perceived workload and task performance",
        "authors": "Manja Lohse, Reinier Rothuis, Jorge Gallego-Pérez, Daphne E. Karreman, Vanessa Evers",
        "abstract": "Gestures are important non-verbal signals in human communication. Research with virtual agents and robots has started to add to the scientific knowledge about gestures but many questions with respect to the use of gestures in human-computer interaction are still open. This paper investigates the influence of robot gestures on the users' perceived workload and task performance (i.e. information recall) in a direction-giving task. We conducted a 2 x 2 (robot gestures vs. no robot gestures x easy vs. difficult task) experiment. The results indicate that robot gestures increased user performance and decreased perceived workload in the difficult task but not in the easy task. Thus, robot gestures are a promising means to improve human-robot interaction particularly in challenging tasks.",
        "session": "SESSION: Human-robot interaction"
    },
    {
        "title": "Measuring operator anticipatory inputs in response to time-delay for teleoperated human-robot interfaces",
        "authors": "Jonathan Bidwell, Alexandra Holloway, Scott Davidoff",
        "abstract": "Many tasks call for efficient user interaction under time delay-controlling space instruments, piloting remote aircraft and operating search and rescue robots. In this paper we identify an underexplored design opportunity for building robotic teleoperation user interfaces following an evaluation of operator performance during a time-delayed robotic arm block-stacking task in twenty-two participants. More delay resulted in greater operator hesitation and a decreased ratio of active to inactive input. This ratio can serve as a useful proxy for measuring an operator's ability to anticipate the outcome of their control inputs before receiving delayed visual feedback. High anticipatory input ratio (AIR) scores indicate times when robot operators enter commands before waiting for visual feedback. Low AIR scores highlight when operators must wait for visual feedback before continuing. We used this measurement to help us identify particular sub-tasks where operators would likely benefit from additional support.",
        "session": "SESSION: Human-robot interaction"
    },
    {
        "title": "Stay on the boundary: artifact analysis exploring researcher and user framing of robot design",
        "authors": "Hee Rin Lee, Selma Šabanovic, Erik Stolterman",
        "abstract": "In recent years, HCI researchers have increased their focus on studying the power relationships between researchers and users, and developing methodologies for eliciting design ideas that are sensitive to existing epistemic hierarchies in technology design. The differential value given to expert versus lay knowledge is a central factor in these debates. We apply Artifact Analysis, developed to help designers handle the complexity of digital artifacts, as a method to explore how experts and non-experts understand and frame robots, a technology characterized by significant complexity. Our results show that both non-expert users and expert researchers have knowledge that is significant to future robot development, but they focus on different aspects of the technology - users address mediated and interaction complexity while researchers focus on internal and external complexity. We also found that robots function as boundary objects between experts and users, and suggest that one task designers can perform is to \"stay on the boundary\" and mediate between the different ways in which experts and non-experts frame emerging technology to develop designs that benefit from insights from both user and researcher perspectives.",
        "session": "SESSION: Human-robot interaction"
    },
    {
        "title": "Help beacons: design and evaluation of an ad-hoc lightweight s.o.s. system for smartphones",
        "authors": "Amro Al-Akkad, Leonardo Ramirez, Alexander Boden, Dave Randall, Andreas Zimmermann",
        "abstract": "We present the design and evaluation of a lightweight mobile S.O.S. system that facilitates ad-hoc communication between first responders and victims in emergency situations. Our approach leverages established protocols and standards in unforeseen ways to provide a platform supporting the creation of short-lived communication links. The system comprises two mobile applications: one victim application that allows the broadcasting of distress signals by a novel use of Wi-Fi SSIDs; and a responder application that allows first responders to discover and trace the people broadcasting the signals. The main difference of our system with other platforms enabling communication in crisis situations is that our system is independent from existing network infrastructure and runs on off-the-shelf, commercially available smartphones. We describe the results of our evaluation process in the context of both a design evaluation during a real-world emergency response exercise and of two user workshops in preparation for an upcoming large-scale exercise.",
        "session": "SESSION: Emergency response"
    },
    {
        "title": "Upvoting hurricane Sandy: event-based news production processes on a social news site",
        "authors": "Alex Leavitt, Joshua A. Clark",
        "abstract": "This paper uses the case of Hurricane Sandy and reddit's topical community (subreddit) /r/sandy to examine the production and curation of news content around events on a social news site. Through qualitative analysis, we provide a coded topology of produced content and describe how types of networked gatekeeping impact the framing of a crisis situation. This study also examines, through quantitative modeling, what kind of information becomes negotiated and voted as relevant. We suggest that highly scored content shared in a social news setting focused more on human-interest media and perspective-based citizen journalism than professional news reports. We conclude by discussing how the mechanisms of social news sites conflict with the social norms and culture of reddit to produce differing expectations around news.",
        "session": "SESSION: Emergency response"
    },
    {
        "title": "Online public communications by police & fire services during the 2012 Hurricane Sandy",
        "authors": "Amanda L. Hughes, Lise A. A. St. Denis, Leysia Palen, Kenneth M. Anderson",
        "abstract": "Social media and other online communication tools are a subject of great interest in mass emergency response. Members of the public are turning to these solutions to seek and offer emergency information. Emergency responders are working to determine what social media policies should be in terms of their \"public information\" functions. We report on the online communications from all the coastal fire and police departments within a 100 mile radius of Hurricane Sandy's US landfall. Across four types of online communication media, we collected data from 840 fire and police departments. Findings indicate that few departments used these online channels in their Sandy response efforts, and that communications differed between fire and police departments and across media type. However, among the highly engaged departments, there is evidence that they bend and adapt policies about what constitutes appropriate public communication in the face of emergency demands; therefore, we propose that flexibility is important in considering future emergency online communication policy. We conclude with design recommendations for making online communication media more \"listenable\" for both emergency managers and members of the public.",
        "session": "SESSION: Emergency response"
    },
    {
        "title": "EmergencyMessenger: a text based communication concept for indoor firefighting",
        "authors": "Matthias Betz, Volker Wulf",
        "abstract": "Finding and rescuing missing or injured people or fighting fire inside burning buildings is a central challenge for fire brigades. To ensure the safety of indoor work, monitoring the operations of firefighting units is crucial. As in most countries, firefighters in Germany utilize radio sets to establish voice communication between indoor operating units and the supervisory structure outside. Based on findings from a long term ethnographic study in cooperation with different German fire brigades over a time span of more than 5 years we analyzed the advantages and disadvantages of the current voice over radio communication tactics and techniques. We designed and evaluated a complementary text based communication device the EMERGENCY-MESSENGER to support the time critical work of indoor units working under harsh conditions, wearing Self-Contained-Breathing-Apparatus (SCBA). We conducted 13 full scale training missions including extensive debriefings to design and evaluate the communication concept and the corresponding device.",
        "session": "SESSION: Emergency response"
    },
    {
        "title": "Odin: contextual document opinions on the go",
        "authors": "Joshua M. Hailpern, Bernardo A. Huberman",
        "abstract": "Information overload is a systemic problem for knowledge workers in enterprise. For a long time, information was scarce and therefore valuable. While, the explosion of digital information has made information plentiful, time to read and process that content is now scarce. This problem is only exacerbated by our increased mobility, and the expectation to be \"on top\" of the continuous barrage of documents while on the go. Knowledge workers in enterprise need solutions that are designed with quick methods for finding what to read in a large collection of documents (e.g. financial reports, legal documents, news), and ways of presenting it within small visual real estate. Unlike reviews, document collections are long, more varied, and context is extremely important. In response, we present Odin, a mobile web-based window onto a user's document corpus. Rather than performing corpus summarization, Odin users can quickly find opinions and documents that are Aligned or Divergent from the corpus' consensus, or those that are the most Relevant given the overall corpus' of opinions. Odin presents this information through a simple and intuitive mobile interface. To the authors' knowledge, this is the first UI/system (and support algorithm) to allow mobile users to place documents and their opinions in context through alignment rather than raw word count or sentiment. Positive results from two evaluations are also presented.",
        "session": "SESSION: Sensemaking and information in use"
    },
    {
        "title": "Monadic exploration: seeing the whole through its parts",
        "authors": "Marian Dörk, Rob Comber, Martyn Dade-Robertson",
        "abstract": "Monadic exploration is a new approach to interacting with relational information spaces that challenges the distinction between the whole and its parts. Building on the work of sociologists Gabriel Tarde and Bruno Latour we turn to the concept of the monad as a useful lens on online communities and collections that expands the possibility for creating meaning in their navigation. While existing interfaces tend to emphasize either the structure of the whole or details of a part, monadic exploration brings these opposing perspectives closer together in continuous movements between partially overlapping points of view. We present a visualization that reflects a given node's relative position within a network using radial displacements and visual folding. To investigate the potential of monadic exploration we report on an iterative design process of a web-based visualization of a highly cross-referenced book and its six-month deployment.",
        "session": "SESSION: Sensemaking and information in use"
    },
    {
        "title": "Photographing information needs: the role of photos in experience sampling method-style research",
        "authors": "Zhen Yue, Eden Litt, Carrie J. Cai, Jeff Stern, Kathy K. Baxter, Zhiwei Guan, Nikhil Sharma, Guangqiang (George) Zhang",
        "abstract": "The Experience Sampling Method (ESM) enables researchers to capture information about participants' experiences in the moment. Adding an end-of-day retrospective survey also allows participants to elaborate on those experiences. Although the use of photos in retrospective interviews and surveys for memory elicitation is well known, little research has investigated the use of photos in ESM studies. As smartphone adoption increases facilitating ESM studies and making photo sharing easier, researchers need to continuously evaluate the method and investigate the role of photos in such studies. We conducted a large-scale ESM and retrospective survey study via Android smartphones with more than 1,000 US participants, and analyzed participants' photo submissions, including how photo use correlated with participants' data quality and what, if any, value photos added for researchers. Our study sheds light on the role of photos in ESM and retrospective studies that researchers can reference when constructing future study designs.",
        "session": "SESSION: Sensemaking and information in use"
    },
    {
        "title": "Design insights for the next wave ontology authoring tools",
        "authors": "Markel Vigo, Caroline Jay, Robert Stevens",
        "abstract": "Ontologies have been employed across scientific and business domains for some time, and the proliferation of linked data means the number and range of potential authors is set to increase significantly. Ontologies using the Web Ontology Language (OWL) are complex artefacts, however: the authoring process requires not only knowledge of the application domain, but also skills in programming and logics. To date, there has been no systematic attempt to understand the effectiveness of existing tools, or explore what users really require to build successful ontologies. Here we address this shortfall, presenting insights from an interview study with 15 ontology authors. We identify the problems reported by authors, and the strategies they employ to solve them. We map the data to a set of design recommendations, which describe how tools of the future can support ontology authoring. A key challenge is dealing with information overload: improving the user's ability to navigate, populate and debug large ontologies will revolutionise the engineering process, and open ontology authoring up to a new generation of users.",
        "session": "SESSION: Sensemaking and information in use"
    },
    {
        "title": "The role of interactive biclusters in sensemaking",
        "authors": "Maoyuan Sun, Lauren Bradel, Chris L. North, Naren Ramakrishnan",
        "abstract": "Visual exploration of relationships within large, textual datasets is an important aid for human sensemaking. By understanding computed, structural relationships between entities of different types (e.g., people and locations), users can leverage domain expertise and intuition to determine the importance and relevance of these relationships for tasks, such as intelligence analysis. Biclusters are a potentially desirable method to facilitate this, because they reveal coordinated relationships that can represent meaningful relationships. Bixplorer, a visual analytics prototype, supports interactive exploration of textual datasets in a spatial workspace with biclusters. In this paper, we present results of a study that analyzes how users interact with biclusters to solve an intelligence analysis problem using Bixplorer. We found that biclusters played four principal roles in the analytical process: an effective starting point for analysis, a revealer of two levels of connections, an indicator of potentially important entities, and a useful label for clusters of organized information.",
        "session": "SESSION: Sensemaking and information in use"
    },
    {
        "title": "SmartVoice: a presentation support system for overcoming the language barrier",
        "authors": "Xiang Li, Jun Rekimoto",
        "abstract": "In most cases, speeches or presentations at an international event are required to be given in a common language (e.g. English). However, for people who are not proficient in that common language, delivering presentations fluently is very difficult. Simultaneous translation seems to be a solution, but besides its high cost, simultaneous translation undermines the nature of the presentation by substituting the real voice of the lecturer as well as his/her emotions. In this paper, we propose \"SmartVoice\", a presentation support system, which aims to overcome language barriers. By tracking the lip motion of the lecturer, SmartVoice controls the playback of the narration, which is a sound data prepared in advance or created automatically using a voice synthesizer. SmartVoice also controls the intonation of the sound based on the position and shape of the lecturer's mouth. As the lecturer can talk at his/her own pace with the voice automatically following, it appears as if he/she talks in his/her own voice. In our user evaluation, we confirmed that audiences find it difficult to distinguish between the narration generated by SmartVoice and that by a real voice. We also discuss the possibility of applying SmartVoice to fields other than multi-language presentation support, such as Automated Dialogue Replacement and language study.",
        "session": "SESSION: Presentation technologies"
    },
    {
        "title": "PitchPerfect: integrated rehearsal environment for structured presentation preparation",
        "authors": "Ha Trinh, Koji Yatani, Darren Edge",
        "abstract": "Rehearsal is a critical component of preparing to give an oral presentation, yet it is frequently abbreviated, performed in ways that are inefficient or ineffective, or simply omitted. We conducted an exploratory study to understand the relationship between the theory and practice of presentation rehearsal, classifying our qualitative results into five themes to motivate more structured rehearsal support deeply integrated in slide presentation software. In a within-subject study (N=12) comparing against participants' existing rehearsal practices, we found that our resulting PitchPerfect system significantly improved overall presentation quality and content coverage as well as provided greater support for content mastery, time management, and confidence building.",
        "session": "SESSION: Presentation technologies"
    },
    {
        "title": "DemoWiz: re-performing software demonstrations for a live presentation",
        "authors": "Pei-Yu Chi, Bongshin Lee, Steven M. Drucker",
        "abstract": "Showing a live software demonstration during a talk can be engaging, but it is often not easy: presenters may struggle with (or worry about) unexpected software crashes and encounter issues such as mismatched screen resolutions or faulty network connectivity. Furthermore, it can be difficult to recall the steps to show while talking and operating the system all at the same time. An alternative is to present with pre-recorded screencast videos. It is, however, challenging to precisely match the narration to the video when using existing video players. We introduce DemoWiz, a video presentation system that provides an increased awareness of upcoming actions through glanceable visualizations. DemoWiz supports better control of timing by overlaying visual cues and enabling lightweight editing. A user study shows that our design significantly improves the presenters' perceived ease of narration and timing compared to a system without visualizations that was similar to a standard playback control. Furthermore, nine (out of ten) participants preferred DemoWiz over the standard playback control with the last expressing no preference.",
        "session": "SESSION: Presentation technologies"
    },
    {
        "title": "TurningPoint: narrative-driven presentation planning",
        "authors": "Larissa Pschetz, Koji Yatani, Darren Edge",
        "abstract": "Once upon a time, people told stories unencumbered by slides. What modern presentations gain through visual slide support, however, is often at the expense of storytelling. We present TurningPoint, a probe to investigate the potential use of narrative-driven talk planning in slideware. Our study of TurningPoint reveals a delicate balance between narrative templates focusing author attention in ways that save time, and fixating attention in ways that limit experimentation.",
        "session": "SESSION: Presentation technologies"
    },
    {
        "title": "Supporting treatment of people living with HIV / AIDS in resource limited settings with IVRs",
        "authors": "Anirudha Joshi, Mandar Rane, Debjani Roy, Nagraj Emmadi, Padma Srinivasan, N. Kumarasamy, Sanjay Pujari, Davidson Solomon, Rashmi Rodrigues, D.G. Saple, Kamalika Sen, Els Veldeman, Romain Rutten",
        "abstract": "We developed an interactive voice response (IVR) system called TAMA (Treatment Advice by Mobile Alerts) that provides treatment support to people living with HIV / AIDS (PLHA) in developing countries, who are on antiret-roviral therapy (ART). We deployed TAMA with 54 PLHA in 5 HIV clinics in India for a period of 12 weeks. During the study, we gathered feedback about TAMA's design and usage. Additionally, we conducted detailed qualitative interviews and analysed usage logs. We found that TAMA was usable and viable in the real life settings of PLHA and it had many desirable effects on their treatment adherence. We developed insights that inform the design of TAMA and some of these can be generalised to design of other long-term, frequent-use IVR applications for users in developing countries in the healthcare domain and beyond.",
        "session": "SESSION: Personal health and wellbeing"
    },
    {
        "title": "Reflection through design: immigrant women's self-reflection on managing health and wellness",
        "authors": "Deana Brown, Victoria Ayo, Rebecca E. Grinter",
        "abstract": "Women comprise nearly half of the immigrant population worldwide and are susceptible to a wider range of health challenges compared to immigrant men. We present the findings of four participatory design sessions with immigrant women from the Caribbean to identify health and wellness challenges they faced and to conceptualize technologies to help them manage these issues. Stress, dietary challenges (specifically obesity), mental health, and domestic abuse, as identified by the women, form the focal themes for the design sessions. Their design approaches emphasized rebuilding the support structure, reducing stressors through entertainment and relaxation and encouraging positive gradational lifestyle changes. In conceiving health and wellness technologies for immigrant women, our work highlights opportunities for HCI to consider the role of others (and who benefits) and to reflect on the role of design and the underlying values and themes designs encompass. Finally, we emphasize how the technologies conceived by these women support rather than replace social solutions to the health and wellness challenges faced by these and other immigrant women.",
        "session": "SESSION: Personal health and wellbeing"
    },
    {
        "title": "DDFSeeks same: sexual health-related language in online personal ads for men who have sex with men",
        "authors": "Oliver L. Haimson, Jed R. Brubaker, Gillian R. Hayes",
        "abstract": "The HIV/AIDS crisis of the 1980s fundamentally changed sexual practices of men who have sex with men (MSM) in the U.S., including increased usage of sexual health-related (SHR) language in personal advertisements. Analyzing online personal ads from Craigslist, we found a substantial increase in SHR language, from ~23% in 1988 to over 53% today, echoing continuing concern about rising HIV rates. We argue that SHR language in Craigslist ads can be used as a sensor to provide insight into HIV epidemiology as well as discourse among particular communities. We show a positive significant relationship between prevalence rate of HIV in an ad's location and use of SHR language in that location. Analysis highlights the opportunity for SHR information found in Craigslist personal ads to serve as a data source for HIV prevention research. More broadly, we argue for mining large-scale user-generated content to inform HCI design of health and other systems, and explore use of such data to examine temporal changes in language to facilitate improved user-interface design.",
        "session": "SESSION: Personal health and wellbeing"
    },
    {
        "title": "Support matching and satisfaction in an online breast cancer support community",
        "authors": "Tatiana A. Vlahovic, Yi-Chia Wang, Robert E. Kraut, John M. Levine",
        "abstract": "Research suggests that online health support benefits chronically ill users. Their satisfaction might be an indicator that they perceive group interactions as beneficial and a precursor to group commitment. We examined whether receiving emotional and informational support is satisfying in its own right, or whether satisfaction depends on matches between what users sought and what they received. Two studies collected judgments in a breast cancer support community of support users sought, support they received, and their expressed satisfaction. While receiving emotional or informational support in general positively predicted satisfaction, users expressed less satisfaction when they sought informational support but received emotional support. There was also a tendency for users to express more satisfaction when they sought and received informational support. On the other hand, users were equally satisfied with emotional and informational support after seeking emotional support. Implications for membership commitment and interventions in online support groups are discussed.",
        "session": "SESSION: Personal health and wellbeing"
    },
    {
        "title": "Between theory and practice: bridging concepts in HCI research",
        "authors": "Peter Dalsgaard, Christian Dindler",
        "abstract": "We present the notion of \"bridging concepts\" as a particular form of intermediary knowledge in HCI research, residing between theory and practice. We argue that bridging concepts address the challenge of facilitating exchange between theory and practice in HCI, and we compare it to other intermediary forms of knowledge such as strong concepts and conceptual constructs. We propose that bridging concepts have three defining constituents: a theoretical foundation, a set of design articulations and a range of exemplars that demonstrate the scope and potential of their application. These constituents specify how bridging concepts, as a form of knowledge, are accountable to both theory and practice. We present an analysis of the concept of \"peepholes\" as an example of a bridging concept aimed at spurring user curiosity and engagement.",
        "session": "SESSION: Design theory"
    },
    {
        "title": "Evolution of design competence in UX practice",
        "authors": "Colin M. Gray",
        "abstract": "There has been increasing interest in the adoption of UX within corporate environments, and what competencies translate into effective UX design. This paper addresses the space between pedagogy and UX practice through the lens of competence, with the goal of understanding how students are initiated into the practice community, how their perception of competence shifts over time, and what factors influence this shift. A 12-week longitudinal data collection, including surveys and interviews, documents this shift, with participants beginning internships and full-time positions in UX. Students and early professionals were asked to assess their level of competence and factors that influenced competence. A co-construction of identity between the designer and their environment is proposed, with a variety of factors relating to tool and representational knowledge, complexity, and corporate culture influencing perceptions of competence in UX over time. Opportunities for future research, particularly in building an understanding of competency in UX based on this preliminary framing of early UX practice are addressed.",
        "session": "SESSION: Design theory"
    },
    {
        "title": "Causal interactions",
        "authors": "Adam Darlow, Gideon Goldin, Steven Sloman",
        "abstract": "In this paper we present two design guidelines, causal order and continuity, to be used as rules of thumb for designing intuitive interactions based on principles of causal reasoning. We propose that designing interactions to behave like real-world systems of cause and effect makes them more intuitive. Using these basic principles avoids the limitations inherent to specific metaphors. In three experiments, participants solved puzzles using variations of a novel graphical interface. Participants using interfaces that were consistent with the causal guidelines consistently solved the puzzle faster than participants using inconsistent interfaces. We also discuss common interactions already consistent with the causal guidelines as well as areas where the guidelines are likely to apply successfully. The causal order guidelines provide specific utility while also demonstrating how principles of causal psychology can be applied to help interface designers better convey the functionality of their interfaces.",
        "session": "SESSION: Design theory"
    },
    {
        "title": "Personas is applicable: a study on the use of personas in Denmark",
        "authors": "Lene Nielsen, Kira Storgaard Hansen",
        "abstract": "The persona method is gaining widespread use and support. Many researchers have reported from single cases and novel domains how they have used the method. Few have conducted literature studies in order to identify and discuss the different understandings of the method. Fewer still have reported on ethnographic studies of practice. This paper falls within the last category, reporting on a study on how practitioners in Denmark use the method, and their perceptions of benefits and challenges when using the method. Finally, different casts of personas obtained from the involved companies are analyzed. The findings are compared to reported studies of practice. Contrary to the existing findings the study reports that the method is well integrated into existing practices.",
        "session": "SESSION: Design theory"
    },
    {
        "title": "GestKeyboard: enabling gesture-based interaction on ordinary physical keyboard",
        "authors": "Haimo Zhang, Yang Li",
        "abstract": "Stroke gestures are intuitive and efficient but often require gesture-capable input hardware such as a touchscreen. In this paper, we present GestKeyboard, a novel technique for gesturing over an ordinary, unmodified physical keyboard that remains the major input modality for existing desktop and laptop computers. We discuss an exploratory study for understanding the design space of gesturing on a physical keyboard and our algorithms for detecting gestures in a modeless way, without interfering with the keyboard's major functionality such as text entry and shortcuts activation. We explored various features for detecting gestures from a keyboard event stream. Our experiment based on the data collected from 10 participants indicated it is feasible to reliably detect gestures from normal keyboard use, 95% detection accuracy within a maximum latency of 200ms.",
        "session": "SESSION: Novel keyboards"
    },
    {
        "title": "Gesture script: recognizing gestures and their structure using rendering scripts and interactively trained parts",
        "authors": "Hao Lü, James A. Fogarty, Yang Li",
        "abstract": "Gesture-based interactions have become an essential part of the modern user interface. However, it remains challenging for developers to create gestures for their applications. This paper studies unistroke gestures, an important category of gestures defined by their single-stroke trajectories. We present Gesture Script, a tool for creating unistroke gesture recognizers. Gesture Script enhances example-based learning with interactive declarative guidance through rendering scripts and interactively trained parts. The structural information from the rendering scripts allows Gesture Script to synthesize gesture variations and generate a more accurate recognizer that also automatically extracts gesture attributes needed by applications. The results of our study with developers show that Gesture Script preserves the threshold of familiar example based gesture tools, while raising the ceiling of the recognizers created in such tools.",
        "session": "SESSION: Novel keyboards"
    },
    {
        "title": "Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard",
        "authors": "Stuart Taylor, Cem Keskin, Otmar Hilliges, Shahram Izadi, John Helmes",
        "abstract": "We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.",
        "session": "SESSION: Novel keyboards"
    },
    {
        "title": "B#: chord-based correction for multitouch braille input",
        "authors": "Hugo Nicolau, Kyle Montague, Tiago Guerreiro, João Guerreiro, Vicki L. Hanson",
        "abstract": "Braille has paved its way into mobile touchscreen devices, providing faster text input for blind people. This advantage comes at the cost of accuracy, as chord typing over a flat surface has proven to be highly error prone. A misplaced finger on the screen translates into a different or unrecognized character. However, the chord itself gathers information that can be leveraged to improve input performance. We present B#, a novel correction system for multitouch Braille input that uses chords as the atomic unit of information rather than characters. Experimental results on data collected from 11 blind people revealed that B# is effective in correcting errors at character-level, thus providing opportunities for instant corrections of unrecognized chords; and at word-level, where it outperforms a popular spellchecker by providing correct suggestions for 72% of incorrect words (against 38%). We finish with implications for designing chord-based correction system and avenues for future work.",
        "session": "SESSION: Novel keyboards"
    },
    {
        "title": "Representatively memorable: sampling the right phrase set to get the text entry experiment right",
        "authors": "Luis A. Leiva, Germán Sanchis-Trilles",
        "abstract": "In text entry experiments, memorability is a desired property of the phrases used as stimuli. Unfortunately, to date there is no automated method to achieve this effect. As a result, researchers have to use either manually curated English-only phrase sets or sampling procedures that do not guarantee phrases being memorable. In response to this need, we present a novel sampling method based on two core ideas: a multiple regression model over language-independent features, and the statistical analysis of the corpus from which phrases will be drawn. Our results show that researchers can finally use a method to successfully curate their own stimuli targeting potentially any language or domain. The source code as well as our phrase sets are publicly available.",
        "session": "SESSION: Novel keyboards"
    },
    {
        "title": "Sketching in circuits: designing and building electronics on paper",
        "authors": "Jie Qi, Leah Buechley",
        "abstract": "The field of new methods and techniques for building electronics is quickly growing - from research in new materials for circuit building, to modular toolkits, and more recently to untoolkits, which aim to incorporate more off-the-shelf parts. However, the standard mediums for circuit design and construction remain the breadboard, protoboard, and printed circuit board (PCB). As an alternative, we introduce a method in which circuits are hand-made on ordinary paper substrates, connected with conductive foil tape and off-the-shelf circuit components with the aim of supporting the durability, scalability, and accessibility needs of novice and expert circuit builders alike. We also used electrified notebooks to investigate how the circuit design and build process would be affected by the constraints and affordances of the bound book. Our ideas and techniques were evaluated through a series of workshops, through which we found our methods supported a wide variety of approaches and results - both technical and expressive - to electronics design and construction.",
        "session": "SESSION: DIY and hacking"
    },
    {
        "title": "Do-it-yourself cellphones: an investigation into the possibilities and limits of high-tech diy",
        "authors": "David A. Mellis, Leah Buechley",
        "abstract": "This paper describes our do-it-yourself cellphone and our use of it to investigate the possibilities and limits of high-tech DIY practice. We describe our autobiographical approach -- making the phone and using it in our daily lives -- and our work disseminating the cellphone in workshops and online. This informs a discussion of the implications of technology for DIY practice. We suggest an understanding of DIY as an individual's ability to combine existing technologies into a desired product, enabled and limited by ecosystems of industrial actors and individuals. We distinguish different pathways into high-tech DIY practice, consider the relationship between prototyping and production, and discuss the effect of technology on DIY's relevance and tools, and on notions of transparency. We conclude by reflecting on the relationship between DIY and empowerment: the extent to which making devices gives people control over the technology in their lives.",
        "session": "SESSION: DIY and hacking"
    },
    {
        "title": "3D printed interactive speakers",
        "authors": "Yoshio Ishiguro, Ivan Poupyrev",
        "abstract": "We propose technology for designing and manufacturing interactive 3D printed speakers. With the proposed technology, sound reproduction can easily be integrated into vari-ous objects at the design stage and little assembly is required. The speaker can take the shape of anything from an abstract spiral to a rubber duck, opening new opportunities in product design. Furthermore, both audible sound and inaudible ultrasound can be produced with the same design, allowing for identifying and tracking 3D printed objects in space using common integrated microphones. The design of 3D printed speakers is based on electrostatic loudspeaker technology first explored in the early 1930s but not broadly applied until now. These speakers are simpler than common electromagnetic speakers, while allowing for sound reproduction at 60 dB levels with arbitrary directivity ranging from focused to omnidirectional. Our research of 3D printed speakers contributes to the growing body of work exploring functional 3D printing in interactive applications.",
        "session": "SESSION: DIY and hacking"
    },
    {
        "title": "Circuit stickers: peel-and-stick construction of interactive electronic prototypes",
        "authors": "Steve Hodges, Nicolas Villar, Nicholas Chen, Tushar Chugh, Jie Qi, Diana Nowacka, Yoshihiro Kawahara",
        "abstract": "We present a novel approach to the construction of electronic prototypes which can support a variety of interactive devices. Our technique, which we call circuit stickers, involves adhering physical interface elements such as LEDs, sounders, buttons and sensors onto a cheap and easy-to-make substrate which provides electrical connectivity. This assembly may include control electronics and a battery for standalone operation, or it can be interfaced to a microcontroller or PC. In this paper we illustrate different points in the design space and demonstrate the technical feasibility of our approach. We have found circuit stickers to be versatile and low-cost, supporting quick and easy construction of physically flexible interactive prototypes. Building extra copies of a device is straightforward. We believe this technology has potential for design exploration, research proto-typing, education and for hobbyist projects.",
        "session": "SESSION: DIY and hacking"
    },
    {
        "title": "Modeling the perception of user performance",
        "authors": "Max Nicosia, Antti Oulasvirta, Per Ola Kristensson",
        "abstract": "This paper studies how users perceive their own performance in two alternative user interfaces. We extend methodology from psychophysics to the study of interactive performance and conduct two experiments in order to create a model of users' perception of their own performance. In our studies, two interfaces are sequentially used in a pointing task, and users are asked to rate in which interface their performance was higher. We first differentiate the effects of objective performance (speed and accuracy) versus interface qualities (distance between elements and width of elements) on perceived performance. We then derive a model that predicts the amount of change required in an interface for users to reliably detect a difference. The model is useful as a heuristic for predicting if a new interface design is better enough for users to reliably appreciate the obtained gain in user performance. We validate the model via a separate user study, and conclude by discussing how to apply our findings to design problems.",
        "session": "SESSION: User models and prediction"
    },
    {
        "title": "Edit distance modulo bisimulation: a quantitative measure to study evolution of user models",
        "authors": "Himanshu Zade, Santosh Arvind Adimoolam, Sai Gollapudi, Anind K. Dey, Venkatesh Choppella",
        "abstract": "When a user learns to use a new device, her understanding of it evolves. A progressive comparison of the evolving user models towards the device target model, for analysing learning, involves determining the behavioral proximity between them. To quantify the gap between a user model and a target model, we introduce an edit distance metric for measuring their behavioral proximity using a bisimulation-based equivalence relation. We define edit distance to be the minimum number of edges and states with incident edges required to be deleted from and/or added to a user model to make it bisimilar to the target model. We propose an algorithm to compute edit distance between two models and employ the heuristic procedure on experimental data for computing edit distance between target and user models. The data is organised into two experiments depending on the device the user interacted with: (a) a simple device resembling a vending machine and (b) a close to real-world vehicle transmission model. The results validate our proposed metric as edit distance converges with progressive user learning, increases for erroneous learning, and remains unchanged indicating no learning.",
        "session": "SESSION: User models and prediction"
    },
    {
        "title": "The law of unintended consequences: the case of external subgoal support",
        "authors": "J. Gregory Trafton, Raj M. Ratwani",
        "abstract": "Many interfaces have been designed to prevent or reduce errors. These interfaces may, in fact, reduce the error rate of specific error classes, but may also have unintended consequences. In this paper, we show a series of studies where a better interface did not reduce the number of errors but instead shifted errors from one error class (omissions) to another error class (perseverations). We also show that having access to progress tracking (a progress bar) does not reduce the number of errors. We propose and demonstrate a solution -- a predictive error system -- that reduces errors based on the error class, not on the type of interface.",
        "session": "SESSION: User models and prediction"
    },
    {
        "title": "Causality: a conceptual model of interaction history",
        "authors": "Mathieu Nancel, Andy Cockburn",
        "abstract": "Simple history systems such as Undo and Redo permit retrieval of earlier or later interaction states, but advanced systems allow powerful capabilities to reuse or reapply combinations of commands, states, or data across interaction contexts. Whether simple or powerful, designing interaction history mechanisms is challenging. We begin by reviewing existing history systems and models, observing a lack of tools to assist designers and researchers in specifying, contemplating, combining, and communicating the behaviour of history systems. To resolve this problem, we present CAUSALITY, a conceptual model of interaction history that clarifies the possibilities for temporal interactions. The model includes components for the work artifact (such as the text and formatting of a Word document), the system context (such as the settings and parameters of the user interface), the linear timeline (the commands executed in real time), and the branching chronology (a structure of executed commands and their impact on the artifact and/or context, which may be navigable by the user). We then describe and exemplify how this model can be used to encapsulate existing user interfaces and reveal limitations in their behaviour, and we also show in a conceptual evaluation how the model stimulates the design of new and innovative opportunities for interacting in time.",
        "session": "SESSION: User models and prediction"
    },
    {
        "title": "Conversing with children: cartoon and video people elicit similar conversational behaviors",
        "authors": "Jennifer Hyde, Sara Kiesler, Jessica K. Hodgins, Elizabeth J. Carter",
        "abstract": "Interactive animated characters have the potential to engage and educate children, but there is little research on children's interactions with animated characters and real people. We conducted an experiment with 69 children between the ages of 4 and 10 years to investigate how they might engage in conversation differently if their interactive partner appeared as a cartoon character or as a person. A subset of the participants interacted with characters that displayed exaggerated and damped facial motion. The children completed two conversations with an adult confederate who appeared once as herself through video and once as a cartoon character. We measured how much the children spoke and compared their gaze and gesture patterns. We asked them to rate their conversations and indicate their preferred partner. There was no difference in children's conversation behavior with the cartoon character and the person on video, even among those who preferred the person and when the cartoon exhibited altered motion. These results suggest that children will interact with animated characters as they would another person.",
        "session": "SESSION: Engage and educate children"
    },
    {
        "title": "Involving children in content control: a collaborative and education-oriented content filtering approach",
        "authors": "Yasmeen Hashish, Andrea Bunt, James E. Young",
        "abstract": "We present an approach to content control where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting. We conducted an initial exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content. Building on these findings, we designed an initial prototype which allows parents and children to work together to select appropriate applications, providing an opportunity for parents to educate their children on what is appropriate. A second qualitative study with parents and children in the six to eight year-old age group revealed a favorable response to this approach. Our results suggest that parents felt that this approach helped facilitate discussions with their children and made the education more enjoyable and approachable, and that children may have also learned from the interaction. In addition, the approach provided some parents with insights into their children's interests and understanding of their notions of appropriate and inappropriate content.",
        "session": "SESSION: Engage and educate children"
    },
    {
        "title": "What did spot hide?: a question-answering game for preschool children",
        "authors": "Anuj Tewari, John Canny",
        "abstract": "Early literacy is critical to child development, and determines a child's later educational and life opportunities. Moreover, preschool children are incessantly inquisitive, and will readily engage in question answering and asking activities if given the opportunity. We argue here that question asking/answering technologies can play a major role in early literacy. We describe the design and evaluation of a conversational agent called Spot, with the goal of engaging children in a 20-questions game. Towards this goal, we conducted a feasibility study to determine if children's questions are \"on-topic\" and suitable for ASR/dialogue systems. We evaluated Spot's performance at conducting a game of 20-questions against that of a human partner.",
        "session": "SESSION: Engage and educate children"
    },
    {
        "title": "Rafigh: a living media interface for speech intervention",
        "authors": "Foad Hamidi, Melanie Baljko",
        "abstract": "Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.",
        "session": "SESSION: Engage and educate children"
    },
    {
        "title": "A comparative study about children's and adults' perception of targeted web search engines",
        "authors": "Tatiana Gossen, Juliane Höbel, Andreas Nürnberger",
        "abstract": "In this paper we describe an eye-tracking study where we compare children's and adults' search behavior and perception of search interface elements on search engine results pages (SERPs) during an informational and a navigational search with Google and a search engine for children. Our first results indicate that children employ an exhaustive scanning strategy combined with cued visual jumps. Then they navigate to the next result page and only then modify their query. Adults only scan the first three results, following the F-shaped strategy, and immediately reformulate the query. Children pay less attention to textual summaries and more to thumbnails than adults do. Children take notice of a navigational menu with categories while adults do not.",
        "session": "SESSION: Engage and educate children"
    },
    {
        "title": "Structuring the space: a study on enriching node-link diagrams with visual references",
        "authors": "Basak E. Alper, Nathalie Henry Riche, Tobias Hollerer",
        "abstract": "Exploring large visualizations that do not fit in the screen raises orientation and navigation challenges. Structuring the space with additional visual references such as grids or contour lines provide spatial landmarks that may help viewers form a mental model of the space. However, previous studies report mixed results regarding their utility. While some evidence showed that grid and other visual embellishments improve memorability, experiments with contour lines suggest otherwise. In this work, we describe an evaluation framework to capture the impact of introducing visual references in node-link diagrams. We present the results of three controlled experiments that deepen our understanding on enriching large visualization spaces with visual structures. In particular, we provide the first tangible evidence that contour lines have significant benefits when navigating large node-link diagrams.",
        "session": "SESSION: Studying visualization"
    },
    {
        "title": "Highlighting interventions and user differences: informing adaptive information visualization support",
        "authors": "Giuseppe Carenini, Cristina Conati, Enamul Hoque, Ben Steichen, Dereck Toker, James Enns",
        "abstract": "There is increasing evidence that the effectiveness of information visualization techniques can be impacted by the particular needs and abilities of each user. This suggests that it is important to investigate information visualization systems that can dynamically adapt to each user. In this paper, we address the question of how to adapt. In particular, we present a study to evaluate a variety of visual prompts, called \"interventions\", that can be performed on a visualization to help users process it. Our results show that some of the tested interventions perform better than a condition in which no intervention is provided, both in terms of task performance as well as subjective user ratings. We also discuss findings on how intervention effectiveness is influenced by individual differences and task complexity.",
        "session": "SESSION: Studying visualization"
    },
    {
        "title": "Exertion in the small: improving differentiation and expressiveness in sports games with physical controls",
        "authors": "Mike Sheinin, Carl Gutwin",
        "abstract": "Many sports video games contain elements such as running or throwing that are based on real-world physical activities, but the translation of these activities to game controllers means that the original physicality is lost. This results in games where players have limited opportunity to improve their physical skills, where there is little differentiation in people's physical abilities, and where skills do not change over the course of a game. To explore ways of adding these elements back into sports games, we developed two games with small-scale physical controls for running and throwing -- one game was a simple running race, and one was a team-based handball-style game called Jelly Polo. In two studies (three track-and-field tournaments for the running game, and a four-week league for Jelly Polo), we observed the effects of physical controls on gameplay. Our studies showed that the physical controls enabled substantial individual differences in running and passing skill, allowed people to increase their expertise over time, and led to fatigue-based changes in performance during a game. Physical controls increased the games' challenge, complexity, and unpredictability, and dramatically improved player interest, expressiveness, and enjoyment. Our work shows that game designers should consider the idea of \"exertion in the small\" as a way to improve play experience in games based on physical activities.",
        "session": "SESSION: Exploring exergames"
    },
    {
        "title": "\"healthifying\" exergames: improving health outcomes through intentional priming",
        "authors": "Frank X. Chen, Abby C. King, Eric B. Hekler",
        "abstract": "Exergames, video game systems that require exertion and interaction, have been rising in popularity in the past years. However, research on popular exergames shows mixed health benefits, potentially due to minimal energy expenditure and decreasing use over time. This paper presents a 2x2 experimental study (N = 44), using a popular exergame, where we vary the framing of intention (i.e., \"Gameplay\" or \"Exercise\") and feedback (i.e., \"Health\" or \"No health\") to explore their single and interactive impacts on perceived exertion, objectively measured energy expenditure, affect, and duration of usage in a single session. Our study showed that participants primed with exercise used the system significantly longer than those primed with game play (M = 49.2 ±2.0 min versus M = 39.3 ±2.0 min). We discuss our results and possible design implications based on our single-session experiment. We conclude with a discussion on the potential impact of focusing on \"healthifying\" exergames -highlighting an exergames\" dual purpose as both a game and exercise - as opposed to gamifying health behaviors.",
        "session": "SESSION: Exploring exergames"
    },
    {
        "title": "Human factors of speed-based exergame controllers",
        "authors": "Taiwoo Park, Uichin Lee, Scott MacKenzie, Miri Moon, Inseok Hwang, Junehwa Song",
        "abstract": "Exergame controllers are intended to add fun to monotonous exercise. However, studies on exergame controllers mostly focus on designing new controllers and exploring specific application domains without analyzing human factors, such as performance, comfort, and effort. In this paper, we examine the characteristics of a speed-based exergame controller that bear on human factors related to body movement and exercise. Users performed tasks such as changing and maintaining exercise speed for avatar control while their performance was measured. The exergame controller follows Fitts' law, but requires longer movement time than a gamepad and Wiimote. As well, resistance force and target speed affect performance. User experience data confirm that the comfort and mental effort are adequate as practical game controllers. The paper concludes with discussion on applying our findings to practical exergame design.",
        "session": "SESSION: Exploring exergames"
    },
    {
        "title": "Establishing design guidelines in interactive exercise gaming: preliminary data from two posing studies",
        "authors": "Monica Zaczynski, Anthony D. Whitehead",
        "abstract": "Interactive gaming has demonstrated promise as a low-cost, at-home training and fitness instruction alternative. Gaming systems offer convenience and the ability to provide enhanced reporting and progress data if body measurement information is collected effectively. However, commercially available systems today are designed primarily for entertainment and as a result, the quality of instruction delivery and level of involvement may not meet the needs of a user performing a disciplined activity. This paper will look at adapting for occlusion and lack of visibility; learning and orientation; and providing feedback in an effort to determine if there is an ideal visual demonstration delivery that maximizes pose understanding and user self-efficacy, determine whether supplementary modalities are important for instruction, and determine if there is an ideal feedback delivery that promotes pose comprehension, confidence and motivation. This information can provide a guideline for designing clear and supportive, interactive training systems that can engage users, prevent injury and help maintain fitness.",
        "session": "SESSION: Exploring exergames"
    },
    {
        "title": "The dept. of hidden stories: playful digital storytelling for children in a public library",
        "authors": "Gavin Wood, John Vines, Madeline Balaam, Nick Taylor, Thomas Smith, Clara Crivellaro, Juliana Mensah, Helen Limon, John Challis, Linda Anderson, Adam Clarke, Peter C. Wright",
        "abstract": "We detail the design of the Dept. of Hidden Stories (DoHS), a mobile-based game to support playful digital storytelling among primary school children in public libraries. Through a process of iterative design in collaboration with library staff and children's writers we designed DoHS to support the potential for playful storytelling through interactions with books. A deployment of DoHS with two classes of 8 to 10 years olds as part of their regular library visits revealed insights related to how to balance the expectations of a child-at-play and the requirement to further develop their creative reading and writing skills. Based on our experiences we recommend that designers create playful digitally based activities that encourage children to explore libraries and experience new interactions with physical books.",
        "session": "SESSION: Narratives and storytelling"
    },
    {
        "title": "Visualizing interactive narratives: employing a branching comic to tell a story and show its readings",
        "authors": "Daniel Andrews, Chris Baber",
        "abstract": "This paper describes the design and evaluation of a branching comic to compare how readers recall a visual narrative when presented as an interactive, digital program, or as a linear sequence on paper. The layout of the comic is used to visualize this data as heat maps and explore patterns of users' recollections. We describe the theoretical justification for this based upon previous work in narrative visualizations, interactive stories and comics. Having tested the comic with school boys aged 11-12; we saw patterns in the data that complement other research in both interactive stories and visualizations. We argue that the heat maps helped identify these patterns, which have implications for future designs and analyses of interactive visual and/or narrative media.",
        "session": "SESSION: Narratives and storytelling"
    },
    {
        "title": "FOCUS: enhancing children's engagement in reading by using contextual BCI training sessions",
        "authors": "Jin Huang, Chun Yu, Yuntao Wang, Yuhang Zhao, Siqi Liu, Chou Mo, Jie Liu, Lie Zhang, Yuanchun Shi",
        "abstract": "Reading is an important aspect of a child's development. Reading outcome is heavily dependent on the level of engagement while reading. In this paper, we present FOCUS, an EEG-augmented reading system which monitors a child's engagement level in real time, and provides contextual BCI training sessions to improve a child's reading engagement. A laboratory experiment was conducted to assess the validity of the system. Results showed that FOCUS could significantly improve engagement in terms of both EEG-based measurement and teachers' subjective measure on the reading outcome.",
        "session": "SESSION: Narratives and storytelling"
    },
    {
        "title": "Sensing a live audience",
        "authors": "Chen Wang, Erik N. Geelhoed, Phil P. Stenton, Pablo Cesar",
        "abstract": "Psychophysiological measurement has the potential to play an important role in audience research. Currently, such research is still in its infancy and it usually involves collecting data in the laboratory, where during each experimental session one individual watches a video recording of a performance. We extend the experimental paradigm by simultaneously measuring Galvanic Skin Response (GSR) of a group of participants during a live performance. GSR data were synchronized with video footage of performers and audience. In conjunction with questionnaire data, this enabled us to identify a strongly correlated main group of participants, describe the nature of their theatre experience and map out a minute-by-minute unfolding of the performance in terms of psycho-physiological engagement. The benefits of our approach are twofold. It provides a robust and accurate mechanism for assessing a performance. Moreover, our infrastructure can enable, in the future, real-time feedback from remote audiences for online performances.",
        "session": "SESSION: Narratives and storytelling"
    },
    {
        "title": "Interface design for older adults with varying cultural attitudes toward uncertainty",
        "authors": "Shathel Haddad, Joanna McGrenere, Claudia Jacova",
        "abstract": "This work reports on the design and evaluation of culturally appropriate technology for older adults. Our design context was Cognitive Testing on a Computer (C-TOC): a self-administered computerized test under development, intended to screen older adults for cognitive impairments. Using theory triangulation of cultural attitudes toward uncertainty, we designed two interfaces (one minimal and one rich) for one C-TOC subtest and hypothesized they would be culturally appropriate for older adult Caucasians and East Asians respectively. We ran an experiment with 36 participants to investigate cultural differences in performance, preference and anxiety. We found that Caucasians preferred the interface with minimal elements (i.e. those essential for the primary task) or had no preference. By contrast, East Asians preferred the rich interface augmented with security and learning support and felt less anxious with it than the minimal.",
        "session": "SESSION: Designing for older adults and demographic change"
    },
    {
        "title": "Social dependency and mobile autonomy: supporting older adults' mobility with ridesharing ict",
        "authors": "Johanna Meurer, Martin Stein, David Randall, Markus Rohde, Volker Wulf",
        "abstract": "Alternative mobility modes for older adults are increasingly important for economic, ecological and social reasons. A promising option is ridesharing, defined as use of the same vehicle by two or more people traveling to a common destination. In particular, mobile computer supported ridesharing provides a promising way to enlarge older adults' mobility choices in addition to private driving and public transportation options. In order to understand the opportunities and obstacles of ridesharing from the point of view of elderly people, we conducted an interview study in order to examining ridesharing experiences. It turns out that \"mobile independence\" and \"decisional autonomy\" are key issues for mobile wellbeing. This partially conflicts with common ridesharing concepts. Hence, we further analyze older adults' strategies dealing with these conflicts and show that these strategies offer departure points for the design ridesharing solutions, which are better suited to the demands of older adults.",
        "session": "SESSION: Designing for older adults and demographic change"
    },
    {
        "title": "From checking on to checking in: designing for low socio-economic status older adults",
        "authors": "Ingrid Arreola, Zan Morris, Matthew Francisco, Kay Connelly, Kelly Caine, Ginger White",
        "abstract": "In this paper we describe the design evolution of a novel technology that collects and displays presence information to be used in the homes of older adults. The first two iterations, the Ambient Plant and Presence Clock, were designed for higher socio-economic status (SES) older adults, whereas the Check-In Tree was designed for low SES older adults. We describe how feedback from older adult participants drove our design decisions, and give an in-depth account of how the Check-In Tree evolved from concept to a final design ready for in situ deployment.",
        "session": "SESSION: Designing for older adults and demographic change"
    },
    {
        "title": "Invisible connections: investigating older people's emotions and social relations around objects",
        "authors": "Kate Vaisutis, Margot Brereton, Toni Robertson, Frank Vetere, Jeannette Durick, Bjorn Nansen, Laurie Buys",
        "abstract": "The advent of the Internet of Things creates an interest in how people might interrelate through and with networks of internet enabled objects. With an emphasis on fostering social connection and physical activity among older people, this preliminary study investigated objects that people over the age of 65 years viewed as significant to them. We conducted contextual interviews in people's homes about their significant objects in order to understand the role of the objects in their lives, the extent to which they fostered emotional and social connections and physical activity, and how they might be augmented through internet connection. Discussion of significant objects generated considerable emotion in the participants. We identified objects of comfort and routine, objects that exhibited status, those that fostered independence and connection, and those that symbolized relationships with loved ones. These findings lead us to consider implications for the design of interconnected objects.",
        "session": "SESSION: Designing for older adults and demographic change"
    },
    {
        "title": "Always somewhere, never there: using critical design to understand database interactions",
        "authors": "Melanie Feinberg, Daniel Carter, Julia Bullard",
        "abstract": "Structured databases achieve effective searching and sorting by enacting sharply delineated category boundaries around their contents. While this enables precise retrieval, it also distorts identities that exist between category lines. A choice between Single and Married, for example, blurs distinctions within the Single group: single, perhaps, merely because same-sex marriage is not legal in one's locality. Sociologists Susan Leigh Star and Geoffrey Bowker describe such residual states as inevitable byproducts of information systems. To minimize residuality, traditional practice for descriptive metadata seeks to demarcate clear and objective classes. In this study, we use critical design to question this position by creating information collections that foreground the residual, instead of diminishing it. We then interrogate our design experiments with solicited critical responses from invited experts and student designers. Inspired by the anthropologist Tim Ingold, we argue that our experiments illuminate a form of interacting with databases characterized by notions of wayfaring, or inhabiting a space, as opposed to notions of transport, or reaching a known destination. We suggest that the form of coherence that shapes a wayfaring database is enacted through its flow, or fluid integration between structure and content.",
        "session": "SESSION: Critical design"
    },
    {
        "title": "Reading critical designs: supporting reasoned interpretations of critical design",
        "authors": "Jeffrey Bardzell, Shaowen Bardzell, Erik Stolterman",
        "abstract": "Critical Design has emerged as an important concept in HCI research and practice. Yet researchers have noted that its uptake has been limited by certain lacks of intellectual infrastructure theories, methodologies, canons and exemplars, and a community of practice. We argue that one way to create this infrastructure is to cultivate a community adept at reading that is, critically interpreting and making reasoned judgments about critical designs. We propose an approach to developing close readings of critical designs, which are both evidence-based and carefully reasoned. The approach highlights analytical units of analysis, the relevance of design languages and social norms, and the analytical contemplation of critical aspects of a design. It is intended to be relatively easy to learn, to try out, and to teach, in the hopes of inviting more members of the HCI community to engage in this practice. We exemplify the approach with readings of two critical designs and reflect on different ways that a design might serve a critical purpose or offer a critical argument about design, society, and the future.",
        "session": "SESSION: Critical design"
    },
    {
        "title": "Designing for slowness, anticipation and re-visitation: a long term field study of the photobox",
        "authors": "William T. Odom, Abigail J. Sellen, Richard Banks, David S. Kirk, Tim Regan, Mark Selby, Jodi L. Forlizzi, John Zimmerman",
        "abstract": "We describe the design, implementation and deployment of Photobox, a domestic technology that prints four or five randomly selected photos from the owner's Flickr collection at random intervals each month. We deployed Photobox in three homes for fourteen months, to explore how the slow pace at which it operates could support experiences of anticipation and re-visitation of the past. Findings reveal changes in attitude toward the device, from frustration to eventual acceptance. Participants drew on the photos to reflect on past life events and reactions indicated a renewed interest for their Flickr collection. Photobox also provoked reflection on technology in and around the home. These findings suggest several opportunities, such as designing for anticipation, better supporting reflection on the past, and, more generally, expanding the slow technology research program within the HCI community.",
        "session": "SESSION: Critical design"
    },
    {
        "title": "Generating implications for design through design research",
        "authors": "Corina Sas, Steve Whittaker, Steven Dow, Jodi Forlizzi, John Zimmerman",
        "abstract": "A central tenet of HCI is that technology should be user-centric, with designs being based around social science findings about users. Nevertheless a repeated but critical challenge in design is translating empirical findings into actionable ideas that inform design, or generating implications for design. Despite various design methods aiming to bridge this gap, knowledge informing design is still seen as problematic. However there has been little empirical exploration into what design researchers understand by such design knowledge, the functions and principles behind their creation. We report on interviews with twelve expert HCI design researchers probing the roles and types of design implications, and the process of generating and evaluating them. We synthesize different types of design implications into a framework to guide their generation. Our findings identify a broader range than previously described, additional sources and heuristics supporting their development as well some important evaluation criteria. We discuss the value of these findings for interaction design research.",
        "session": "SESSION: Critical design"
    },
    {
        "title": "Investigating the effects of encumbrance on one- and two- handed interactions with mobile devices",
        "authors": "Alexander Ng, Stephen A. Brewster, John H. Williamson",
        "abstract": "In this paper, we investigate the effects of encumbrance (carrying typical objects such as shopping bags during interaction) and walking on target acquisition on a touchscreen mobile phone. Users often hold objects and use mobile devices at the same time and we examined the impact encumbrance has on one- and two- handed interactions. Three common input postures were evaluated: two-handed index finger, one-handed preferred thumb and two-handed both thumbs, to assess the effects on performance of carrying a bag in each hand while walking. The results showed a significant decrease in targeting performance when users were encumbered. For example, input accuracy dropped to 48.1% for targeting with the index finger when encumbered, while targeting error using the preferred thumb to input was 4.2mm, an increase of 40% compared to unencumbered input. We also introduce a new method to evaluate the user's preferred walking speed when interacting - PWS&I, and suggest future studies should use this to get a more accurate measure of the user's input performance.",
        "session": "SESSION: Understanding and modeling touch"
    },
    {
        "title": "Modeling the functional area of the thumb on mobile touchscreen surfaces",
        "authors": "Joanna Bergstrom-Lehtovirta, Antti Oulasvirta",
        "abstract": "We present a predictive model for the functional area of the thumb on a touchscreen surface: the area of the interface reachable by the thumb of the hand that is holding the device. We derive a quadratic formula by analyzing the kinematics of the gripping hand. Model fit is high for the thumb-motion trajectories of 20 participants. The model predicts the functional area for a given 1) surface size, 2) hand size, and 3) position of the index finger on the back of the device. Designers can use this model to ensure that a user interface is suitable for interaction with the thumb. The model can also be used inversely - that is, to infer the grips assumed by a given user interface layout.",
        "session": "SESSION: Understanding and modeling touch"
    },
    {
        "title": "Coordination of tilt and touch in one- and two-handed use",
        "authors": "Theophanis Tsandilas, Caroline Appert, Anastasia Bezerianos, David Bonnet",
        "abstract": "Our goal is to enhance navigation in mobile interfaces with quick command gestures that do not make use of explicit mode-switching actions. TilTouch gestures extend the vocabulary of navigation interfaces by combining motion tilt with directional touch. We consider sixteen directional TilTouch gestures that rely on tilt and touch movements along the four main compass directions. An experiment explores their effectiveness for both one-handed and two-handed use. Results identify the best combinations of TilTouch gestures in terms of performance, motor coordination, and user preferences.",
        "session": "SESSION: Understanding and modeling touch"
    },
    {
        "title": "28 frames later: predicting screen touches from back-of-device grip changes",
        "authors": "Mohammad Faizuddin Mohd Noor, Andrew Ramsay, Stephen Hughes, Simon Rogers, John Williamson, Roderick Murray-Smith",
        "abstract": "We demonstrate that front-of-screen targeting on mobile phones can be predicted from back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors placed around a standard phone, we outline a machine learning approach to modelling the grip modulation and inferring front-of-screen touch targets. We experimentally demonstrate that grip is a remarkably good predictor of touch, and we can predict touch position 200ms before contact with an accuracy of 18mm.",
        "session": "SESSION: Understanding and modeling touch"
    },
    {
        "title": "Probabilistic palm rejection using spatiotemporal touch features and iterative classification",
        "authors": "Julia Schwarz, Robert Xiao, Jennifer Mankoff, Scott E. Hudson, Chris Harrison",
        "abstract": "Tablet computers are often called upon to emulate classical pen-and-paper input. However, touchscreens typically lack the means to distinguish between legitimate stylus and finger touches and touches with the palm or other parts of the hand. This forces users to rest their palms elsewhere or hover above the screen, resulting in ergonomic and usability problems. We present a probabilistic touch filtering approach that uses the temporal evolution of touch contacts to reject palms. Our system improves upon previous approaches, reducing accidental palm inputs to 0.016 per pen stroke, while correctly passing 98% of stylus inputs.",
        "session": "SESSION: Understanding and modeling touch"
    },
    {
        "title": "Orientation matters: efficiency of translation-rotation multitouch tasks",
        "authors": "Quan Nguyen, Michael Kipp",
        "abstract": "The translation and rotation of objects with two fingers is a well explored multitouch technique. However, there are some unsolved questions regarding the optimal conditions under which this technique functions best. Does it matter in which direction the movement is oriented? Does parallel or sequential performance of the two operations work best? This study attempts to answer this question using a typical Fitts' Law setup but with varying translation-rotation orientation combinations. The results show that right-oriented movements were faster and easier than left-oriented ones. Movement combinations which went in different directions (translation right, rotation left, and vice versa) were found more tiresome and resulted in more strategy switches compared to equi-directional combinations. Our findings can inform positioning decisions in interaction design and contribute to theoretical adjustments to Fitts' Law.",
        "session": "SESSION: Understanding and modeling touch"
    },
    {
        "title": "MotionMontage: a system to annotate and combine motion takes for 3D animations",
        "authors": "Ankit Gupta, Maneesh Agrawala, Brian Curless, Michael Cohen",
        "abstract": "We present MotionMontage, a system for recording multiple motion takes of a rigid virtual object and compositing them together into a montage. Our system incorporates a Kinect-based performance capture setup that allows animators to create 3D animations by tracking the motion of a rigid physical object and mapping it in realtime onto a virtual object. The animator then temporally annotates the best parts of each take. MotionMontage merges the annotated motions into a single composite montage using a combination of dynamic time warping and optimization of a Semi-Markov Conditional Random Field. Our system also supports the creation of layered animations in which multiple objects are moving at the same time. To aid the animator in coordinating the motions of the objects we provide spatial markers which indicate the positions of previously recorded objects at user-specified points in time. We perform a user study to evaluate the perceived quality of the montages created with our system and find that viewers (including both the original animators and new viewers) generally prefer the animation montage to any individual take.",
        "session": "SESSION: 3D interaction: modeling and prototyping"
    },
    {
        "title": "History assisted view authoring for 3D models",
        "authors": "Hsiang-Ting Chen, Tovi Grossman, Li-Yi Wei, Ryan M. Schmidt, Björn Hartmann, George Fitzmaurice, Maneesh Agrawala",
        "abstract": "3D modelers often wish to showcase their models for sharing or review purposes. This may consist of generating static viewpoints of the model or authoring animated fly-throughs. Manually creating such views is often tedious and few automatic methods are designed to interactively assist the modelers with the view authoring process. We present a view authoring assistance system that supports the creation of informative view points, view paths, and view surfaces, allowing modelers to author the interactive navigation experience of a model. The key concept of our implementation is to analyze the model's workflow history, to infer important regions of the model and representative viewpoints of those areas. An evaluation indicated that the viewpoints generated by our algorithm are comparable to those manually selected by the modeler. In addition, participants of a user study found our system easy to use and effective for authoring viewpoint summaries.",
        "session": "SESSION: 3D interaction: modeling and prototyping"
    },
    {
        "title": "FrameBox and MirrorBox: tools and guidelines to support designers in prototyping interfaces for 3D displays",
        "authors": "Nora Broy, Stefan Schneegass, Florian Alt, Albrecht Schmidt",
        "abstract": "In this paper, we identify design guidelines for stereoscopic 3D (S3D) user interfaces (UIs) and present the MirrorBox and the FrameBox, two UI prototyping tools for S3D displays. As auto-stereoscopy becomes available for the mass market we believe the design of S3D UIs for devices, for example, mobile phones, public displays, or car dashboards, will rapidly gain importance. A benefit of such UIs is that they can group and structure information in a way that makes them easily perceivable for the user. For example, important information can be shown in front of less important information. This paper identifies core requirements for designing S3D UIs and derives concrete guidelines. The requirements also serve as a basis for two depth layout tools we built with the aim to overcome limitations of traditional prototyping when sketching S3D UIs. We evaluated the tools with usability experts and compared them to traditional paper prototyping.",
        "session": "SESSION: 3D interaction: modeling and prototyping"
    },
    {
        "title": "Direct drawing on 3D shapes with automated camera control",
        "authors": "Michaël Ortega, Thomas Vincent",
        "abstract": "We present ACCD, an interaction technique that allows direct drawing of long curves on 3D shapes with a tablet display over both multiple depth layers and multiple viewpoints. ACCD reduces the number of explicit viewpoint manipulations by combining self-occlusion management and automated camera control. As such it enables drawing on occluded faces but also around a 3D shape while keeping a constant drawing precision. Our experimental results indicates the efficacy of ACCD over conventional techniques.",
        "session": "SESSION: 3D interaction: modeling and prototyping"
    },
    {
        "title": "Interactively stylizing camera motion",
        "authors": "Neel S. Joshi, Dan Morris, Michael F. Cohen",
        "abstract": "Movie directors and cinematographers impart style onto video using techniques that are learned through years of experience: camera movement, framing, color, lighting, etc. Without this experience and expensive equipment, it is very difficult to control stylistic aspects of a video. We introduce a novel approach for post-hoc editing of one specific aspect of cinematography -- camera motion style -- via an equalizer-like set of controls that manipulates the power spectra of a video's apparent motion path. We explore free manipulation of apparent camera motion as well as the transfer of motion styles from an example video to a new video to create a wide range of stylistic variations. We report on a user study confirming the ability of non-expert users to create motion styles.",
        "session": "SESSION: 3D interaction: modeling and prototyping"
    },
    {
        "title": "Stimulating a blink: reduction of eye fatigue with visual stimulus",
        "authors": "Tarik Crnovrsanin, Yang Wang, Kwan-Liu Ma",
        "abstract": "Computers make incredible amounts of information available at our fingertips. As computers become integral parts of our lives, we spend more time staring at computer monitor than ever before, sometimes with negative effects. One major concern is the increasing number of people suffering from Computer Vision Syndrome (CVS). CVS is caused by extensive use of computers, and its symptoms include eye fatigue, frequent headaches, dry eyes, and blurred vision. It is possible to partially alleviate CVS if we can remind users to blink more often. We present a prototype system that uses a camera to monitor a user's blink rate, and when the user has not blinked in a while, the system triggers a blink stimulus. We investigated four different types of eye-blink stimulus: screen blurring, screen flashing, border flashing, and pop-up notifications. Users also rated each stimulus type in terms of effectiveness, intrusiveness, and satisfaction. Results from our user studies show that our stimuli are effective in increasing user blink rate with screen blurring being the best.",
        "session": "SESSION: The eyes have it"
    },
    {
        "title": "Smart photo selection: interpret gaze as personal interest",
        "authors": "Tina Caroline Walber, Ansgar Scherp, Steffen Staab",
        "abstract": "Manually selecting subsets of photos from large collections in order to present them to friends or colleagues or to print them as photo books can be a tedious task. Today, fully automatic approaches are at hand for supporting users. They make use of pixel information extracted from the images, analyze contextual information such as capture time and focal aperture, or use both to determine a proper subset of photos. However, these approaches miss the most important factor in the photo selection process: the user. The goal of our approach is to consider individual interests. By recording and analyzing gaze information from the user's viewing photo collections, we obtain information on user's interests and use this information in the creation of personal photo selections. In a controlled experiment with 33 participants, we show that the selections can be significantly improved over a baseline approach by up to 22% when taking individual viewing behavior into account. We also obtained significantly better results for photos taken at an event participants were involved in compared with photos from another event.",
        "session": "SESSION: The eyes have it"
    },
    {
        "title": "Pupil responses during discrete goal-directed movements",
        "authors": "Xianta Jiang, M. Stella Atkins, Geoffrey Tien, Roman Bednarik, Bin Zheng",
        "abstract": "Pupil size is known to correlate with the changes of cognitive task workloads, but how the pupil responds to requirements of basic goal-directed motor tasks involved in human-machine interactions is not yet clear. This work conducted a user study to investigate the pupil dilations during aiming in a tele-operation setting, with the purpose of better understanding how the changes in task requirements are reflected by the changes of pupil size. The task requirements, managed by Fitts' index of difficulty (ID), i.e. the size and distance apart of the targets, were varied between tasks, and pupil responses to different task IDs were recorded. The results showed that pupil diameter can be employed as an indicator of task requirements in goal-directed movements-higher task difficulty evoked higher valley to peak pupil dilation, and the peak pupil dilation occurred after a longer delay. These findings contribute to the foundation for developing methods to objectively evaluate interactive task requirements using pupil parameters during goal-directed movements in HCI.",
        "session": "SESSION: The eyes have it"
    },
    {
        "title": "Collocating interface objects: zooming into maps",
        "authors": "Jon May, Tim Gamble",
        "abstract": "May, Dean and Barnard (2003) used a theoretically based model to argue that objects in a wide range of interfaces should be collocated following screen changes such as a zoom-in to detail. Many existing online maps do not follow this principle, but move a clicked point to the centre of the subsequent display, leaving the user looking at an unrelated location. This paper presents three experiments showing that collocating the point clicked on a map so that the detailed location appears in the place previously occupied by the overview location makes the map easier to use, reducing eye movements and interaction duration. We discuss the benefit of basing design principles on theoretical models so that they can be applied to novel situations, and so designers can infer when to use and not use them.",
        "session": "SESSION: The eyes have it"
    },
    {
        "title": "Showing face in video instruction: effects on information retention, visual attention, and affect",
        "authors": "René F. Kizilcec, Kathryn Papadopoulos, Lalida Sritanyaratana",
        "abstract": "The amount of online educational content is rapidly increasing, particularly in the form of video lectures. The goal is to design video instruction to facilitate an experience that maximizes learning and satisfaction. A widely used but understudied design element in video instruction is the overlay of a small video of the instructor over lecture slides. We conducted an experiment with eye-tracking and recall tests to investigate how adding the instructor's face to video instruction affects information retention, visual attention, and affect. Participants strongly preferred instruction with the face and perceived it as more educational. They spent about 41% of time looking at the face and switched between the face and slide every 3.7 seconds. Consistent with prior work, no significant difference in short- and medium-term recall ability was found. Including the face in video instruction is encouraged based on learners' positive affective response. More fine-grained analytics combining eye-tracking with detailed learning assessment could shed light on the mechanisms by which the face aids or hinders learning.",
        "session": "SESSION: Learning and education"
    },
    {
        "title": "Supporting learners in collecting and exploring data from immersive simulations in collective inquiry",
        "authors": "Michelle Lui, Alex C. Kuhn, Alisa Acosta, Chris Quintana, James D. Slotta",
        "abstract": "Digitally augmented physical spaces (e.g., smart classrooms) offer opportunities to engage students in novel and potentially transformative learning experiences. This paper presents an immersive rainforest simulation and collective inquiry activity where students collect observational data from the environment and explore their peers' data through large visualization displays and personal mobile devices. Two iterations of the design were tested, which resulted in higher quality student explanations constructed. Images were found to be an important source of evidence for the explanations, more so than text-only evidence. We also found that patterns of collective ideas influenced student performance, and that visualizations, as ambient or plenary displays, supported both teacher and students in reviewing patterns of collected data.",
        "session": "SESSION: Learning and education"
    },
    {
        "title": "Learning to see the body: supporting instructional practices in laparoscopic surgical procedures",
        "authors": "Helena M. Mentis, Amine Chellali, Steven Schwaitzberg",
        "abstract": "Learning the practices and the performance of physically manipulating instruments in minimally invasive surgeries is an impetus for the development of surgical training simulators. However, an often-overlooked aspect of surgical training is learning how to see the body through the various imaging mechanisms. With this study, we address the ways in which surgeons demonstrate and instruct residents in seeing the body during minimally invasive surgical procedures. Drawing on observations and analysis of video recordings of minimally invasive surgical operations, we examine how particular anatomy and movement within the body to see and conceptualize that anatomy are made visible by the instructive practices of the surgeon. We use these findings to discuss further directions for minimally invasive surgical training through mechanisms for making the body visible during situated surgical training and surgical training simulation systems.",
        "session": "SESSION: Learning and education"
    },
    {
        "title": "Information-building applications: designing for data exploration and analysis by elementary school students",
        "authors": "Tia Shelley, Leilah Lyons, Tom Moher, Chandan Dasgupta, Brenda Lopez Silva, Alexandra Silva",
        "abstract": "The propagation of Inquiry Based Learning has lead to many more elementary students interacting with authentic scientific tools and practices. However, the more problematic realities of scientific data collection, such as noise and large data sets, are often deliberately hidden from students. Students will need to confront these realities and be able to make skillful data scoping decisions in order to make sense of ever more prevalent large datasets. We dub software designed to support these activities Information-Building Applications (IBAs). This paper presents the design considerations that went into building an exemplar IBA, PhotoMAT (Photo Management and Analysis Tool), a brief user study to show how the solutions enacted by following these principles are taken up by actual students, and a discussion of how the design considerations identified by our work might be applied to another IBA.",
        "session": "SESSION: Learning and education"
    },
    {
        "title": "Remote handshaking: touch enhances video-mediated social telepresence",
        "authors": "Hideyuki Nakanishi, Kazuaki Tanaka, Yuya Wada",
        "abstract": "Since past studies on haptic and visual communication have tended to be isolated from each other, it has remained unclear whether a touch channel can still enrich mediated communication where video and audio channels are already available. To clarify this, we analyzed remote handshaking in which a robot hand that was attached just under a videoconferencing terminal's display moved according to the opening and closing motion of a conversation partner's hand. Combining touch and video channels raises a question as to whether the partner's action of touching a haptic device should be visible to the user. If it can be invisible, the action may be unnecessary, and a unilaterally controlled device may be enough to establish an effective touch channel. Our analysis revealed that the feeling of being close to the partner can be enhanced by mutual touch in which the partner's action needs to occur but should be invisible.",
        "session": "SESSION: Telepresence and connecting over video"
    },
    {
        "title": "Bodies in motion: mobility, presence, and task awareness in telepresence",
        "authors": "Irene Rae, Bilge Mutlu, Leila Takayama",
        "abstract": "Robotic telepresence systems - videoconferencing systems that allow a remote user to drive around in another location - provide an alternative to video-mediated communications as a way of interacting over distances. These systems, which are seeing increasing use in business and medical settings, are unique in their ability to grant the remote user the ability to maneuver in a distant location. While this mobility promises increased feelings of \"being there\" for remote users and thus greater support for task collaboration, whether these promises are borne out, providing benefits in task performance, is unknown. To better understand the role that mobility plays in shaping the remote user's sense of presence and its potential benefits, we conducted a two-by-two (system mobility: stationary vs. mobile; task demands for mobility: low vs. high) controlled laboratory experiment. We asked participants (N=40) to collaborate in a construction task with a confederate via a robotic telepresence system. Our results showed that mobility significantly increased the remote user's feelings of presence, particularly in tasks with high mobility requirements, but decreased task performance. Our findings highlight the positive effects of mobility on feelings of \"being there,\" while illustrating the need to design support for effective use of mobility in high-mobility tasks.",
        "session": "SESSION: Telepresence and connecting over video"
    },
    {
        "title": "Exploring video streaming in public settings: shared geocaching over distance using mobile video chat",
        "authors": "Jason Procyk, Carman Neustaedter, Carolyn Pang, Anthony Tang, Tejinder K. Judge",
        "abstract": "Our research explores the use of mobile video chat in public spaces by people participating in parallel experiences, where both a local and remote person are doing the same activity together at the same time. We prototyped a wearable video chat experience and had pairs of friends and family members participate in 'shared geocaching' over distance. Our results show that video streaming works best for navigation tasks but is more challenging to use for fine-grained searching tasks. Video streaming also creates a very intimate experience with a remote partner, but this can lead to distraction from the 'real world' and even safety concerns. Overall, privacy concerns with streaming from a public space were not typically an issue; however, people tended to rely on assumptions of what were acceptable. The implications are that designers should consider appropriate feedback, user disembodiment, and asymmetry when designing for parallel experiences.",
        "session": "SESSION: Telepresence and connecting over video"
    },
    {
        "title": "A gaze-preserving situated multiview telepresence system",
        "authors": "Ye Pan, Anthony Steed",
        "abstract": "Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user. We propose a low-cost cylindrical videoconferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table. We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen. The cylindrical screen reflects each image to a narrow viewing zone. The use of such a situated display allows participants to see the remote person from multiple viewing directions. We compare our system to three alternative display configurations. We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.",
        "session": "SESSION: Telepresence and connecting over video"
    },
    {
        "title": "OneSpace: shared visual scenes for active freeplay",
        "authors": "Maayan Cohen, Kody R. Dillman, Haley MacLeod, Seth Hunter, Anthony Tang",
        "abstract": "Children engage in free play for emotional, physical and social development; researchers have explored supporting free play between physically remote playmates using videoconferencing tools. We show that the configuration of the video conferencing setup affects play. Specifically, we show that a shared visual scene configuration promotes fundamentally active forms of engaged, co-operative play.",
        "session": "SESSION: Telepresence and connecting over video"
    },
    {
        "title": "i-dentity: innominate movement representation as engaging game element",
        "authors": "Jayden Garner, Gavin Wood, Sebastiaan Pijnappel, Martin Murer, Florian Mueller",
        "abstract": "Movement-based digital games typically make it clear whose movement representation belongs to which player. In contrast, we argue that selectively concealing whose movement controls which representation can facilitate engaging play experiences. We call this \"innominate movement representation\" and explore this opportunity through our game \"i-dentity\", where players have to guess who makes everyone's controller light up based on his/her movements. Our work reveals five dimensions for the design of innominate movement representation: concealing the association between movement and representation; number of represented movements; number of players with representations; location of representation in relation to the body and technical attributes of representation. We also present five strategies for how innominate representation can be embedded into a play experience. With our work we hope to expand the range of digital movement games.",
        "session": "SESSION: Exergame design"
    },
    {
        "title": "Movement-based game guidelines",
        "authors": "Florian Mueller, Katherine Isbister",
        "abstract": "Movement-based digital games are becoming increasingly popular, yet there is limited comprehensive guidance on how to design these games. We present a set of guidelines for movement-based game design that has emerged from our research-based game development practice. These guidelines have been examined and refined by 14 movement-based game design experts with experience in the academic, independent and commercial game development domains. We contextualize the guidelines using current findings about movement-based game and interaction design, taken from both published research papers and game design venues. Our primary contribution is a body of generative intermediate-level knowledge in the design research tradition that is readily accessible and actionable for the design of future movement-based games.",
        "session": "SESSION: Exergame design"
    },
    {
        "title": "Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames",
        "authors": "Kathrin Maria Gerling, Matthew Miller, Regan L. Mandryk, Max Valentin Birk, Jan David Smeddinck",
        "abstract": "Game balancing can help players with different skill levels play multiplayer games together; however, little is known about how the balancing approach affects performance, experience, and self-esteem'especially when differences in player strength result from given abilities, rather than learned skill. We explore three balancing approaches in a dance game and show that the explicit approach commonly used in commercial games reduces self-esteem and feelings of relatedness in dyads, whereas hidden balancing improves self-esteem and reduces score differential without affecting game outcome. We apply our results in a second study with dyads where one player had a mobility disability and used a wheelchair. By making motion-based games accessible for people with different physical abilities, and by enabling people with mobility disabilities to compete on a par with able-bodied peers, we show how to provide empowering experiences through enjoyable games that have the potential to increase physical activity and self-esteem.",
        "session": "SESSION: Exergame design"
    },
    {
        "title": "Supporting the creative game design process with exertion cards",
        "authors": "Florian Mueller, Martin R. Gibbs, Frank Vetere, Darren Edge",
        "abstract": "Advances in sensing technologies have led to research into exertion games that support physically effortful experiences. Despite the existence of theoretical frameworks that can be used to analyze such exertion experiences, there are few tools to support the hands-on practice of exertion game design. To address this, we present a set of design cards based on the \"Exertion Framework\", grounded in our experience of creating exertion games for over a decade. We present results demonstrating the value and utility of these Exertion Cards based on our studies of their use in three workshops held over seven sessions with 134 design students and experts. We also articulate lessons learned from transforming a theoretical framework into a design tool that aims to support designers in their practice.",
        "session": "SESSION: Exergame design"
    },
    {
        "title": "WADE: simplified GUI add-on development for third-party software",
        "authors": "Xiaojun Meng, Shengdong Zhao, Yongfeng Huang, Zhongyuan Zhang, James Eagan, Ramanathan Subramanian",
        "abstract": "We present the WADE Integrated Development Environment (IDE), which simplifies interface and functionality modification of existing third-party software without access to source code. WADE clones the Graphical User Interface (GUI) of a host program through dynamic-link library (DLL) injection, enabling modifications to (1) the GUI in a WYSIWYG fashion and (2) software functionality. We compare WADE with an alternative state-of-the-art runtime toolkit overloading approach in a user-study, whose results demonstrate that WADE significantly simplifies the task of GUI-based add-on development.",
        "session": "SESSION: Designing and modeling GUIs"
    },
    {
        "title": "Pixel-based methods for widget state and style in a runtime implementation of sliding widgets",
        "authors": "Morgan E. Dixon, Gierad Laput, James A. Fogarty",
        "abstract": "Pixel-based methods offer unique potential for modifying existing interfaces independent of their underlying implementation. Prior work has demonstrated a variety of modifications to existing interfaces, including accessibility enhancements, interface language translation, testing frameworks, and interaction techniques. But pixel-based methods have also been limited in their understanding of the interface and therefore the complexity of modifications they can support. This work examines deeper pixel-level understanding of widgets and the resulting capabilities of pixel-based runtime enhancements. Specifically, we present three new sets of methods: methods for pixel-based modeling of widgets in multiple states, methods for managing the combinatorial complexity that arises in creating a multitude of runtime enhancements, and methods for styling runtime enhancements to preserve consistency with the design of an existing interface. We validate our methods through an implementation of Moscovich et al.'s Sliding Widgets, a novel runtime enhancement that could not have been implemented with prior pixel-based methods.",
        "session": "SESSION: Designing and modeling GUIs"
    },
    {
        "title": "The usability of CommandMaps in realistic tasks",
        "authors": "Joey Scarr, Andy Cockburn, Carl Gutwin, Andrea Bunt, Jared E. Cechanowicz",
        "abstract": "CommandMaps are a promising interface technique that flattens command hierarchies and exploits human spatial memory to provide rapid access to commands. CommandMaps have performed favorably in constrained cued-selection studies, but have not yet been tested in the context of real tasks. In this paper we present two real-world implementations of CommandMaps: one for Microsoft Word and one for an image editing program called Pinta. We use these as our experimental platforms in two experiments. In the first, we show that CommandMaps demonstrate performance and subjective advantages in a realistic task. In the second, we observe naturalistic use of CommandMaps over the course of a week, and gather qualitative data from interviews, questionnaires, and conversations. Our results provide substantial insight into users' reactions to CommandMaps, showing that they are positively received by users and allowing us to provide concrete recommendations to designers regarding when and how they should be implemented in real applications.",
        "session": "SESSION: Designing and modeling GUIs"
    },
    {
        "title": "Novice use of a predictive human performance modeling tool to produce UI recommendations",
        "authors": "Kyung Wha Hong, Robert St. Amant",
        "abstract": "This note describes two studies of the use of a performance modeling tool, CogTool, for making recommendations to improve a user interface. The first study replicates findings by Bonnie John [7]: the rates at which novice modelers made correct recommendations (88.1%) and supported them (68.2%) are close to the values in John's study (91.7% and 75.1%, respectively). A follow-on study of novice modelers on the same task without CogTool produced sig-nificantly lower values. CogTool improves the UI design recommendations made by novices.",
        "session": "SESSION: Designing and modeling GUIs"
    },
    {
        "title": "On the selection of 2D objects using external labeling",
        "authors": "Jan Balata, Ladislav Cmolik, Zdenek Mikovec",
        "abstract": "We present an external labeling laid over small and/or overlapping 2D objects as an efficient representation for their selection. The approximation of objects with points allows us to transform the labeling problem to graph layout problem, which we solve by means of force-based algorithm. The input parameters allow us to influence the resulting layout of label boxes (e.g. to adapt their distance for imprecise input devices). In a study with 15 participants two implementations of our algorithm were compared against labeling method, where all label boxes share the same offset from corresponding objects. The results of the study show that implementation using a special functionality (temporary freezing of the label box position recalculation) was 14% faster with a comparable accuracy. The subjective evaluation revealed that the implementation with temporary freezing is perceived as most comfortable, fastest and most accurate. The implementation without temporary freezing showed much higher error rate and cannot be recommended.",
        "session": "SESSION: Designing and modeling GUIs"
    },
    {
        "title": "Real-time feedback for improving medication taking",
        "authors": "Matthew L. Lee, Anind K. Dey",
        "abstract": "Medication taking is a self-regulatory process that requires individuals to self-monitor their medication taking behaviors, but this can be difficult because medication taking is such a mundane, unremarkable behavior. Ubiquitous sensing systems have the potential to sense everyday behaviors and provide the objective feedback necessary for self-regulation of medication taking. We describe an unobtrusive sensing system consisting of a sensor-augmented pillbox and an ambient display that provides near real-time visual feedback about how well medications are being taken. In contrast to other systems that focus on reminding before medication taking, our approach uses feedback after medication taking to allow the individual to develop their own routines through self-regulation. We evaluated this system in the homes of older adults in a 10-month deployment. Feedback helped improve the consistency of medication-taking behaviors as well as increased ratings of self-efficacy. However, the improved performance did not persist after the feedback display was removed, because individuals had integrated the feedback display into their routines to support their self-awareness, identify mistakes, guide the timing of medication taking, and provide a sense of security that they are taking their medications well. Finally, we reflect on design considerations for feedback systems to support the process of self-regulation of everyday behaviors.",
        "session": "SESSION: Health and everyday life"
    },
    {
        "title": "Don't forget your pill!: designing effective medication reminder apps that support users' daily routines",
        "authors": "Katarzyna Stawarz, Anna L. Cox, Ann Blandford",
        "abstract": "Despite the fact that a third of all cases of unintentional medication non-adherence are caused by simple forgetfulness, the majority of interventions neglect this issue. Even though patients have access to smartphone applications (\"apps\") designed to help them remember medication, neither their quality nor effectiveness has been evaluated yet. We report the findings of a functionality review of 229 medication reminder apps and a thematic analysis of their 1,012 user reviews. Our research highlights the gap between the theory and practice: while the literature shows that many medication regimens are habitual in nature and the presence of daily routines supports remembering, existing apps rely on timer-based reminders. To address this disparity, we present design requirements for building medication reminders that support the routine aspect of medication-taking and its individual nature, and demonstrate how they could be implemented to move from passive alerts to a smarter memory and routine assistant.",
        "session": "SESSION: Health and everyday life"
    },
    {
        "title": "@BabySteps: design and evaluation of a system for using twitter for tracking children's developmental milestones",
        "authors": "Hyewon Suh, John R. Porter, Alexis Hiniker, Julie A. Kientz",
        "abstract": "The tracking of developmental milestones in young children is an important public health goal for ensuring early detection and treatment for developmental delay. While numerous paper-based and web-based solutions are available for tracking milestones, many busy parents often forget to enter information on a regular basis. To help address this need, we have developed an interactive system called @BabySteps for allowing parents who use Twitter to track and respond to tweets about developmental milestones using a special hashtag syntax. Parent responses are parsed automatically and written into a central database that can be accessed via the web. We deployed @BabySteps with 14 parents over a 3-week period and found that parents were able to learn how to use the system to track their children's progress, with some using it to communicate with other parents. The study helped to identify a number of ways to improve the approach, including simplifying the hashtag syntax, allowing for private responses via direct messaging, and improving the social component. We provide a discussion of lessons learned and suggestions for the design of interactive public health systems.",
        "session": "SESSION: Health and everyday life"
    },
    {
        "title": "DoDo game, a color vision deficiency screening test for young children",
        "authors": "Linh Chi Nguyen, Ellen Yi-Luen Do, Audrey Chia, Yuan Wang, Henry Been-Lirn Duh",
        "abstract": "This paper presents 'DoDo's Catching Adventure,' a new color vision deficient screening test for young children. Early detection of color blindness among children is useful for parents and teachers to better understand children's needs, to overcome difficulties in learning, and for life and career planning. Unfortunately, current color screening tests are not designed for young children; most require more advanced verbal or cognitive skills. DoDo game has taken a new approach by embedding game elements into a color vision screening test. A user study conducted at Singapore National Eye Centre on twenty-eight children, identified fourteen as Red-Green deficient subjects as did by Ishihara screening test, showed that DoDo was adequately effective in identifying Red-Green color vision deficiency and comparable to two current gold standard colorblind tests, Ishihara and D15.",
        "session": "SESSION: Health and everyday life"
    },
    {
        "title": "The influence of emotion on number entry errors",
        "authors": "Paul Cairns, Pratyush Pandab, Christopher Power",
        "abstract": "Given the proliferation of devices like infusion pumps in hospitals, number entry and in particular number entry error is an emerging important concern in HCI. There are clearly design features that could greatly improve accuracy in entering numbers but the context of the task could also play an important role. In particular, the emotional state of a person is known to strongly influence their response to a difficult situation and hence the errors that they make. In this paper, we consider the impact of the emotional state of the user on the accuracy with which people enter numbers. Our experiment shows that participants who are in a more positive emotional state are more accurate. The effect is small but could be very important when considering the potentially highly-charged emotional contexts where many healthcare devices are used.",
        "session": "SESSION: Health and everyday life"
    },
    {
        "title": "Both complete and correct?: multi-objective optimization of touchscreen keyboard",
        "authors": "Xiaojun Bi, Tom Ouyang, Shumin Zhai",
        "abstract": "Correcting erroneous input (i.e., correction) and completing a word based on partial input (i.e., completion) are two important \"smart\" capabilities of a modern intelligent touchscreen keyboard. However little is known whether these two capabilities are conflicting or compatible with each other in the keyboard parameter tuning. Applying computational optimization methods, this work explores the optimality issues related to them. The work demonstrates that it is possible to simultaneously optimize a keyboard algorithm for both correction and completion. The keyboard simultaneously optimized for both introduces no compromise to correction and only a slight compromise to completion when compared to the keyboards exclusively optimized for one objective. Our research also demonstrates the effectiveness of the proposed optimization method in keyboard algorithm design, which is based on the Pareto multi-objective optimization and the Metropolis algorithm. For the development and test datasets used in our experiments, computational optimization improved the correction accuracy rate by 8.3% and completion power by 17.7%.",
        "session": "SESSION: Text entry and evaluation"
    },
    {
        "title": "Uncertain text entry on mobile devices",
        "authors": "Daryl Weir, Henning Pohl, Simon Rogers, Keith Vertanen, Per Ola Kristensson",
        "abstract": "Users often struggle to enter text accurately on touchscreen keyboards. To address this, we present a flexible decoder for touchscreen text entry that combines probabilistic touch models with a language model. We investigate two different touch models. The first touch model is based on a Gaussian Process regression approach and implicitly models the inherent uncertainty of the touching process. The second touch model allows users to explicitly control the uncertainty via touch pressure. Using the first model we show that the character error rate can be reduced by up to 7% over a baseline method, and by up to 1.3% over a leading commercial keyboard. Using the second model we demonstrate that providing users with control over input certainty reduces the amount of text users have to correct manually and increases the text entry rate.",
        "session": "SESSION: Text entry and evaluation"
    },
    {
        "title": "Mobile attachment causes and consequences for emotional bonding with mobile phones",
        "authors": "Alexander Meschtscherjakov, David Wilfinger, Manfred Tscheligi",
        "abstract": "This paper addresses the phenomenon of emotional attachments to mobile phones. We introduce the term \"mobile attachment\" and define it as a bond between a person's self and a mobile phone that varies in strength. Based on a critical reflection of interdisciplinary literature, a conceptual mobile attachment model is developed. Within this model causes, consequences and influencing factors of mobile attachment are exposed and elaborated. We argue that mobile attachment emerges when the mobile phone becomes part of the user's self concept. The link between the user and their mobile phone may be fostered when it empowers, enriches, or gratifies the user's self. Attachment causes lead to \"design space determinants\" that enable user experience designers to design for mobile attachment. Attachment consequences may be operationalized for user experience evaluation.",
        "session": "SESSION: Emotions and mobiles"
    },
    {
        "title": "Hooked on smartphones: an exploratory study on smartphone overuse among college students",
        "authors": "Uichin Lee, Joonwon Lee, Minsam Ko, Changhun Lee, Yuhwan Kim, Subin Yang, Koji Yatani, Gahgene Gweon, Kyong-Mee Chung, Junehwa Song",
        "abstract": "The negative aspects of smartphone overuse on young adults, such as sleep deprivation and attention deficits, are being increasingly recognized recently. This emerging issue motivated us to analyze the usage patterns related to smartphone overuse. We investigate smartphone usage for 95 college students using surveys, logged data, and interviews. We first divide the participants into risk and non-risk groups based on self-reported rating scale for smartphone overuse. We then analyze the usage data to identify between-group usage differences, which ranged from the overall usage patterns to app-specific usage patterns. Compared with the non-risk group, our results show that the risk group has longer usage time per day and different diurnal usage patterns. Also, the risk group users are more susceptible to push notifications, and tend to consume more online content. We characterize the overall relationship between usage features and smartphone overuse using analytic modeling and provide detailed illustrations of problematic usage behaviors based on interview data.",
        "session": "SESSION: Emotions and mobiles"
    },
    {
        "title": "Broken display = broken interface': the impact of display damage on smartphone interaction",
        "authors": "Florian Schaub, Julian Seifert, Frank Honold, Michael Müller, Enrico Rukzio, Michael Weber",
        "abstract": "This paper is the first to assess the impact of touchscreen damage on smartphone interaction. We gathered a dataset consisting of 95 closeup images of damaged smartphones and extensive information about a device's usage history, damage severity, and impact on use. 88% of our participants continued to use their damaged smartphone for at least three months; 32% plan to use it for another year or more, mainly due to high repair and replacement costs. From the dataset, we identified three categories of damaged smartphone displays. Reading and text input were most affected. Further interviews (n=11) revealed that users adapt to damage with diverse coping strategies, closely tailored to specific interaction issues. In total, we identified 23 different strategies. Based on our results, we proposed guidelines for interaction design in order to provide a positive user experience when display damage occurs.",
        "session": "SESSION: Emotions and mobiles"
    },
    {
        "title": "Leakiness and creepiness in app space: perceptions of privacy and mobile app use",
        "authors": "Irina Shklovski, Scott D. Mainwaring, Halla Hrund Skúladóttir, Höskuldur Borgthorsson",
        "abstract": "Mobile devices are playing an increasingly intimate role in everyday life. However, users can be surprised when informed of the data collection and distribution activities of apps they install. We report on two studies of smartphone users in western European countries, in which users were confronted with app behaviors and their reactions assessed. Users felt their personal space had been violated in \"creepy\" ways. Using Altman's notions of personal space and territoriality, and Nissenbaum's theory of contextual integrity, we account for these emotional reactions and suggest that they point to important underlying issues, even when users continue using apps they find creepy.",
        "session": "SESSION: Privacy"
    },
    {
        "title": "Personalisation and privacy in future pervasive display networks",
        "authors": "Nigel Davies, Marc Langheinrich, Sarah Clinch, Ivan Elhart, Adrian Friday, Thomas Kubitza, Bholanathsingh Surajbali",
        "abstract": "There is increasing interest in using digital signage to deliver highly personalised content. However, display personalization presents a number of architectural design challenges in particular, how best to provide personalisation without unduly compromising viewers' privacy. While previous research has focused on understanding specific elements of the overall vision, our work presents details of the first significant attempt at a system that integrates future pervasive display networks and mobile devices to support display personalisation. We describe a series of usage models and design goals for display personalisation and then present Tacita, a system that supports these models and goals. Our architecture includes mobile, display and cloud-based elements and provides comprehensive personalisation features while preventing the creation of user profiles within the display infrastructure, thus helping to preserve users' privacy. An initial evaluation of our prototype implementation of the architecture is also included and demonstrates the viability of the Tacita approach.",
        "session": "SESSION: Privacy"
    },
    {
        "title": "A field trial of privacy nudges for facebook",
        "authors": "Yang Wang, Pedro Giovanni Leon, Alessandro Acquisti, Lorrie Faith Cranor, Alain Forget, Norman Sadeh",
        "abstract": "Anecdotal evidence and scholarly research have shown that Internet users may regret some of their online disclosures. To help individuals avoid such regrets, we designed two modifications to the Facebook web interface that nudge users to consider the content and audience of their online disclosures more carefully. We implemented and evaluated these two nudges in a 6-week field trial with 28 Facebook users. We analyzed participants' interactions with the nudges, the content of their posts, and opinions collected through surveys. We found that reminders about the audience of posts can prevent unintended disclosures without major burden; however, introducing a time delay before publishing users' posts can be perceived as both beneficial and annoying. On balance, some participants found the nudges helpful while others found them unnecessary or overly intrusive. We discuss implications and challenges for designing and evaluating systems to assist users with online disclosures.",
        "session": "SESSION: Privacy"
    },
    {
        "title": "In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies",
        "authors": "Tamara Denning, Zakariya Dehlawi, Tadayoshi Kohno",
        "abstract": "Augmented reality (AR) devices are poised to enter the market. It is unclear how the properties of these devices will affect individuals' privacy. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in cafés and interviewed 31 bystanders regarding their reactions to a co-located AR device. Participants were predominantly split between having indifferent and negative reactions to the device. Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology's lack of prevalence. Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken. Participants expressed interest in being asked permission before being recorded and in recording-blocking devices. We use the interview results to guide an exploration of design directions for privacy-mediating technologies.",
        "session": "SESSION: Privacy"
    },
    {
        "title": "Listening to the forest and its curators: lessons learnt from a bioacoustic smartphone application deployment",
        "authors": "Stuart Moran, Nadia Pantidi, Tom Rodden, Alan Chamberlain, Chloe Griffiths, Davide Zilli, Geoff Merrett, Alex Rogers",
        "abstract": "Our natural environment is complex and sensitive, and is home to a number of species on the verge of extinction. Surveying is one approach to their preservation, and can be supported by technology. This paper presents the deployment of a smartphone-based citizen science biodiversity application. Our findings from interviews with members of the biodiversity community revealed a tension between the technology and their established working practices. From our experience, we present a series of general guidelines for those designing citizen science apps.",
        "session": "SESSION: Issues that matter"
    },
    {
        "title": "Making public things: how HCI design can express matters of concern",
        "authors": "Carl DiSalvo, Jonathan Lukens, Thomas Lodato, Tom Jenkins, Tanyoung Kim",
        "abstract": "Science studies scholar Bruno Latour suggests that contemporary democracy is shifting from \"matters of fact\"to \"matters of concern\": contentious conditions entwined with everyday life. What is the role of human-computer interaction (HCI) design in this shift' In this paper we draw from five design projects to explore how design can express matters of concern by communicating the factors and consequences of issues. In the process, we consider the role of design in contributing to the formation of publics and discuss an emerging orientation to publics in HCI design.",
        "session": "SESSION: Issues that matter"
    },
    {
        "title": "Just awful enough: the functional dysfunction of the something awful forums",
        "authors": "Jessica Annette Pater, Yacin Nadji, Elizabeth D. Mynatt, Amy S. Bruckman",
        "abstract": "The Something Awful Forums (SAF) is an online community comprised of a loosely connected federation of forums, united in a distinctive brand of humor with a focus on the quality of member contributions. In this case study we find that the site has sustained success while deviating from common conventions and norms of online communities. Humor and the quality of content contributed by SAF members foster practices that seem counterintuitive to the development of a stable and thriving community. In this case study we show how design decisions are contextual and inter-dependent and together these heuristics create a different kind of online third place that challenges common practices.",
        "session": "SESSION: Issues that matter"
    },
    {
        "title": "Everyday ideation: all of my ideas are on pinterest",
        "authors": "Rhema Linder, Clair Snodgrass, Andruid Kerne",
        "abstract": "We develop new understanding of how people engage in digital curation. We interview twenty users of Pinterest, a social curation platform. We find that through collecting, organizing, and sharing image bookmarks, users engage in processes of everyday ideation. That is, they use digital found objects as creative resources to develop ideas for shaping their lives. Curators assemble information into new contexts, forming and sharing ideas with practical and emotional value. We investigate cognitive and social aspects of creativity that affect the digital curation practices of everyday ideation. We derive implications for the design of curation environments that support information-based ideation.",
        "session": "SESSION: Understanding and using social media"
    },
    {
        "title": "Understanding user adaptation strategies for the launching of facebook timeline",
        "authors": "Pamela Wisniewski, Heng Xu, Yunan Chen",
        "abstract": "This paper applies coping theory to understand user adaptation strategies to major interface changes on Social Networking Sites (SNSs). Specifically, we qualitatively examine 1,149 user comments posted to the Facebook's official Timeline blog in order to get a large and unobtrusive sample of real Facebook users' perceptions about the launch of Timeline. Our data suggests a high level of stress associated with the transition to the new interface introduced by Timeline. We also found evidence which suggests that increasing users' perceptions of control over major interface changes may help facilitate user adaptation to these changes. This study offers valuable insights to SNSs for mitigating user stress and facilitating successful adaptation during major interface changes.",
        "session": "SESSION: Understanding and using social media"
    },
    {
        "title": "Curation through use: understanding the personal value of social media",
        "authors": "Xuan Zhao, Siân E. Lindley",
        "abstract": "Content generation on social network sites has been considered mainly from the perspective of individuals interacting with social network contacts. Yet research has also pointed to the potential for social media to become a meaningful personal archive over time. The aim of this paper is to consider how social media, over time and across sites, forms part of the wider digital archiving space for individuals. Our findings, from a qualitative study of 14 social media users, highlight how although some sites are more associated with 'keepable' social media than others, even those are not seen as archives in the usual sense of the word. We show how this perception is bound up with five contradictions, which center on social media as curated, as a reliable repository of meaningful content, as readily encountered and as having the potential to present content as a compelling narrative. We conclude by highlighting opportunities for design relating to curation through use and what this implies for personal digital archives, which are known to present difficulties in terms of curation and re-finding.",
        "session": "SESSION: Understanding and using social media"
    },
    {
        "title": "Together alone: motivations for live-tweeting a television series",
        "authors": "Steven Schirra, Huan Sun, Frank Bentley",
        "abstract": "In this paper, we explore motivations for live-tweeting across a season of a television show. Using the third season of Downton Abbey as a case study, we followed 2,234 live-tweeters from the show's premiere episode to its finale, finding that nearly a third of users returned each week to tweet. Semi-structured interviews with 11 diverse live-tweeters revealed that the decision to live-tweet is dependent upon a variety of personal considerations and social conventions forming around this emerging TV viewing practice. This includes the desire to feel connected to a larger community that is interested in the show. Participants actively sought to protect the user experience of others by following good live-tweeting \"etiquette\", including limiting their number of posts and censoring content that might spoil the show for others. Over time, live-tweeting helped users build and maintain a network of fellow Downton Abbey viewers with shared interests.",
        "session": "SESSION: Understanding and using social media"
    },
    {
        "title": "Documentscape: intertextuality, sequentiality, & autonomy at work",
        "authors": "Lars Rune Christensen, Pernille Bjorn",
        "abstract": "On the basis of an ethnographic field study, this article introduces the concept of documentscape to the analysis of document-centric work practices. The concept of documentscape refers to the entire ensemble of documents in their mutual intertextual interlocking. Providing empirical data from a global software development case, we show how hierarchical structures and sequentiality across the interlocked documents are critical to how actors make sense of the work of others and what to do next in a geographically distributed setting. Furthermore, we found that while each document is created as part of a quasi-sequential order, this characteristic does not make the document, as a single entity, into a stable object. Instead, we found that the documents were malleable and dynamic while suspended in intertextual structures. Our concept of documentscape points to how the hierarchical structure, sequentiality, and authorless nature of documents serve as a constitutive platform for the development of iterative and emergent work practices, making it possible for highly distributed actors to collaborate with limited communication, as the documentscape serves as a vehicle of coordination.",
        "session": "SESSION: Working together"
    },
    {
        "title": "Cloudy forecast: an exploration of the factors underlying shared repository use",
        "authors": "Charlotte Massey, Thomas Lennig, Steve Whittaker",
        "abstract": "Many teams are now adopting shared repositories for their work. Such adoption is paradoxical, however, as past research has repeatedly shown major co-organizational barriers; teams cannot agree a common organizational scheme, making it difficult to retrieve information organized by others. Another barrier is email competition; email provides a reliable alternative for distributing files that are then personally organized. To address this paradox, we explored how 27 participants actively using shared repositories overcome these barriers in a qualitative study. We found teams addressed co-organization using 4 strategies. First they create ContentMaps that provide explicit structure to organize shared information. Participants also co-organize using implicit strategies based on task structure, expertise, and tool affordances. Greater shared repository use also leads to a changed role for email. Versioning problems mean email is not used for distributing attachments, instead for task management. We present technical implications suggesting how new tools might be better integrated with email facilitating these continued email uses.",
        "session": "SESSION: Working together"
    },
    {
        "title": "Designing information savvy societies: an introduction to assessability",
        "authors": "Andrea Forte, Nazanin Andalibi, Thomas Park, Heather Willever-Farr",
        "abstract": "This paper provides first steps toward an empirically grounded design vocabulary for assessable design as an HCI response to the global need for better information literacy skills. We present a framework for synthesizing literatures called the Interdisciplinary Literacy Framework and use it to highlight gaps in our understanding of information literacy that HCI as a field is particularly well suited to fill. We report on two studies that lay a foundation for developing guidelines for assessable information system design. The first is a study of Wikipedians', librarians', and laypersons' information assessment practices from which we derive two important features of assessable designs: information provenance and stewardship. The second is an experimental study in which we operationalize these concepts in designs and test them using Amazon Mechanical Turk (MTurk).",
        "session": "SESSION: Working together"
    },
    {
        "title": "Addressing misconceptions about code with always-on programming visualizations",
        "authors": "Tom Lieber, Joel R. Brandt, Rob C. Miller",
        "abstract": "We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript code editor. By displaying real-time information about how code actually behaves during execution, Theseus proactively addresses misconceptions by drawing attention to similarities and differences between the programmer's idea of what code does and what it actually does. To understand how programmers would respond to this kind of an always-on visualization, we ran a lab study with graduate students, and interviewed 9 professional programmers who were asked to use Theseus in their day-to-day work. We found that users quickly adopted strategies that are unique to always-on, real-time visualizations, and used the additional information to guide their navigation through their code.",
        "session": "SESSION: Programming and development tools"
    },
    {
        "title": "Emergent, crowd-scale programming practice in the IDE",
        "authors": "Ethan Fast, Daniel Steffee, Lucy Wang, Joel R. Brandt, Michael S. Bernstein",
        "abstract": "While emergent behaviors are uncodified across many domains such as programming and writing, interfaces need explicit rules to support users. We hypothesize that by codifying emergent programming behavior, software engineering interfaces can support a far broader set of developer needs. To explore this idea, we built Codex, a knowledge base that records common practice for the Ruby programming language by indexing over three million lines of popular code. Codex enables new data-driven interfaces for programming systems: statistical linting, identifying code that is unlikely to occur in practice and may constitute a bug; pattern annotation, automatically discovering common programming idioms and annotating them with metadata using expert crowdsourcing; and library generation, constructing a utility package that encapsulates and reflects emergent software practice. We evaluate these applications to find Codex captures a broad swatch of programming practice, statistical linting detects problematic code snippets, and pattern annotation discovers nontrivial idioms such as basic HTTP authentication and database migration templates. Our work suggests that operationalizing practice-driven knowledge in structured domains such as programming can enable a new class of user interfaces.",
        "session": "SESSION: Programming and development tools"
    },
    {
        "title": "Design considerations for parallel performance tools",
        "authors": "Roman Atachiants, David Gregg, Kim Jarvis, Gavin Doherty",
        "abstract": "In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers' needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the design of software tools to support developers in the endeavour of parallel programming.",
        "session": "SESSION: Programming and development tools"
    },
    {
        "title": "The patchworks code editor: toward faster navigation with less code arranging and fewer navigation mistakes",
        "authors": "Austin Z. Henley, Scott D. Fleming",
        "abstract": "Increasingly, people are faced with navigating large information spaces, and making such navigation efficient is of paramount concern. In this paper, we focus on the problems programmers face in navigating large code bases, and propose a novel code editor, Patchworks, that addresses the problems. In particular, Patchworks leverages two new interface idioms - the patch grid and the ribbon - to help programmers navigate more quickly, make fewer navigation errors, and spend less time arranging their code. To validate Patchworks, we conducted a user study that compared Patchworks to two existing code editors: the traditional file-based editor, Eclipse, and the newer canvas-based editor, Code Bubbles. Our results showed (1) that programmers using Patchworks were able to navigate significantly faster than with Eclipse (and comparably with Code Bubbles), (2) that programmers using Patchworks made significantly fewer navigation errors than with Code Bubbles or Eclipse, and (3) that programmers using Patchworks spent significantly less time arranging their code than with Code Bubbles (and comparably with Eclipse).",
        "session": "SESSION: Programming and development tools"
    },
    {
        "title": "A novel knee rehabilitation system for the home",
        "authors": "Mobolaji Ayoade, Lynne Baillie",
        "abstract": "In this paper, we describe the design and evaluation of an interactive home-based rehabilitation visualisation system used by a wide variety of ages (users in our studies were aged from 47-89) to undertake rehabilitation in the home following knee replacement surgery. We present the rehabilitation visualization system and the results of a randomized controlled study in which we investigated the usability and feasibility of the system in the home. We found that our users were able to use the system successfully for their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared to the current rehabilitation care. Finally we highlight the lessons learned which will benefit prospective designers of home rehabilitation technology in ensuring successful home evaluations in clinical rehabilitation.",
        "session": "SESSION: Interactive technologies for rehabilitation"
    },
    {
        "title": "GaitAssist: a daily-life support and training system for parkinson's disease patients with freezing of gait",
        "authors": "Sinziana Mazilu, Ulf Blanke, Michael Hardegger, Gerhard Tröster, Eran Gazit, Jeffrey M. Hausdorff",
        "abstract": "Patients with Parkinson's disease often experience freezing of gait, which bears a high risk of falling, a prevalent cause for morbidity and mortality. In this work we present GaitAssist, a wearable system for freezing of gait support in daily life. The system provides real-time auditory cueing after the onset of freezing episodes. Furthermore, GaitAssist implements training exercises to learn how to handle freezing situations. GaitAssist is the result of a design process where we considered the input of engineers, clinicians and 18 Parkinson's disease patients, in order to find an optimal trade-off between system wearability and performance. We tested the final system in a user study with 5 additional patients. They reported a reduction in the freezing of gait duration as a result of the auditory stimulation provided, and that they feel the system enhanced their confidence during walking.",
        "session": "SESSION: Interactive technologies for rehabilitation"
    },
    {
        "title": "A technology probe of wearable in-home computer-assisted physical therapy",
        "authors": "Kevin Huang, Patrick J. Sparto, Sara Kiesler, Asim Smailagic, Jennifer Mankoff, Dan Siewiorek",
        "abstract": "Physical therapists could make better treatment decisions if they had accurate patient home exercise data but today this information is only available from patient self-report. A more accurate source of data could be gained from wearable computing designed for physical therapy exercise support. Existing systems have been tested in the lab but we have little information about issues they may face in home settings. We designed a technology probe, SenseCap, and deployed it for seven days in ten physical therapy patients' homes. SenseCap is a wearable physical therapy support system that gathers patient exercise compliance and performance data and summarizes the data in charts on an iPad Dashboard for physical therapists to view when patients return to the clinic. In this paper, we present the results of our deployment, show in-home patient exercise data gathered by the probe, and make design recommendations based on patient and physical therapist responses.",
        "session": "SESSION: Interactive technologies for rehabilitation"
    },
    {
        "title": "Exploring the acceptability of google glass as an everyday assistive device for people with parkinson's",
        "authors": "Rísin McNaney, John Vines, Daniel Roggen, Madeline Balaam, Pengfei Zhang, Ivan Poliakov, Patrick Olivier",
        "abstract": "We describe a qualitative study investigating the acceptability of the Google Glass eyewear computer to people with Parkinson's disease (PD). We held a workshop with 5 PD patients and 2 carers exploring perceptions of Glass. This was followed by 5-day field trials of Glass with 4 PD patients, where participants wore the device during everyday activities at home and in public. We report generally positive responses to Glass as a device to instil confidence and safety for this potentially vulnerable group. We also raise concerns related to the potential for Glass to reaffirm dependency on others and stigmatise wearers.",
        "session": "SESSION: Interactive technologies for rehabilitation"
    },
    {
        "title": "Non-intrusive tongue machine interface",
        "authors": "Qiao Zhang, Shyamnath Gollakota, Ben Taskar, Raj P.N. Rao",
        "abstract": "There has been recent interest in designing systems that use the tongue as an input interface. Prior work however either require surgical procedures or in-mouth sensor placements. In this paper, we introduce TongueSee, a non-intrusive tongue machine interface that can recognize a rich set of tongue gestures using electromyography (EMG) signals from the surface of the skin. We demonstrate the feasibility and robustness of TongueSee with experimental studies to classify six tongue gestures across eight participants. TongueSee achieves a classification accuracy of 94.17% and a false positive probability of 0.000358 per second using three-protrusion preamble design.",
        "session": "SESSION: Interactive technologies for rehabilitation"
    },
    {
        "title": "Causing commotion with a shape-changing bench: experiencing shape-changing interfaces in use",
        "authors": "Erik Grönvall, Sofie Kinch, Marianne Graves Petersen, Majken K. Rasmussen",
        "abstract": "In this paper we describe results from testing coMotion, a shape-changing bench, in three different contexts: a concert hall foyer, an airport departure hall and a shopping mall. We have gathered insights from more than 120 people, with regard to how users experience and make sense of the bench's shape changing capability. The paper applies McCarthy and Wright's six different sense making processes (anticipating, connecting, interpreting, reflecting, appropriating and recounting) as an instrument to analyse people's experience with shape-changing furniture in the wild. The paper also introduces exploring as a seventh sense making process. Based on this analysis, the paper points to three relevant aspects when designing shape-changing artefacts for the wild, namely: 1) Affordance of shape-changing interfaces, 2) Transitions between background and foreground and 3) Interpreting physically dynamic objects.",
        "session": "SESSION: Shape-changing interfaces"
    },
    {
        "title": "Paddle: highly deformable mobile devices with physical controls",
        "authors": "Raf Ramakers, Johannes Schöning, Kris Luyten",
        "abstract": "We present the concept of highly deformable mobile devices that can be transformed into various special-purpose controls in order to bring physical controls to mobile devices. Physical controls have the advantage of exploiting people's innate abilities for manipulating physical objects in the real world. We designed and implemented a prototype, called Paddle, to demonstrate our concept. Additionally, we explore the interaction techniques enabled by this concept and conduct an in-depth study to evaluate our transformable physical controls. Our findings show that these physical controls provide several benefits over traditional touch interaction techniques commonly used on mobile devices.",
        "session": "SESSION: Shape-changing interfaces"
    },
    {
        "title": "Is my phone alive?: a large-scale study of shape change in handheld devices using videos",
        "authors": "Esben W. Pedersen, Sriram Subramanian, Kasper Hornbæk",
        "abstract": "Shape-changing handheld devices are emerging as research prototypes, but it is unclear how users perceive them and which experiences they engender. The little data we have on user experience is from single prototypes, only covering a small part of the possibilities in shape change. We produce 51 videos of a shape-changing handheld device by systematically varying seven parameters of shape change. In a crowd-sourced study, 187 participants watched the videos and described their experiences using rating scales and free text. We find significant and large differences among parameters of shape change. Shapes that have previously been used for notifications were rated the least urgent; the degree of shape change was found to impact experience more than type of shape change. The experience of shape change was surprisingly complex: hedonic quality were inversely related to urgency, and some shapes were perceived as ugly, yet useful. We discuss how to advance models of shape change and improve research on the experience of shape change.",
        "session": "SESSION: Shape-changing interfaces"
    },
    {
        "title": "Evaluating the effectiveness of physical shape-change for in-pocket mobile device notifications",
        "authors": "Panteleimon Dimitriadis, Jason Alexander",
        "abstract": "Audio and vibrotactile output are the standard mechanisms mobile devices use to attract their owner's attention. Yet in busy and noisy environments, or when the user is physically active, these channels sometimes fail. Recent work has explored the use of physical shape-change as an additional method for conveying notifications when the device is in-hand or viewable. However, we do not yet understand the effectiveness of physical shape-change as a method for communicating in-pocket notifications. This paper presents three robustly implemented, mobile-device sized shape-changing devices, and two user studies to evaluate their effectiveness at conveying notifications. The studies reveal that (1) different types and configurations of shape-change convey different levels of urgency and; (2) fast pulsing shape-changing notifications are missed less often and recognised more quickly than the standard slower vibration pulse rates of a mobile device.",
        "session": "SESSION: Shape-changing interfaces"
    },
    {
        "title": "Changibles: analyzing and designing shape changing constructive assembly",
        "authors": "Anne Roudaut, Rebecca Reed, Tianbo Hao, Sriram Subramanian",
        "abstract": "Advances in shape changing assemblies have been made in reconfiguration algorithms, hardware designs and interaction techniques. However no tools exist for guiding designers in building those modular devices and especially for choosing the shape of the units. The task becomes even more complex when the units themselves can change their shapes to animate the entire assembly. In this paper, we contribute with the first analysis tool which helps the designer to both choose the right subset of forms for the units and to create an assembly with maximum accuracy from the set of given objects. We introduce the concept of Changibles that are interactive wireless units that can reshape themselves and be attached together to create an animated assembly. We present a use case to demonstrate the use of our tool, with an instantiation of six Changibles that are used to construct a pulsing heart assembly.",
        "session": "SESSION: Shape-changing interfaces"
    },
    {
        "title": "Expanding touch input vocabulary by using consecutive distant taps",
        "authors": "Seongkook Heo, Jiseong Gu, Geehyuk Lee",
        "abstract": "In recent years, touch screens have emerged and matured as the main input interface for mobile and tablet computers calling for extended touch input possibilities. In this paper, we explore the use of consecutive distant taps to expand the touch screen input vocabulary. We analyzed time intervals and distances between consecutive taps during common applications on a tablet and verified that consecutive distant taps can be used conflict-free with existing touch gestures. We designed the two interaction techniques Ta-tap and Ta-Ta-tap that utilize consecutive distant taps. Ta-tap uses two consecutive distant taps to invoke alternative touch operations for multi-touch emulation, whereas Ta-Ta-tap uses a series of consecutive distant taps to define a spatial gesture. We verified the feasibility of both interaction techniques through a series of experiments and a user study. The high recognition rate of Ta-tap and Ta-Ta-tap gestures, the few conflicts with existing gestures, and the positive feedback from the participants assert the potential of consecutive distant taps as a new design space to enrich touch screen interactions.",
        "session": "SESSION: Touch input"
    },
    {
        "title": "LinearDragger: a Linear Selector for One-finger Target Acquisition",
        "authors": "Oscar Kin-Chung Au, Xiaojun Su, Rynson W.H. Lau",
        "abstract": "Touch input is increasingly popular nowadays, especially for mobile devices such as smartphones and tablet computers. However, the human finger has considerably large fingertip size and finger input is imprecise. As such, acquiring small targets on a touch screen is still a challenging task. In this paper, we present the LinearDragger, a new and integrated one-finger target acquisition technique for small and clustered targets. The proposed method has three advantages. First, it allows users to select targets in dense clustered groups easily with a single touch-drag-release operation. Second, it maps the 2D selection problem into a more precise 1D selection problem, which is independent of the target distribution. Third, it avoids finger occlusion and does not create visual distraction. As a result, it is particularly suitable for applications with dense targets and rich visual elements. Results of our controlled experiments show that when selecting small targets, LinearDragger takes about 70% and 30% less selection time than target acquisition without using any techniques and with the state-of-the-art target acquisition technique that involves a single touch operation, respectively, while maintaining a reasonable error rate.",
        "session": "SESSION: Touch input"
    },
    {
        "title": "Faster command selection on tablets with FastTap",
        "authors": "Carl Gutwin, Andy Cockburn, Joey Scarr, Sylvain Malacria, Scott C. Olson",
        "abstract": "Touch-based tablet UIs provide few shortcut mechanisms for rapid command selection; as a result, command selection on tablets often requires slow traversal of menus. We developed a new selection technique for multi-touch tablets, called FastTap, that uses thumb-and-finger touches to show and choose from a spatially-stable grid-based overlay interface. FastTap allows novices to view and inspect the full interface, but once item locations are known, FastTap allows people to select commands with a single quick thumb-and-finger tap. The interface helps users develop expertise, since the motor actions carried out as a novice rehearse the expert behavior. A controlled study showed that FastTap was significantly faster (by 33% per selection overall) than marking menus, both for novices and experts, and without reduction in accuracy or subjective preference. Our work introduces a new and efficient selection mechanism that supports rapid command execution on touch tablets, for both novices and experts.",
        "session": "SESSION: Touch input"
    },
    {
        "title": "Crossing-based selection with direct touch input",
        "authors": "Yuexing Luo, Daniel Vogel",
        "abstract": "Fundamental performance results for crossing-based selec-tion tasks with direct touch input are presented. A close adaptation of Accot and Zhai's indirect stylus crossing ex-periment reveals similar trends for direct touch input: touch crossing task time is faster or equivalent to touch pointing; continuous selection of large orthogonal crossing targets is most effective; and continuous selection of small collinear targets is least effective. Unlike indirect stylus and mouse crossing, not every kind of direct touch pointing perfor-mance is modeled accurately with standard Fitts' law. Instead, Fitts' law, used previously for touch pointing with small targets, is used to more accurately model discrete touch crossing with a directionally constrained target. In addition, visual touch feedback is shown to have a strong effect on absolute accuracy. Our work empirically validates touch crossing as a practical and efficient selection technique, and motivates the exploration of novel forms of expressive multi-touch crossing.",
        "session": "SESSION: Touch input"
    },
    {
        "title": "Easy does it: more usable CAPTCHAs",
        "authors": "Elie Bursztein, Angelique Moscicki, Celine Fabry, Steven Bethard, John C. Mitchell, Dan Jurafsky",
        "abstract": "Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer algorithms masquerading as people. While CAPTCHAs are generally effective at stopping abuse, they might impair website usability if they are not properly designed. In this paper we describe how we designed two new CAPTCHA schemes for Google that focus on maximizing usability. We began by running an evaluation on Amazon Mechanical Turk with over 27,000 respondents to test the usability of different feature combinations. Then we studied user preferences using Google's consumer survey infrastructure. Finally, drawing on the insights gleaned during those studies, we tested our new captcha schemes first on Mechanical Turk and then on a fraction of production traffic. The resulting scheme is now an integral part of our production system and is served to millions of users. Our scheme achieved a 95.3% human accuracy, a 6.7.",
        "session": "SESSION: Risks and security"
    },
    {
        "title": "Using personal examples to improve risk communication for security & privacy decisions",
        "authors": "Marian Harbach, Markus Hettig, Susanne Weber, Matthew Smith",
        "abstract": "IT security systems often attempt to support users in taking a decision by communicating associated risks. However, a lack of efficacy as well as problems with habituation in such systems are well known issues. In this paper, we propose to leverage the rich set of personal data available on smartphones to communicate risks using personalized examples. Examples of private information that may be at risk can draw the users' attention to relevant information for a decision and also improve their response. We present two experiments that validate this approach in the context of Android app permissions. Private information that becomes accessible given certain permissions is displayed when a user wants to install an app, demonstrating the consequences this installation might have. We find that participants made more privacy-conscious choices when deciding which apps to install. Additionally, our results show that our approach causes a negative affect in participants, which makes them pay more attention.",
        "session": "SESSION: Risks and security"
    },
    {
        "title": "\"My religious aunt asked why i was trying to sell her viagra\": experiences with account hijacking",
        "authors": "Richard Shay, Iulia Ion, Robert W. Reeder, Sunny Consolvo",
        "abstract": "With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data. Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts. In this paper, we report results of a survey about people's experiences with and attitudes toward account hijacking. The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party. Five themes emerged from our results: (1) compromised accounts are often valuable to victims, (2) attackers are mostly unknown, but sometimes known, to victims, (3) users acknowledge some responsibility for keeping their accounts secure, (4) users' understanding of important security measures is incomplete, and (5) harm from account hijacking is concrete and emotional. We discuss implications for designing security mechanisms to improve chances for user adoption.",
        "session": "SESSION: Risks and security"
    },
    {
        "title": "Experimenting at scale with google chrome's SSL warning",
        "authors": "Adrienne Porter Felt, Robert W. Reeder, Hazim Almuhimedi, Sunny Consolvo",
        "abstract": "Web browsers show HTTPS authentication warnings (i.e., SSL warnings) when the integrity and confidentiality of users' interactions with websites are at risk. Our goal in this work is to decrease the number of users who click through the Google Chrome SSL warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower click-through rate (CTR) than Chrome. We investigate several factors that could be responsible: the use of imagery, extra steps before the user can proceed, and style choices. To test these factors, we ran six experimental SSL warnings in Google Chrome 29 and measured 130,754 impressions.",
        "session": "SESSION: Risks and security"
    },
    {
        "title": "Betrayed by updates: how negative experiences affect future security",
        "authors": "Kami E. Vaniea, Emilee Rader, Rick Wash",
        "abstract": "Installing security-relevant software updates is one of the best computer protection mechanisms. However, users do not always choose to install updates. Through interviewing non-expert Windows users, we found that users frequently decide not to install future updates, regardless of whether they are important for security, after negative experiences with past updates. This means that even non-security updates (such as user interface changes) can impact the security of a computer. We discuss three themes impacting users' willingness to install updates: unexpected new features in an update, the difficulty of assessing whether an update is ``worth it', and confusion about why an update is necessary.",
        "session": "SESSION: Risks and security"
    },
    {
        "title": "Understanding sustained community engagement: a case study in heritage preservation in rural argentina",
        "authors": "Mara Balestrini, Jon Bird, Paul Marshall, Alberto Zaro, Yvonne Rogers",
        "abstract": "HCI projects are increasingly evaluating technologies in the wild, which typically involves working with communities over extended periods, often with the goal of effecting sustainable change. However, there are few descriptions of projects that have been successful in the long-term. In this paper we investigate what factors are important for developing long lasting community ICT interventions. We do this by analysing a successful action research project and provide five recommendations for facilitating sustained community engagement. CrowdMemo aimed to preserve local heritage in a town in rural Argentina and the project was set up so that it could be continued by the community once researchers had left. Participants created videos about personal memories of the town and over 600 people attended the premiere where they were first screened. The impact has not just been short-term and there has been sustained engagement with the project by stakeholders in the town and wider region: the local school integrated digital storytelling into its curriculum; the approach has been adopted by two nearby towns; and the project has influenced regional government educational policy.",
        "session": "SESSION: CHI for social development"
    },
    {
        "title": "Human values in curating a human rights media archive",
        "authors": "Abigail C. Durrant, David S. Kirk, Stuart Reeves",
        "abstract": "Cultural institutions, such as museums, often curate politically and ethically sensitive materials. Increasingly, Internet-enabled, digital technology intersects with these curatorial practices offering new opportunities for public and scholarly engagement. We report on a case study of human rights media archiving at a genocide memorial centre in Rwanda, motivated by our interests in ICT support to memorialisation practices. Through an analysis of our discussions with staff about their work, we report on how accounts of the Rwandan Genocide are being captured and curated to support the centre's humanitarian agenda and associated values. We identify transferable curatorial concerns for human rights media communication amongst scholarly networks and public audiences worldwide, elucidating interaction design challenges for supportive ICT and contributing to HCI discourses on Value Sensitive Design and cultural engagement with sensitive materials.",
        "session": "SESSION: CHI for social development"
    },
    {
        "title": "Protibadi: A platform for fighting sexual harassment in urban Bangladesh",
        "authors": "Syed Ishtiaque Ahmed, Steven J. Jackson, Nova Ahmed, Hasan Shahid Ferdous, Md. Rashidujjaman Rifat, A.S.M Rizvi, Shamir Ahmed, Rifat Sabbir Mansur",
        "abstract": "Public sexual harassment has emerged as a large and growing concern in urban Bangladesh, with deep and damaging implications for gender security, justice, and rights of public participation. In this paper we describe an integrated program of ethnographic and design work meant to understand and address such problems. For one year we conducted surveys, interviews, and focus groups around sexual harassment with women at three different universities in Dhaka. Based on this input, we developed \"Protibadi\", a web and mobile phone based application designed to report, map, and share women's stories around sexual harassment in public places. In August 2013 the system launched, user studies were conducted, and public responses were monitored to gauge reactions, strengths, and limits of the system. This paper describes the findings of our ethnographic and design-based work, and suggests lessons relevant to other HCI efforts to understand and design around difficult and culturally sensitive problems.",
        "session": "SESSION: CHI for social development"
    },
    {
        "title": "How technology supports family communication in rural, suburban, and urban kenya",
        "authors": "Erick Oduor, Carman Neustaedter, Tejinder K. Judge, Kate Hennessy, Carolyn Pang, Serena Hillman",
        "abstract": "Much ICTD research for sub-Saharan Africa has focused on how technology related interventions have aimed to incorporate marginalized communities towards global economic growth. Our work builds on this. We present results from an exploratory qualitative study on the family communication practices of family members who communicate both within and between rural, suburban, and urban settings in Kenya. Our findings reveal that family communication focuses on economic support, well-being, life advice, and everyday coordination of activities. We also outline social factors that affect family communication, including being an eldest child, having a widowed sibling, and having reduced access to technology because of gender, literacy, or one's financial situation. Lastly, we discuss new opportunities for technology design and articulate the challenges that designers will face if creating or deploying family communication technologies in Kenya.",
        "session": "SESSION: CHI for social development"
    },
    {
        "title": "Towards crowd-based customer service: a mixed-initiative tool for managing Q&A sites",
        "authors": "Tiziano Piccardi, Gregorio Convertino, Massimo Zancanaro, Ji Wang, Cedric Archambeau",
        "abstract": "In this paper, we propose a mixed-initiative approach to integrate a Q&A site based on a crowd of volunteers with a standard operator-based help desk, ensuring quality of customer service. Q&A sites have emerged as an efficient way to address questions in various domains by leveraging crowd knowledge. However, they lack sufficient reliability to be the sole basis of customer service applications. We built a proof-of-concept mixed-initiative tool that helps a crowd-manager to decide if a question will get a satisfactory and timely answer by the crowd or if it should be redirected to a dedicated operator. A user experiment found that our tool reduced the participants' cognitive load and improved their performance, in terms of their precision and recall. In particular, those with higher performance benefited more than those with lower performance.",
        "session": "SESSION: Question and answer systems"
    },
    {
        "title": "Estimating the social costs of friendsourcing",
        "authors": "Jeffrey M. Rzeszotarski, Meredith Ringel Morris",
        "abstract": "Every day users of social networking services ask their followers and friends millions of questions. These friendsourced questions not only provide informational benefits, but also may reinforce social bonds. However, there is a limit to how much a person may want to friendsource. They may be uncomfortable asking questions that are too private, might not want to expend others' time or effort, or may feel as though they have already accrued too many social debts. These perceived social costs limit the potential benefits of friendsourcing. In this paper we explore the perceived social costs of friendsourcing on Twitter via a monetary choice. We develop a model of how users value the attention and effort of their social network while friendsourcing, compare and contrast it with paid question answering in a crowdsourced labor market, and provide future design considerations for better supporting friendsourcing.",
        "session": "SESSION: Question and answer systems"
    },
    {
        "title": "Expert voices in echo chambers: effects of source expertise indicators on exposure to diverse opinions",
        "authors": "Q. Vera Liao, Wai-Tat Fu",
        "abstract": "We studied how a source expertise indicator impacted users' information seeking behavior when using a system aggregating diverse opinions, and how it interacted with a source position indicator to shape users' selectivity of information. We found that, for both attitude consistent and inconsistent information, the expertise indicator increased the selection of sources indicated to have high expertise and decreased that of low expertise. Moreover, when both source expertise and position indicators were present, users' selective exposure tendency, i.e., preferential selection of attitude consistent sources over inconsistent ones, decreased among expert sources. Moreover, we found that the expertise indicator could benefit encouraging common ground seeking with different others by increasing the agreement with, and perceived expertise of inconsistent sources indicated to be experts. Design implications for moderating selective exposure by highlighting the utility of dissonant information were discussed.",
        "session": "SESSION: Question and answer systems"
    },
    {
        "title": "Is anyone out there?: unpacking Q&A hashtags on twitter",
        "authors": "Jeffrey M. Rzeszotarski, Emma S. Spiro, Jorge Nathan Matias, Andrés Monroy-Hernández, Meredith Ringel Morris",
        "abstract": "In addition to posting news and status updates, many Twitter users post questions that seek various types of subjective and objective information. These questions are often labeled with 'Q&A' hashtags, such as #lazyweb or #twoogle. We surveyed Twitter users and found they employ these Q&A hashtags both as a topical signifier (this tweet needs an answer!) and to reach out to those beyond their immediate followers (a community of helpful tweeters who monitor the hashtag). However, our log analysis of thousands of hashtagged Q&A exchanges reveals that nearly all replies to hashtagged questions come from a user's immediate follower network, contradicting users' beliefs that they are tapping into a larger community by tagging their question tweets. This finding has implications for designing next-generation social search systems that reach and engage a wide audience of answerers.",
        "session": "SESSION: Question and answer systems"
    },
    {
        "title": "What if we ask a different question?: social inferences create product ratings faster",
        "authors": "Eric Gilbert",
        "abstract": "Consumer product reviews are the backbone of commerce online. Most commonly, sites ask users for their personal opinions on a product or service. I conjecture, however, that this traditional method of eliciting reviews often invites idiosyncratic viewpoints. In this paper, I present a statistical study examining the differences between traditionally elicited product ratings (i.e., \"How do you rate this product'\") and social inference ratings (i.e., \"How do you think other people will rate this product'\"). In 5 of 6 trials, I find that social inference ratings produce the same aggregate product rating as the one produced via traditionally elicited ratings. In all cases, however, social inferences yield less variance. This is significant because using social inference ratings 1) therefore converges on the true aggregate product rating faster, and 2) is a cheap design intervention on the part of existing sites.",
        "session": "SESSION: Question and answer systems"
    },
    {
        "title": "Smarties: an input system for wall display development",
        "authors": "Olivier Chapuis, Anastasia Bezerianos, Stelios Frantzeskakis",
        "abstract": "Wall-sized displays can support data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It consists of an interface running on touch mobile devices for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. Each touch mobile has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of associated widgets are decided by the wall application, making the mobile interface customizable by the wall application it connects to.",
        "session": "SESSION: Cross-device interaction"
    },
    {
        "title": "Conductor: enabling and understanding cross-device interaction",
        "authors": "Peter Hamilton, Daniel J. Wigdor",
        "abstract": "The proliferation of inexpensive connected devices has created a situation where a person, at any given moment, is surrounded by interactive computers. Despite this fact, there are very few means by which a user may take advantage of this large number of screens. We present Conductor, a prototype framework which serves as an exemplar for the construction of cross-device applications. We present a series of interaction methods by which users can easily share information, chain tasks across devices, and manage sessions across devices. We also present a cross-device usage scenario which utilizes several cross-device applications built within our prototype framework. We also describe a user study, which helped us to understand how users will take advantage of a large number of devices in support of performance of a sense making task.",
        "session": "SESSION: Cross-device interaction"
    },
    {
        "title": "Panelrama: enabling easy specification of cross-device web applications",
        "authors": "Jishuo Yang, Daniel Wigdor",
        "abstract": "We present Panelrama, a web-based framework for the construction of applications using distributed user interfaces (DUIs). Our implementation provides developers with low migration costs through built-in mechanisms for the synchronization of a UI state, requiring minimal changes to existing languages. Additionally, we describe a solution to categorize device characteristics and dynamically change UI allocation to best-fit devices. We illustrate the use of Panelrama through three sample applications which demonstrate its support for known interaction methods, we also present the results of a developer study, which validates our belief that cross-device application experiences can be easily implemented using our framework.",
        "session": "SESSION: Cross-device interaction"
    },
    {
        "title": "Interactive development of cross-device user interfaces",
        "authors": "Michael Nebeling, Theano Mintsi, Maria Husmann, Moira Norrie",
        "abstract": "Current GUI builders provide a design environment for user interfaces that target either a single type or fixed set of devices, and provide little support for scenarios in which the user interface, or parts of it, are distributed over multiple devices. Distributed user interfaces have received increasing attention over the past years. There are different, often model-based, approaches that focus on technical issues. This paper presents XDStudio--a new GUI builder designed to support interactive development of cross-device web interfaces. XDStudio implements two complementary authoring modes with a focus on the design process of distributed user interfaces. First, simulated authoring allows designing for a multi-device environment on a single device by simulating other target devices. Second, on-device authoring allows the design process itself to be distributed over multiple devices, as design and development take place on the target devices themselves. To support interactive development for multi-device environments, where not all devices may be present at design and run-time, XDStudio supports switching between the two authoring modes, as well as between design and use modes, as required. This paper focuses on the design of XDStudio, and evaluates its support for two distribution scenarios.",
        "session": "SESSION: Cross-device interaction"
    },
    {
        "title": "Motivating people with chronic pain to do physical activity: opportunities for technology design",
        "authors": "Aneesha Singh, Annina Klapper, Jinni Jia, Antonio Fidalgo, Ana Tajadura-Jiménez, Natalie Kanakam, Nadia Bianchi-Berthouze, Amanda Williams",
        "abstract": "Physical activity is important for improving quality of life in people with chronic pain. However, actual or anticipated pain exacerbation, and lack of confidence when doing physical activity, make it difficult to maintain and build towards long-term activity goals. Research guiding the design of interactive technology to motivate and support physical activity in people with chronic pain is lacking. We conducted studies with: (1) people with chronic pain, to understand how they maintained and increased physical activity in daily life and what factors deterred them; and (2) pain-specialist physiotherapists, to understand how they supported people with chronic pain. Building on this understanding, we investigated the use of auditory feedback to address some of the psychological barriers and needs identified and to increase self-efficacy, motivation and confidence in physical activity. We conclude by discussing further design opportunities based on the overall findings.",
        "session": "SESSION: Exergaming for health and fitness"
    },
    {
        "title": "Investigating the long-term use of exergames in the home with elderly fallers",
        "authors": "Stephen Uzor, Lynne Baillie",
        "abstract": "Rehabilitation has been shown to significantly reduce the risk of falling in older adults. However, low adherence to rehabilitation exercises in the home means that seniors often do not get the therapy that they require. We propose that the use of tailored exergames could encourage adherence to falls rehabilitation in the home, as exergames have proved successful in clinical settings. We describe the results from the first known study to investigate the long-term (12 weeks) use of exergames, designed in close collaboration with elderly users, for falls rehabilitation in the home. Our findings suggest that there is an untapped potential of exergames for home rehabilitation use, as our findings show that there was better adherence to exercise in participants who used the exergames, versus those who used standard care. Finally, we make recommendations for designers, on the design of exergames for the rehabilitation of seniors.",
        "session": "SESSION: Exergaming for health and fitness"
    },
    {
        "title": "StepStream: a school-based pervasive social fitness system for everyday adolescent health",
        "authors": "Andrew D. Miller, Elizabeth D. Mynatt",
        "abstract": "Computer-supported fitness interventions for adolescents have the potential to improve adolescents' attitudes and perceptions about physical activity through peer influence and interpersonal accountability. Past research has explored the potential of interventions based on competition and social-comparison mechanisms. We present a new approach: school-based, pervasive social fitness systems. We describe one such system: StepStream, a pedometer-based microblog we designed and deployed for four weeks with 42 US middle school students. StepStream users improved their attitudes about fitness and increased their sense of social support for fitness. The least-active students also increased their daily activity. We show that our school-based social fitness approach performed comparably in attitude and behavior change to more competitive or direct-comparison systems. These results expand the strategies available computer-supported fitness interventions. Our school-based social fitness approach to everyday adolescent health shows the potential for social computing systems to positively influence offline health behaviors in real-world settings.",
        "session": "SESSION: Exergaming for health and fitness"
    },
    {
        "title": "Social fabric fitness: the design and evaluation of wearable E-textile displays to support group running",
        "authors": "Matthew Mauriello, Michael Gubbels, Jon E. Froehlich",
        "abstract": "Group exercise has multiple benefits including greater adherence to fitness regimens, increased enjoyment among participants, and enhanced workout intensity. While a large number of technology tools have emerged to support real-time feedback of individual performance, tools to support group fitness are limited. In this paper, we present a set of wearable e-textile displays for running groups called Social Fabric Fitness (SFF). SFF provides a glanceable, shared screen on the back of the wearer's shirt to increase awareness and motivation of group fitness performance. We discuss parallel prototyping of three designs-one flexible e-ink and two flexible LED-based displays; the selection and refinement of one design; and two evaluations'a field study of 10 running groups and two case studies of running races. Our qualitative findings indicate that SFF improves awareness of individual and group performance, helps groups stay together, and improves in-situ motivation. We close with reflections for future athletic e-textile displays.",
        "session": "SESSION: Exergaming for health and fitness"
    },
    {
        "title": "Opportunities for odor: experiences with smell and implications for technology",
        "authors": "Marianna Obrist, Alexandre N. Tuch, Kasper Hornbaek",
        "abstract": "Technologies for capturing and generating smell are emerging, and our ability to engineer such technologies and use them in HCI is rapidly developing. Our understanding of how these technologies match the experiences with smell that people have or want to have is surprisingly limited. We therefore investigated the experience of smell and the emotions that accompany it. We collected stories from 439 participants who described personally memorable smell experiences in an online questionnaire. Based on the stories we developed 10 categories of smell experience. We explored the implications of the categories for smell-enhanced technology design by (a) probing participants to envision technologies that match their smell story and (b) having HCI researchers brainstorm technologies using the categories as design stimuli. We discuss how our findings can benefit research on personal memories, momentary and first time experiences, and wellbeing.",
        "session": "SESSION: Sensory experiences: smell and taste"
    },
    {
        "title": "Temporal, affective, and embodied characteristics of taste experiences: a framework for design",
        "authors": "Marianna Obrist, Rob Comber, Sriram Subramanian, Betina Piqueras-Fiszman, Carlos Velasco, Charles Spence",
        "abstract": "We present rich descriptions of taste experience through an analysis of the diachronic and synchronic experiences of each of the five basic taste qualities: sweet, sour, salt, bitter, and umami. Our findings, based on a combination of user experience evaluation techniques highlight three main themes: temporality, affective reactions, and embodiment. We present the taste characteristics as a framework for design and discuss each taste in order to elucidate the design qualities of individual taste experiences. These findings add a semantic understanding of taste experiences, their temporality enhanced through descriptions of the affective reactions and embodiment that the five basic tastes elicit. These findings are discussed on the basis of established psychological and behavioral phenomena, highlighting the potential for taste-enhanced design.",
        "session": "SESSION: Sensory experiences: smell and taste"
    },
    {
        "title": "SensaBubble: a chrono-sensory mid-air display of sight and smell",
        "authors": "Sue Ann Seah, Diego Martinez Plasencia, Peter D. Bennett, Abhijit Karnik, Vlad Stefan Otrocol, Jarrod Knibbe, Andy Cockburn, Sriram Subramanian",
        "abstract": "We present SensaBubble, a chrono-sensory mid-air display system that generates scented bubbles to deliver information to the user via a number of sensory modalities. The system reliably produces single bubbles of specific sizes along a directed path. Each bubble produced by SensaBubble is filled with fog containing a scent relevant to the notification. The chrono-sensory aspect of SensaBubble means that information is presented both temporally and multimodally. Temporal information is enabled through two forms of persistence: firstly, a visual display projected onto the bubble which only endures until it bursts; secondly, a scent released upon the bursting of the bubble slowly disperses and leaves a longer-lasting perceptible trace of the event. We report details of SensaBubble's design and implementation, as well as results of technical and user evaluations. We then discuss and demonstrate how SensaBubble can be adapted for use in a wide range of application contexts -- from an ambient peripheral display for persistent alerts, to an engaging display for gaming or education.",
        "session": "SESSION: Sensory experiences: smell and taste"
    },
    {
        "title": "Food messaging: using edible medium for social messaging",
        "authors": "Jun Wei, Xiaojuan Ma, Shengdong Zhao",
        "abstract": "Food is more than just a means of survival; it is also a form of communication. In this paper, we investigate the potential of food as a social message carrier (a.k.a., food messaging). To investigate how people accept, use, and perceive food messaging, we conducted exploratory interviews, a field study, and follow-up interviews over four weeks in a large information technology (IT) company. We collected 904 messages sent by 343 users. Our results suggest strong acceptance of food messaging as an alternative message channel. Further analysis implies that food messaging embodies characteristics of both text messaging and gifting. It is preferred in close relationships for its evocation of positive emotions. As the first field study on edible social messaging, our empirical findings provide valuable insights into the uniqueness of food as a message carrier and its capabilities to promote greater social bonding.",
        "session": "SESSION: Sensory experiences: smell and taste"
    },
    {
        "title": "Multi-finger chords for hand-held tablets: recognizable and memorable",
        "authors": "Julie Wagner, Eric Lecolinet, Ted Selker",
        "abstract": "Despite the demonstrated benefits of multi-finger input, todays gesture vocabularies offer a limited number of postures and gestures. Previous research designed several posture sets, but does not address the limited human capacity of retaining them. We present a multi-finger chord vocabulary, introduce a novel hand-centric approach to detect the identity of fingers on off-the-shelf hand-held tablets, and report on the detection accuracy. A between-subjects experiment comparing \"random\" to a \"categorized\" chord-command mapping found that users retained categorized mappings more accurately over one week than random ones. In response to the logical posture-language structure, people adapted to logical memorization strategies, such as 'exclusion', 'order', and 'category', to minimize the amount of information to retain. We conclude that structured chord-command mappings support learning, short-, and long-term retention of chord- command mappings.",
        "session": "SESSION: Multitouch interaction"
    },
    {
        "title": "Prospective motor control on tabletops: planning grasp for multitouch interaction",
        "authors": "Halla B. Olafsdottir, Theophanis Tsandilas, Caroline Appert",
        "abstract": "Substantial amount of research in Psychology has studied how people manipulate objects in the physical world. This work has unveiled that people show strong signs of prospective motor planning, i.e., they choose initial grasps that avoid uncomfortable end postures and facilitate object manipulation. Interactive tabletops allow their users great flexibility in the manipulation of virtual objects but to our knowledge previous work has never examined whether prospective motor control takes place in this context. To test this, we ran three experiments. We systematically studied how users adapt their grasp when asked to translate and rotate virtual objects on a multitouch tabletop. Our results demonstrate that target position and orientation significantly affect the orientation of finger placement on the object. We analyze our results in the light of the most recent model of planning for manipulating physical objects and identify their implications for the design of tabletop interfaces. \\",
        "session": "SESSION: Multitouch interaction"
    },
    {
        "title": "Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effects",
        "authors": "Ayman Alzayat, Mark Hancock, Miguel Nacenta",
        "abstract": "Over the past decade, multi-touch surfaces have become commonplace, with many researchers and practitioners describing the benefits of their natural, physical-like interactions. We present a pair of studies that empirically investigates the psychophysical effects of direct interaction with both physical and virtual artefacts. We use the phenomenon of Kinesthetic Figural After Effects-a change in understanding of the physical size of an object after a period of exposure to an object of different size. Our studies show that, while this effect is robustly reproducible when using physical artefacts, this same effect does not manifest when manipulating virtual artefacts on a direct, multi-touch tabletop display. We contribute quantitative evidence suggesting a psychophysical difference in our response to physical vs. virtual objects, and discuss future research directions to explore measurable phenomena to evaluate the presence of physical-like changes from virtual on-screen objects.",
        "session": "SESSION: Multitouch interaction"
    },
    {
        "title": "TouchTools: leveraging familiarity and skill with physical tools to augment touch interaction",
        "authors": "Chris Harrison, Robert Xiao, Julia Schwarz, Scott E. Hudson",
        "abstract": "The average person can skillfully manipulate a plethora of tools, from hammers to tweezers. However, despite this remarkable dexterity, gestures on today's touch devices are simplistic, relying primarily on the chording of fingers: one-finger pan, two-finger pinch, four-finger swipe and similar. We propose that touch gesture design be inspired by the manipulation of physical tools from the real world. In this way, we can leverage user familiarity and fluency with such tools to build a rich set of gestures for touch interaction. With only a few minutes of training on a proof-of-concept system, users were able to summon a variety of virtual tools by replicating their corresponding real-world grasps.",
        "session": "SESSION: Multitouch interaction"
    },
    {
        "title": "Passhint: memorable and secure authentication",
        "authors": "Soumyadeb Chowdhury, Ron Poet, Lewis Mackenzie",
        "abstract": "People find it difficult to remember multiple alphanumeric as well as graphical passwords. We propose a Passhint authentication system (PHAS), where the users have to choose four images and create hints for each one of them in order to register a new password. During authentication, they have to recognize only the target images, which are displayed with their corresponding hints, among collections of 15 decoy images, in a four step process. A usability study was conducted with 40 subjects. They created 1 Mikon, 1 doodle, 1 art and 1 object password and then recalled each password after a period of two weeks (without any practice sessions). The results demonstrated that the memorability of multiple passwords in PHAS is better than in existing Graphical authentication systems (GASs). Although the registration time is high, authentication time for successful attempts is either equivalent to or less than the time reported for previous GASs. A guessability study conducted with the same subjects revealed that art passwords are the least guessable, followed by Mikon, doodle and objects in that order. The results strongly suggest the use of art passwords in PHAS, which would offer usable as well as secure authentication. The preliminary results indicate that PHAS has solved the memorability problem with multiple passwords. We propose two new features that could enhance the security offered by PHAS, but the usability of these features would need to be tested before they could be adopted in practice.",
        "session": "SESSION: Authentication and passwords"
    },
    {
        "title": "Can long passwords be secure and usable?",
        "authors": "Richard Shay, Saranga Komanduri, Adam L. Durity, Phillip (Seyoung) Huh, Michelle L. Mazurek, Sean M. Segreti, Blase Ur, Lujo Bauer, Nicolas Christin, Lorrie Faith Cranor",
        "abstract": "To encourage strong passwords, system administrators employ password-composition policies, such as a traditional policy requiring that passwords have at least 8 characters from 4 character classes and pass a dictionary check. Recent research has suggested, however, that policies requiring longer passwords with fewer additional requirements can be more usable and in some cases more secure than this traditional policy. To explore long passwords in more detail, we conducted an online experiment with 8,143 participants. Using a cracking algorithm modified for longer passwords, we evaluate eight policies across a variety of metrics for strength and usability. Among the longer policies, we discover new evidence for a security/usability tradeoff, with none being strictly better than another on both dimensions. However, several policies are both more usable and more secure that the traditional policy we tested. Our analyses additionally reveal common patterns and strings found in cracked passwords. We discuss how system administrators can use these results to improve password-composition policies.",
        "session": "SESSION: Authentication and passwords"
    },
    {
        "title": "Now you see me, now you don't: protecting smartphone authentication from shoulder surfers",
        "authors": "Alexander De Luca, Marian Harbach, Emanuel von Zezschwitz, Max-Emanuel Maurer, Bernhard Ewald Slawik, Heinrich Hussmann, Matthew Smith",
        "abstract": "In this paper, we present XSide, an authentication mechanism that uses the front and the back of smartphones to enter stroke-based passwords. Users can switch sides during input to minimize the risk of shoulder surfing. We performed a user study (n = 32) to explore how switching sides during authentication affects usability and security of the system. The results indicate that switching the sides increases security while authentication speed stays relatively fast (≤ 4 seconds). The paper furthermore provides insights on accuracy of eyes-free input (as used in XSide) and shows how 3D printed prototype cases can improve the back-of-device interaction experience.",
        "session": "SESSION: Authentication and passwords"
    },
    {
        "title": "The presentation effect on graphical passwords",
        "authors": "Julie Thorpe, Muath Al-Badawi, Brent MacRae, Amirali Salehi-Abari",
        "abstract": "We provide a simple yet powerful demonstration of how an unobtrusive change to a graphical password interface can modify the distribution of user chosen passwords, and thus possibly the security it provides. The only change to the interface is how the background image is presented to the user in the password creation phase--we call the effect of this change the \"presentation effect\". We demonstrate the presentation effect by performing a comparative user study of two groups using the same background image, where the image is presented in two different ways prior to password creation. Our results show a statistically different distribution of user's graphical passwords, with no observed usability consequences.",
        "session": "SESSION: Authentication and passwords"
    },
    {
        "title": "An implicit author verification system for text messages based on gesture typing biometrics",
        "authors": "Ulrich Burgbacher, Klaus Hinrichs",
        "abstract": "Gesture typing is a popular text input method used on smartphones. Gesture keyboards are based on word gestures that subsequently trace all letters of a word on a virtual keyboard. Instead of tapping a word key by key, the user enters a word gesture with a single continuous stroke. In this paper, we introduce an implicit user verification approach for short text messages that are entered with a gesture keyboard. We utilize the way people interact with gesture keyboards to extract behavioral biometric features. We propose a proof-of-concept classification framework that learns the gesture typing behavior of a person and is able to decide whether a gestured message was written by the legitimate user or an imposter. Data collected from gesture keyboard users in a user study is used to assess the performance of the classification framework, demonstrating that the technique has considerable promise.",
        "session": "SESSION: Authentication and passwords"
    },
    {
        "title": "HCI as a means to prosociality in the economy",
        "authors": "John Harvey, David Golightly, Andrew Smith",
        "abstract": "HCI research often involves intervening in the economic lives of people, but researchers only rarely give explicit consideration to what actually constitutes prosociality in the economy. Much has been said previously regarding sustainability but this has largely focused on environmental rather than interpersonal relations. This paper provides an analysis of how prosocial HCI has been discussed and continues to be defined as a research field. Based on a corpus of published works, we describe a variety of genres of work relating to prosocial HCI. Key intellectual differences are explored, including the epistemological and ethical positions involved in designing for prosocial outcomes as well as how HCI researchers posit economic decision-making. Finally, emerging issues and opportunities for further debate and collaboration are discussed in turn.",
        "session": "SESSION: Policies and practice: doing the right thing"
    },
    {
        "title": "Towards a closer dialogue between policy and practice: responsible design in HCI",
        "authors": "Barbara Grimpe, Mark Hartswood, Marina Jirotka",
        "abstract": "Given the potent and pervasive nature of modern technologies, this paper lays out the complexities involved in achieving responsible design. In order to do this we will first compare an emerging policy-oriented programme of research known as RRI (Responsible Research and Innovation) with initiatives in HCI. A focus on the similarities and differences may highlight to what extent responsibility is already and successfully embedded within the concerns and practices of design and use, and what may yet need to be incorporated for responsible design. The paper then discusses the challenges of 'naturalising' the very ambitious programme of RRI within specific design activities and concerns, through the lens of four analytic concepts: reflexivity; responsiveness; inclusion; and anticipation. Finally, we make a case for a pragmatic, 'unromantic', but engaged reinterpretation of RRI for HCI.",
        "session": "SESSION: Policies and practice: doing the right thing"
    },
    {
        "title": "Towards community-centered support for peer-to-peer service exchange: rethinking the timebanking metaphor",
        "authors": "Victoria M.E. Bellotti, Sara Cambridge, Karen Hoy, Patrick C. Shih, Lisa Renery Handalian, Kyungsik Han, John M. Carroll",
        "abstract": "Commercial peer-to-peer service exchange businesses, such as AirBnB, Lyft and TaskRabbit, are expanding rapidly, but their non-profit counterparts are lagging behind. We conducted a field study of the most prominent of these, timebanking; a system in which 'time dollars' are earned and spent by people providing services for and receiving them from each other. Our study exposed problems with the very metaphor of banking itself, which deter participation. In this paper we discuss how these problems can be tackled with user experience design for systems supporting timebanking. Our design ideas emphasize the personal and social benefits of participation, and avoid such unappealing concepts as debt and neediness that the timebanking metaphor falls afoul of.",
        "session": "SESSION: Policies and practice: doing the right thing"
    },
    {
        "title": "Designing for dabblers and deterring drop-outs in citizen science",
        "authors": "Alexandra Eveleigh, Charlene Jennett, Ann Blandford, Philip Brohan, Anna L. Cox",
        "abstract": "In most online citizen science projects, a large proportion of participants contribute in small quantities. To investigate how low contributors differ from committed volunteers, we distributed a survey to members of the Old Weather project, followed by interviews with respondents selected according to a range of contribution levels. The studies reveal a complex relationship between motivations and contribution. Whilst high contributors were deeply engaged by social or competitive features, low contributors described a solitary experience of 'dabbling' in projects for short periods. Since the majority of participants exhibit this small-scale contribution pattern, there is great potential value in designing interfaces to tempt lone workers to complete 'just another page', or to lure early drop-outs back into participation. This includes breaking the work into components which can be tackled without a major commitment of time and effort, and providing feedback on the quality and value of these contributions.",
        "session": "SESSION: Journalism and social news"
    },
    {
        "title": "Utilising insight journalism for community technology design",
        "authors": "Nick Taylor, David M. Frohlich, Paul Egglestone, Justin Marshall, Jon Rogers, Alicia Blum-Ross, John Mills, Mike Shorter, Patrick Olivier",
        "abstract": "We describe the process of insight journalism, in which local amateur journalists were used to generate unique insights into the digital needs of a community. We position this as a means for communities to represent themselves to designers, both as a method of designing community technologies and as a first step towards supporting innovation at a local level. To demonstrate insight journalism, we present two case studies of community technologies that were directly inspired, informed and evaluated by journalistic content. Based on this experience, we evaluate the role that insight journalism can play in designing for communities, the particular characteristics that it lends to the design process and how it might be employed to support sustainable community innovation.",
        "session": "SESSION: Journalism and social news"
    },
    {
        "title": "NewsViews: an automated pipeline for creating custom geovisualizations for news",
        "authors": "Tong Gao, Jessica R. Hullman, Eytan Adar, Brent Hecht, Nicholas Diakopoulos",
        "abstract": "Interactive visualizations add rich, data-based context to online news articles. Geographic maps are currently the most prevalent form of these visualizations. Unfortunately, designers capable of producing high-quality, customized geovisualizations are scarce. We present NewsViews, a novel automated news visualization system that generates interactive, annotated maps without requiring professional designers. NewsViews' maps support trend identification and data comparisons relevant to a given news article. The NewsViews system leverages text mining to identify key concepts and locations discussed in articles (as well as potential annotations), an extensive repository of 'found' databases, and techniques adapted from cartography to identify and create visually 'interesting' thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated, map generation and experimentally validate the key features for successful representations (e.g., relevance to context, variable selection, 'interestingness' of representation and annotation quality).",
        "session": "SESSION: Journalism and social news"
    },
    {
        "title": "Finding \"real people\": trust and diversity in the interface between professional and citizen journalists",
        "authors": "Andrew Thomas Garbett, Rob Comber, Paul Egglestone, Maxine Glancy, Patrick Olivier",
        "abstract": "The increase of social media and web blogs has enabled a new generation of citizen journalism to provide new perspectives into local communities. However traditional news organisations are currently struggling to incorporate this new form of journalism into their existing organisational workflow. We present an analysis from 10 interviews with professional journalists and explore the current issues faced by professional journalists when searching for reliable and reputable local news sources as well as the perceived role of citizen journalists within a large news organisation. From this analysis we present a set of design implications for building systems that support interaction between citizen and professional journalists in order to encourage participatory news production and diversify national news perspectives.",
        "session": "SESSION: Journalism and social news"
    },
    {
        "title": "Bored mondays and focused afternoons: the rhythm of attention and online activity in the workplace",
        "authors": "Gloria Mark, Shamsi T. Iqbal, Mary Czerwinski, Paul Johns",
        "abstract": "While distractions using digital media have received attention in HCI, understanding engagement in workplace activities has been little explored. We logged digital activity and continually probed perspectives of 32 information workers for five days in situ to understand how attentional states change with context. We present a framework of how engagement and challenge in work relate to focus, boredom, and rote work. Overall, we find more focused attention than boredom in the workplace. Focus peaks mid-afternoon while boredom is highest in early afternoon. People are happiest doing rote work and most stressed doing focused work. On Mondays people are most bored but also most focused. Online activities are associated with different attentional states, showing different patterns at beginning and end of day, and before and after a mid-day break. Our study shows how rhythms of attentional states are associated with context and time, even in a dynamic workplace environment.",
        "session": "SESSION: Interruptions and distractions"
    },
    {
        "title": "CRISP: an interruption management algorithm based on collaborative filtering",
        "authors": "Tammar Shrot, Avi Rosenfeld, Jennifer Golbeck, Sarit Kraus",
        "abstract": "Interruptions can have a significant impact on users working to complete a task. When people are collaborating, either with other users or with systems, coordinating interruptions is an important factor in maintaining efficiency and preventing information overload. Computer systems can observe user behavior, model it, and use this to optimize the interruptions to minimize disruption. However, current techniques often require long training periods that make them unsuitable for online collaborative environments where new users frequently participate. In this paper, we present a novel synthesis between Collaborative Filtering methods and machine learning classification algorithms to create a fast learning algorithm, CRISP. CRISP exploits the similarities between users in order to apply data from known users to new users, therefore requiring less information on each person. Results from user studies indicate the algorithm significantly improves users' performances in completing the task and their perception of how long it took to complete each task.",
        "session": "SESSION: Interruptions and distractions"
    },
    {
        "title": "Interrupted by a phone call: exploring designs for lowering the impact of call notifications for smartphone users",
        "authors": "Matthias Böhmer, Christian Lander, Sven Gehring, Duncan P. Brumby, Antonio Krüger",
        "abstract": "Mobile phones have evolved significantly in recent years from single-purpose communication devices to multi-purpose computing devices. Despite this evolution, the interaction model for how incoming calls are handled has barely changed. Current-generation smartphones still use abrupt full-screen notifications to alert users to incoming calls, demanding a decision to either accept or decline the call. These full-screen notifications forcibly interrupt whatever activity the user was already engaged in. This might be undesirable when the user's primary task was more important than the incoming call. This paper explores the design space for how smartphones can alert users to incoming calls. We consider designs that allow users to postpone calls and also to multiplex by way of a smaller partial-screen notification. These design alternatives were evaluated in both a small-scale controlled lab study as well as a large-scale naturalistic in-the-wild study. Results show that a multiplex design solution works best because it allows people to continue working on their primary task while being made aware that there is a caller on the line. The contribution of this work is an enhanced interaction design for handling phone calls, and an understanding of how people use it for handling incoming calls.",
        "session": "SESSION: Interruptions and distractions"
    },
    {
        "title": "Large-scale assessment of mobile notifications",
        "authors": "Alireza Sahami Shirazi, Niels Henze, Tilman Dingler, Martin Pielot, Dominik Weber, Albrecht Schmidt",
        "abstract": "Notifications are a core feature of mobile phones. They inform users about a variety of events. Users may take immediate action or ignore them depending on the importance of a notification as well as their current context. The nature of notifications is manifold, applications use them both sparsely and frequently. In this paper we present the first large-scale analysis of mobile notifications with a focus on users' subjective perceptions. We derive a holistic picture of notifications on mobile phones by collecting close to 200 million notifications from more than 40,000 users. Using a data-driven approach, we break down what users like and dislike about notifications. Our results reveal differences in importance of notifications and how users value notifications from messaging apps as well as notifications that include information about people and events. Based on these results we derive a number of findings about the nature of notifications and guidelines to effectively use them.",
        "session": "SESSION: Interruptions and distractions"
    },
    {
        "title": "Customization bias in decision support systems",
        "authors": "Jacob Solomon",
        "abstract": "Many Decision Support Systems (DSS) afford customization of inputs or algorithms before generating recommendations to a decision maker. This paper describes an experiment in which users make decisions assisted by recommendations of a DSS in a fantasy baseball game. This experiment shows that the act of customizing a DSS can lead to biased decision making. I show that users who believe they have customized a DSS's recommendation algorithm are more likely to follow the recommendations regardless of their accuracy. I also show that this customization bias is the result of using a DSS to seek confirmatory information in a recommendation.",
        "session": "SESSION: Decisions, recommendations, and machine learning"
    },
    {
        "title": "Structured labeling for facilitating concept evolution in machine learning",
        "authors": "Todd Kulesza, Saleema Amershi, Rich Caruana, Danyel Fisher, Denis Charles",
        "abstract": "Labeling data is a seemingly simple task required for training many machine learning systems, but is actually fraught with problems. This paper introduces the notion of concept evolution, the changing nature of a person's underlying concept (the abstract notion of the target class a person is labeling for, e.g., spam email, travel related web pages) which can result in inconsistent labels and thus be detrimental to machine learning. We introduce two structured labeling solutions, a novel technique we propose for helping people define and refine their concept in a consistent manner as they label. Through a series of five experiments, including a controlled lab study, we illustrate the impact and dynamics of concept evolution in practice and show that structured labeling helps people label more consistently in the presence of concept evolution than traditional labeling.",
        "session": "SESSION: Decisions, recommendations, and machine learning"
    },
    {
        "title": "Choice-based preference elicitation for collaborative filtering recommender systems",
        "authors": "Benedikt Loepp, Tim Hussein, Jüergen Ziegler",
        "abstract": "We present an approach to interactive recommending that combines the advantages of algorithmic techniques with the benefits of user-controlled, interactive exploration in a novel manner. The method extracts latent factors from a matrix of user rating data as commonly used in Collaborative Filtering, and generates dialogs in which the user iteratively chooses between two sets of sample items. Samples are chosen by the system for low and high values of each latent factor considered. The method positions the user in the latent factor space with few interaction steps, and finally selects items near the user position as recommendations. In a user study, we compare the system with three alternative approaches including manual search and automatic recommending. The results show significant advantages of our approach over the three competing alternatives in 15 out of 24 possible parameter comparisons, in particular with respect to item fit, interaction effort and user control. The findings corroborate our assumption that the proposed method achieves a good trade-off between automated and interactive functions in recommender systems.",
        "session": "SESSION: Decisions, recommendations, and machine learning"
    },
    {
        "title": "Finding dependencies between actions using the crowd",
        "authors": "Walter S. Lasecki, Leon Weingard, George Ferguson, Jeffrey P. Bigham",
        "abstract": "Activity recognition can provide computers with the context underlying user inputs, enabling more relevant responses and more fluid interaction. However, training these systems is difficult because it requires observing every possible sequence of actions that comprise a given activity. Prior work has enabled the crowd to provide labels in real-time to train automated systems on-the-fly, but numerous examples are still needed before the system can recognize an activity on its own. To reduce the need to collect this data by observing users, we introduce ARchitect, a system that uses the crowd to capture the dependency structure of the actions that make up activities. Our tests show that over seven times as many examples can be collected using our approach versus relying on direct observation alone, demonstrating that by leveraging the understanding of the crowd, it is possible to more easily train automated systems.",
        "session": "SESSION: Decisions, recommendations, and machine learning"
    },
    {
        "title": "Scalable multi-label annotation",
        "authors": "Jia Deng, Olga Russakovsky, Jonathan Krause, Michael S. Bernstein, Alex Berg, Li Fei-Fei",
        "abstract": "We study strategies for scalable multi-label annotation, or for efficiently acquiring multiple labels from humans for a collection of items. We propose an algorithm that exploits correlation, hierarchy, and sparsity of the label distribution. A case study of labeling 200 objects using 20,000 images demonstrates the effectiveness of our approach. The algorithm results in up to 6x reduction in human computation time compared to the naive method of querying a human annotator for the presence of every object in every image.",
        "session": "SESSION: Decisions, recommendations, and machine learning"
    },
    {
        "title": "Wearables and chairables: inclusive design of mobile input and output techniques for power wheelchair users",
        "authors": "Patrick Carrington, Amy Hurst, Shaun K. Kane",
        "abstract": "Power wheelchair users often use and carry multiple mobile computing devices. Many power wheelchair users have some upper body motor impairment that can make using these devices difficult. We believe that mobile device accessibility could be improved through designs that take into account users' functional abilities and take advantage of available space around the wheelchair itself. In this paper we present findings from multiple design sessions and interviews with 13 power wheelchair users and 30 clinicians, exploring the placement and form factor possibilities for input and output on a power wheelchair. We found that many power wheelchair users could benefit from chairable technology that is designed to work within the workspace of the wheelchair, whether worn on the body or mounted on he wheelchair frame. We present participants' preferences for chairable input and output devices, and identify possible design configurations for wearable and chairable devices.",
        "session": "SESSION: Accessibility"
    },
    {
        "title": "The last meter: blind visual guidance to a target",
        "authors": "Roberto Manduchi, James M. Coughlan",
        "abstract": "Smartphone apps can use object recognition software to provide information to blind or low vision users about objects in the visual environment. A crucial challenge for these users is aiming the camera properly to take a well-framed picture of the desired target object. We investigate the effects of two fundamental constraints of object recognition -- frame rate and camera field of view -- on a blind person's ability to use an object recognition smartphone app. The app was used by 18 blind participants to find visual targets beyond arm's reach and approach them to within 30 cm. While we expected that a faster frame rate or wider camera field of view should always improve search performance, our experimental results show that in many cases increasing the field of view does not help, and may even hurt, performance. These results have important implications for the design of object recognition systems for blind users.",
        "session": "SESSION: Accessibility"
    },
    {
        "title": "Current and future mobile and wearable device use by people with visual impairments",
        "authors": "Hanlu Ye, Meethu Malu, Uran Oh, Leah Findlater",
        "abstract": "With the increasing popularity of mainstream wearable devices, it is critical to assess the accessibility implications of such technologies. For people with visual impairments, who do not always need the visual display of a mobile phone, alternative means of eyes-free wearable interaction are particularly appealing. To explore the potential impacts of such technology, we conducted two studies. The first was an online survey that included 114 participants with visual impairments and 101 sighted participants; we compare the two groups in terms of current device use. The second was an interview and design probe study with 10 participants with visual impairments. Our findings expand on past work to characterize a range of trends in smartphone use and accessibility issues therein. Participants with visual impairments also responded positively to two eyes-free wearable device scenarios: a wristband or ring and a glasses-based device. Discussions on projected use of these devices suggest that small, easily accessible, and discreet wearable input could positively impact the ability of people with visual impairments to access information on the go and to participate in certain social interactions.",
        "session": "SESSION: Accessibility"
    },
    {
        "title": "Visually impaired users on an online social network",
        "authors": "Shaomei Wu, Lada A. Adamic",
        "abstract": "In this paper we present the first large-scale empirical study of how visually impaired people use online social networks, specifically Facebook. We identify a sample of 50K visually impaired users, and study the activities they perform, the content they produce, and the friendship networks they build on Facebook. We find that visually impaired users participate on Facebook (e.g. status updates, comments, likes) as much as the general population, and receive more feedback (i.e., comments and likes) on average on their content. By analyzing the content produced by visually impaired users, we find that they share their experience and issues related to vision impairment. We also identify distinctive patterns in their language and technology use. We also show that, compared to other users, visually impaired users have smaller social networks, but such differences have decreased over time. Our findings have implications for improving the utility and usability of online social networks for visually impaired users.",
        "session": "SESSION: Accessibility"
    },
    {
        "title": "Kickables: tangibles for feet",
        "authors": "Dominik Schmidt, Raf Ramakers, Esben W. Pedersen, Johannes Jasper, Sven Köhler, Aileen Pohl, Hannes Rantzsch, Andreas Rau, Patrick Schmidt, Christoph Sterz, Yanina Yurchenko, Patrick Baudisch",
        "abstract": "We introduce the concept of tangibles that users can manipulate with their feet. We call them kickables. Unlike traditional tangibles, kickables allow for very large interaction surfaces as kickables reside on the ground. The main benefit of kickables over other foot-based modalities, such as foot touch, is their strong affordance, which we validate in two user studies. This affordance makes kickables well-suited for walk-up installations, such as tradeshows or museum exhibits. We present a custom design as well as five families of standard kickables to help application designers create kickable applications faster. Each family supports multiple standard controls, such as push buttons, switches, dials, and sliders. Each type explores a different design principle, in particular different mechanical constraints. We demonstrate an implementation on our pressure-sensing floor.",
        "session": "SESSION: Tangible interactions and technologies"
    },
    {
        "title": "GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays",
        "authors": "Rong-Hao Liang, Liwei Chan, Hung-Yu Tseng, Han-Chih Kuo, Da-Yuan Huang, De-Nian Yang, Bing-Yu Chen",
        "abstract": "This work describes a novel building block system for tangible interaction design, GaussBricks, which enables real-time constructive tangible interactions on portable displays. Given its simplicity, the mechanical design of the magnetic building blocks facilitates the construction of configurable forms. The form constructed by the magnetic building blocks, which are connected by the magnetic joints, allows users to stably manipulate with various elastic force feedback mechanisms. With an analog Hall-sensor grid mounted to its back, a portable display determines the geometrical configuration and detects various user interactions in real time. This work also introduce several methods to enable shape changing, multi-touch input, and display capabilities in the construction. The proposed building block system enriches how individuals interact with the portable displays physically.",
        "session": "SESSION: Tangible interactions and technologies"
    },
    {
        "title": "Designing tangible video games: lessons learned from the sifteo cubes",
        "authors": "Clément Pillias, Raphaël Robert-Bouchard, Guillaume Levieux",
        "abstract": "In this paper, we present a collaborative game designed for Sifteo Cubes, a new tangible interface for multiplayer games. We discuss how this game exploits the platform's interface to transfer some of the game mechanics into the non-digital world, and how this approach affects both the player's experience and the design process. We present the technical limitations encountered during game development and analyze video recordings of play sessions with regard to the play strategies developed by the players. Then, we identify two properties that this game shares with many other games on tangible platforms and discuss how these properties influence both the game design process and the player experience. We advocate that these properties provide players with more freedom and relatedness, while helping to create an easy-to-learn and customizable gameplay, despite their own design limitations.",
        "session": "SESSION: Tangible interactions and technologies"
    },
    {
        "title": "A low-cost transparent electric field sensor for 3d interaction on mobile devices",
        "authors": "Mathieu Le Goc, Stuart Taylor, Shahram Izadi, Cem Keskin",
        "abstract": "We contribute a thin, transparent, and low-cost design for electric field sensing, allowing for 3D finger and hand tracking and gestures on mobile devices. Our approach requires no direct instrumentation of the hand or body, and is non-optical, allowing for a compact form-factor that is resilient to ambient illumination. Our simple driver electronics are based on an off-the-shelf chip that removes the need for building custom analog electronics. We describe the design of our transparent electrode array, and present a machine learning algorithm for mapping from signal measurements at the receivers to 3D positions. We demonstrate non-contact motion gestures, and precise 3D hand and finger localization. We conclude by discussing limitations and future work.",
        "session": "SESSION: Tangible interactions and technologies"
    },
    {
        "title": "The personal cockpit: a spatial interface for effective task switching on head-worn displays",
        "authors": "Barrett M. Ens, Rory Finnegan, Pourang P. Irani",
        "abstract": "As wearable computing goes mainstream, we must improve the state of interface design to keep users productive with natural-feeling interactions. We present the Personal Cockpit, a solution for mobile multitasking on head-worn displays. We appropriate empty space around the user to situate virtual windows for use with direct input. Through a design-space exploration, we run a series of user studies to fine-tune our layout of the Personal Cockpit. In our final evaluation, we compare our design against two baseline interfaces for switching between everyday mobile applications. This comparison highlights the deficiencies of current view-fixed displays, as the Personal Cockpit provides a 40% improvement in application switching time. We demonstrate of several useful implementations and a discussion of important problems for future implementation of our design on current and near-future wearable devices.",
        "session": "SESSION: Head-worn displays"
    },
    {
        "title": "Exploring the use of hand-to-face input for interacting with head-worn displays",
        "authors": "Marcos Serrano, Barrett M. Ens, Pourang P. Irani",
        "abstract": "We propose the use of Hand-to-Face input, a method to interact with head-worn displays (HWDs) that involves contact with the face. We explore Hand-to-Face interaction to find suitable techniques for common mobile tasks. We evaluate this form of interaction with document navigation tasks and examine its social acceptability. In a first study, users identify the cheek and forehead as predominant areas for interaction and agree on gestures for tasks involving continuous input, such as document navigation. These results guide the design of several Hand-to-Face navigation techniques and reveal that gestures performed on the cheek are more efficient and less tiring than interactions directly on the HWD. Initial results on the social acceptability of Hand-to-Face input allow us to further refine our design choices, and reveal unforeseen results: some gestures are considered culturally inappropriate and gender plays a role in selection of specific Hand-to-Face interactions. From our overall results, we provide a set of guidelines for developing effective Hand-to-Face interaction techniques.",
        "session": "SESSION: Head-worn displays"
    },
    {
        "title": "Permulin: mixed-focus collaboration on multi-view tabletops",
        "authors": "Roman Lissermann, Jochen Huber, Martin Schmitz, Jürgen Steimle, Max Mühlhäuser",
        "abstract": "We contribute Permulin, an integrated set of interaction and visualization techniques for multi-view tabletops to support co-located collaboration across a wide variety of collaborative coupling styles. These techniques (1) provide support both for group work and for individual work, as well as for the transitions in-between, (2) contribute sharing and peeking techniques to support mutual awareness and group coordination during phases of individual work, (3) reduce interference during group work on a group view, and (4) directly integrate with conventional multi-touch input. We illustrate our techniques in a proof-of-concept implementation with the two example applications of map navigation and photo collages. Results from two user studies demonstrate that Permulin supports fluent transitions between individual and group work and exhibits unique awareness properties that allow participants to be highly aware of each other during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.",
        "session": "SESSION: Head-worn displays"
    },
    {
        "title": "In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time",
        "authors": "Felix Lauber, Andreas Butz",
        "abstract": "One unique property of head-mounted displays (HMDs) is that content can easily be displayed at a fixed position within the user's field of view (head-stabilized). This ensures that critical information (e.g. warnings) is continuously visible and can, in principle, be perceived as quickly as possible. We examined this strategy with a physically and visually distracted driver. We ran two consecutive studies in a driving simulator, comparing different warning visualizations in a head-up display (HUD) and a HMD. In an initial study, we found no significant effects of warning type or display technology on the reaction times. In a second study, after modifying our visualization to include a visual reference marker, we found that with only this minor change, reaction times were significantly lower in the HMD when compared to the HUD. Our insights can help others design better head-stabilized notifications.",
        "session": "SESSION: Head-worn displays"
    },
    {
        "title": "Kinect-taped communication: using motion sensing to study gesture use and similarity in face-to-face and computer-mediated brainstorming",
        "authors": "Hao-Chuan Wang, Chien-Tung Lai",
        "abstract": "One key difference between face-to-face (F2F) communication and computer-mediated communication (CMC) is the availability of visual cues. It is often assumed that the reduction of visibility in audio and video conferencing may negatively impact the use of gesture to communicate, and thus negatively influence other outcomes. In this paper we \"Kinect-taped\" F2F and CMC communication in brainstorming groups by using motion sensors to record and analyze group members' hand movements during communication. We investigate how different media influence gesture use and gestural similarity, and how the use of gesture associates with level of understanding and brainstorming performance. Implications to future research and design are discussed.",
        "session": "SESSION: Applications of body sensing"
    },
    {
        "title": "Is motion capture-based biomechanical simulation valid for HCI studies?: study and implications",
        "authors": "Myroslav Bachynskyi, Antti Oulasvirta, Gregorio Palmas, Tino Weinkauf",
        "abstract": "Motion-capture-based biomechanical simulation is a non-invasive analysis method that yields a rich description of posture, joint, and muscle activity in human movement. The method is presently gaining ground in sports, medicine, and industrial ergonomics, but it also bears great potential for studies in HCI where the physical ergonomics of a design is important. To make the method more broadly accessible, we study its predictive validity for movements and users typical to studies in HCI. We discuss the sources of error in biomechanical simulation and present results from two validation studies conducted with a state-of-the-art system. Study I tested aimed movements ranging from multitouch gestures to dancing, finding out that the critical limiting factor is the size of movement. Study II compared muscle activation predictions to surface-EMG recordings in a 3D pointing task. The data shows medium-to-high validity that is, however, constrained by some characteristics of the movement and the user. We draw concrete recommendations to practitioners and discuss challenges to developing the method further.",
        "session": "SESSION: Applications of body sensing"
    },
    {
        "title": "RecoFit: using a wearable sensor to find, recognize, and count repetitive exercises",
        "authors": "Dan Morris, T. Scott Saponas, Andrew Guillory, Ilya Kelner",
        "abstract": "Although numerous devices exist to track and share exercise routines based on running and walking, these devices offer limited functionality for strength-training exercises. We introduce RecoFit, a system for automatically tracking repetitive exercises - such as weight training and calisthenics - via an arm-worn inertial sensor. Our goal is to provide real-time and post-workout feedback, with no user-specific training and no intervention during a workout. Toward this end, we address three challenges: (1) segmenting exercise from intermittent non-exercise periods, (2) recognizing which exercise is being performed, and (3) counting repetitions. We present cross-validation results on our training data and results from a study assessing the final system, totaling 114 participants over 146 sessions. We achieve precision and recall greater than 95% in identifying exercise periods, recognition of 99%, 98%, and 96% on circuits of 4, 7, and 13 exercises respectively, and counting that is accurate to ±1 repetition 93% of the time. These results suggest that our approach enables a new category of fitness tracking devices.",
        "session": "SESSION: Applications of body sensing"
    },
    {
        "title": "Improving automatic speech recognition through head pose driven visual grounding",
        "authors": "Soroush Vosoughi",
        "abstract": "In this paper, we present a multimodal speech recognition system for real world scene description tasks. Given a visual scene, the system dynamically biases its language model based on the content of the visual scene and visual attention of the speaker. Visual attention is used to focus on likely objects within the scene. Given a spoken description the system then uses the visually biased language model to process the speech. The system uses head pose as a proxy for the visual attention of the speaker. Readily available standard computer vision algorithms are used to recognize the objects in the scene and automatic real time head pose estimation is done using depth data captured via a Microsoft Kinect. The system was evaluated on multiple participants. Overall, incorporating visual information into the speech recognizer greatly improved speech recognition accuracy. The rapidly decreasing cost of 3D sensing technologies such as the Kinect allows systems with similar underlying principles to be used for many speech recognition tasks where there is visual information.",
        "session": "SESSION: Applications of body sensing"
    },
    {
        "title": "Tensions in scaling-up community social media: a multi-neighborhood study of nextdoor",
        "authors": "Christina A. Masden, Catherine Grevet, Rebecca E. Grinter, Eric Gilbert, W. Keith Edwards",
        "abstract": "This paper presents a study of Nextdoor, a social media system designed to support local neighborhoods. While not the first system designed to support community engagement, Nextdoor has a number of attributes that make it distinct. Our study, across three communities in a major U.S. city, illustrates that Nextdoor inhabits an already-rich ecosystem of community-oriented social media, but is being appropriated by its users for use in different ways than these existing media. Nextdoor also raises tensions in how it defines the boundaries of neighborhoods, and in the privacy issues it raises among its users.",
        "session": "SESSION: Urban communities and social media"
    },
    {
        "title": "Curated city: capturing individual city guides through social curation",
        "authors": "Justin B. Cranshaw, Kurt Luther, Patrick Gage Kelley, Norman Sadeh",
        "abstract": "We report on our design of Curated City, a website that lets people build their own personal guide to the city's neighborhoods by chronicling their favorite experiences. Although users make their own personal guides, they are immersed in a social curatorial experience where they are influenced directly and indirectly by the guides of others. We use a 2-week field trial involving 20 residents of Pittsburgh as a technological probe to explore the initial design decisions, and we further refine the design landscape through subject interviews. Based on this study, we identify a set of design recommendations for building scalable social platforms for curating the experiences of the city.",
        "session": "SESSION: Urban communities and social media"
    },
    {
        "title": "ZWERM: a modular component network approach for an urban participation game",
        "authors": "Thomas Laureyssens, Tanguy Coenen, Laurence Claeys, Peter Mechant, Johan Criel, Andrew Vande Moere",
        "abstract": "As information technology is increasingly embedded in our cities, opportunities arise to design novel applications that benefit urban communities. We describe the design and evaluation of ZWERM (Dutch for the term 'swarm'), a public game that was specifically designed for augmenting community participation in urban neighborhoods. A network of ten components has been designed, some of which had different interfaces and design approaches: from totem-like Trees for gathering around with RFID cards to playful Sparrows that react on whistle sounds. After implementing the urban game in two city neighborhoods, we investigated the impact of each of these components on their communities. Our insights are useful for the public interaction design of future urban, interactive networks that aim to positively influence community participation and social cohesion.",
        "session": "SESSION: Urban communities and social media"
    },
    {
        "title": "Studying digital graffiti as a location-based social network",
        "authors": "David K. McGookin, Stephen A. Brewster, Georgi Christov",
        "abstract": "Increasing amounts of geo-tagged social media have led to interest in how that media can be re-integrated into the physical environment. Yet, although location information is often automatically appended to media, little is know about how users consider location in its creation and viewing. Using Graffiti as a design meme, we developed a novel social media service to investigate these issues. A two week field study showed how users incorporated both utilitarian and playful aspects of location into their social media creation, as well as revealing a disconnect between the location-media relationship intended by creators and perceived by viewers. We outline implications of our work for services that seek to repurpose existing geo-tagged social media in the design of novel services.",
        "session": "SESSION: Urban communities and social media"
    },
    {
        "title": "Social epistemic cognition in online interactions",
        "authors": "Rosanna Yuen-Yan Chan, Silu Li, Diane Hui",
        "abstract": "Social media and online social networks dramatically change the way in which knowledge is acquired and disseminated. How do we re-understand about human knowledge and knowing? This work aims at extending the current understanding of human epistemic cognition in online social environments, where epistemic cognition refers to cognitions and cognitive processes related to epistemic matters such as knowledge and beliefs justification. We approach our inquiry with mixed methods: (1) quantitative study to test whether epistemic cognition might differ in individual and social contexts, and whether online interactions might mediate the later; and (2) social cognitive task analysis with interviews to manifest the intricate interplay of dynamics between social epistemic cognition and online interactions. We introduce the new construct of social epistemic cognition and contribute to the field of HCI with an evolved theory which states that epistemic cognition can be promoted in online social environments as mediated by online interactions.",
        "session": "SESSION: Social media usage"
    },
    {
        "title": "Share your view: impact of co-navigation support and status composition in collaborative online shopping",
        "authors": "Yanzhen Yue, Xiaojuan Ma, Zhenhui Jiang",
        "abstract": "Collaborative online shopping, an emerging paradigm in e-commerce, allows remote shoppers to extend purchase-oriented social interactions into the digital environment. Online vendors have been experimenting ways to facilitate this activity. However, more research needs to be done on identifying what feature can create a pleasing shopping experience and ultimately encourage spending. In this paper, we present an exploration of the impact of co-navigation supports, including location cue, split screen, and shared view, on the experiences and performance of 60 co-shopper dyads. We also studied if status composition of shopping companions played a role in this process. By analyzing about 1800 minutes of eye-tracking data, video footages, and web logs, we found that split screen encouraged more diverse product search, shared view enabled better coordination, and location cue was the least distracting. Co-buyers achieved better factual and inference understanding, though buyer-advisor dyads were more likely to stay together.",
        "session": "SESSION: Social media usage"
    },
    {
        "title": "Nutriflect: reflecting collective shopping behavior and nutrition",
        "authors": "Wolfgang H. Reitberger, Wolfgang Spreicer, Geraldine Fitzpatrick",
        "abstract": "A poor nutritional state, as is the case for many people today, can increase risks for cancer, cardiovascular disease and obesity. Technology supported approaches could potentially be used to positively influence food consumption. We present the Nutriflect system, which utilizes users' shopping data to inform them about their long term shopping behavior. In an initial study we conducted structured interviews in grocery stores. Based on the results we implemented a system that visualized a household's collective shopping information via situated displays. The aim was to raise awareness about shopping habits and to enable reflection about nutrition without burdening the users with the manual entry of their eating habits. We evaluated the system in a 4 week field study in 8 households with 21 users. The results indicate that contextually situated displays, showing shopping patterns against personal nutrition goals, can foster a reflective and respectful approach towards better shopping and nutrition.",
        "session": "SESSION: Social media usage"
    },
    {
        "title": "Didn't you see my message?: predicting attentiveness to mobile instant messages",
        "authors": "Martin Pielot, Rodrigo de Oliveira, Haewoon Kwak, Nuria Oliver",
        "abstract": "Mobile instant messaging (e.g., via SMS or WhatsApp) often goes along with an expectation of high attentiveness, i.e., that the receiver will notice and read the message within a few minutes. Hence, existing instant messaging services for mobile phones share indicators of availability, such as the last time the user has been online. However, in this paper we not only provide evidence that these cues create social pressure, but that they are also weak predictors of attentiveness. As remedy, we propose to share a machine-computed prediction of whether the user will view a message within the next few minutes or not. For two weeks, we collected behavioral data from 24 users of mobile instant messaging services. By the means of machine-learning techniques, we identified that simple features extracted from the phone, such as the user's interaction with the notification center, the screen activity, the proximity sensor, and the ringer mode, are strong predictors of how quickly the user will attend to the messages. With seven automatically selected features our model predicts whether a phone user will view a message within a few minutes with 70.6% accuracy and a precision for fast attendance of 81.2%",
        "session": "SESSION: Social media usage"
    },
    {
        "title": "Using extracted features to inform alignment-driven design ideas in an educational game",
        "authors": "Erik Harpstead, Christopher J. MacLellan, Vincent Aleven, Brad A. Myers",
        "abstract": "As educational games have become a larger field of study, there has been a growing need for analytic methods that can be used to assess game design and inform iteration. While much previous work has focused on the measurement of student engagement or learning at a gross level, we argue that new methods are necessary for measuring the alignment of a game to its target learning goals at an appropriate level of detail to inform design decisions. We present a novel technique that we have employed to examine alignment in an open-ended educational game. The approach is based on examining how the game reacts to representative student solutions that do and do not obey target principles. We demonstrate this method using real student data and discuss how redesign might be informed by these techniques.",
        "session": "SESSION: Games and education"
    },
    {
        "title": "Brain points: a growth mindset incentive structure boosts persistence in an educational game",
        "authors": "Eleanor O'Rourke, Kyla Haimovitz, Christy Ballweber, Carol Dweck, Zoran Popović",
        "abstract": "There is great interest in leveraging video games to improve student engagement and motivation. However, educational games are not uniformly effective, and little is known about how in-game rewards affect children's learning-related behavior. In this work, we argue that educational games can be improved by fundamentally changing their incentive structures to promote the growth mindset, or the belief that intelligence is malleable. We present \"brain points,\" a system that encourages the development of growth mindset behaviors by directly incentivizing effort, use of strategy, and incremental progress. Through a study of 15,000 children, we show that the \"brain points\" system encourages more low-performing students to persist in the educational game Refraction when compared to a control, and increases overall time played, strategy use, and perseverance after challenge. We believe that this growth mindset incentive structure has great potential in many educational environments.",
        "session": "SESSION: Games and education"
    },
    {
        "title": "Towards automatic experimentation of educational knowledge",
        "authors": "Yun-En Liu, Travis Mandel, Emma Brunskill, Zoran Popović",
        "abstract": "We present a general automatic experimentation and hypothesis generation framework that utilizes a large set of users to explore the effects of different parts of an intervention parameter space on any objective function. We also incorporate importance sampling, allowing us to run these automatic experiments even if we cannot give out the exact intervention distributions that we want. To show the utility of this framework, we present an implementation in the domain of fractions and numberlines, using an online educational game as the source of players. Our system is able to automatically explore the parameter space and generate hypotheses about what types of numberlines lead to maximal short-term transfer; testing on a separate dataset shows the most promising hypotheses are valid. We briefly discuss our results in the context of the wider educational literature, showing that one of our results is not explained by current research on multiple fraction representations, thus proving our ability to generate potentially interesting hypotheses to test.",
        "session": "SESSION: Games and education"
    },
    {
        "title": "Spending real money: purchasing patterns of virtual goods in an online social game",
        "authors": "Donghee Yvette Wohn",
        "abstract": "Researchers have found that 'social' factors contribute to purchasing intentions of virtual goods in an online social game, but little is known about actual purchasing behavior. Study 1 examined the relationship between social factors and virtual goods purchasing patterns using large scale data obtained by server logs of an online social game. Exchange of virtual goods and number of friends increased the likelihood of spending real money compared to no spending. Among those who did spend real money, giving virtual goods to others was the strongest factor associated with the amount of spending. Study 2 examined purchasing patterns of players who spent real money: high real-money spenders were buying items for visual customization while low spenders were buying consumable items necessary to sustain playing the game.",
        "session": "SESSION: Games and education"
    },
    {
        "title": "CADament: a gamified multiplayer software tutorial system",
        "authors": "Wei Li, Tovi Grossman, George Fitzmaurice",
        "abstract": "We present CADament, a gamified multiplayer tutorial system for learning AutoCAD. Compared with existing gamified software tutorial systems, CADament generates engaging learning experience through competitions. We investigate two variations of our game, where over-the-shoulder learning was simulated by providing viewports into other player's screens. We introduce an empirical lab study methodology where participants compete with one another, and we study knowledge transfer effects by tracking the migration of strategies between players during the study session. Our study shows that CADament has an advantage over pre-authored tutorials for improving learners' performance, increasing motivation, and stimulating knowledge transfer.",
        "session": "SESSION: Learning and games"
    },
    {
        "title": "Combining crowdsourcing and learning to improve engagement and performance",
        "authors": "Mira Dontcheva, Robert R. Morris, Joel R. Brandt, Elizabeth M. Gerber",
        "abstract": "Crowdsourcing complex creative tasks remains difficult, in part because these tasks require skilled workers. Most crowdsourcing platforms do not help workers acquire the skills necessary to accomplish complex creative tasks. In this paper, we describe a platform that combines learning and crowdsourcing to benefit both the workers and the requesters. Workers gain new skills through interactive step-by-step tutorials and test their knowledge by improving real-world images submitted by requesters. In a series of three deployments spanning two years, we varied the design of our platform to enhance the learning experience and improve the quality of the crowd work. We tested our approach in the context of LevelUp for Photoshop, which teaches people how to do basic photograph improvement tasks using Adobe Photoshop. We found that by using our system workers gained new skills and produced high-quality edits for requested images, even if they had little prior experience editing images.",
        "session": "SESSION: Learning and games"
    },
    {
        "title": "A game-based learning approach to road safety: the code of everand",
        "authors": "Ian Dunwell, Sara de Freitas, Panagiotis Petridis, Maurice Hendrix, Sylvester Arnab, Petros Lameras, Craig Stewart",
        "abstract": "Game and gamification elements are increasingly seeing use as part of interface designs for applications seeking to engage and retain users whilst transferring information. This paper presents an evaluation of a game-based approach seeking to improve the road safety behaviour amongst children aged 9-15 within the UK, made available outside of a classroom context as an online, browser-based, free-to-play game. The paper reports on data for 99,683 players over 315,882 discrete logins, supplemented by results from a nationally-representative survey of children at UK schools (n=1,108), an incentivized survey of the player-base (n=1,028), and qualitative data obtained through a series of one-to-one interviews aged 9-14 (n=28). Analysis demonstrates the reach of the game to its target demographic, with 88.13% of players within the UK. A 3.94 male/female ratio was observed amongst players surveyed, with an age distribution across the target range of 9-15. Noting mean and median playtimes of 93 and 31 minutes (n=99,683), it is suggested such an approach to user engagement and retention can surpass typical contact times obtained through other forms of web-based content. The size of the player-base attracted to the game and players' qualitative feedback demonstrates the potential for serious games deployed on a national scale.",
        "session": "SESSION: Learning and games"
    },
    {
        "title": "L.IVE: an integrated interactive video-based learning environment",
        "authors": "Toni-Jan Keith Palma Monserrat, Yawen Li, Shengdong Zhao, Xiang Cao",
        "abstract": "In this paper, we introduce L.IVE: an online interactive video-based learning environment with an alternative design and architecture that integrates three major interface components: video, comment threads, and assessments. This is in contrast with the approach of existing interfaces which visually separate these components. Our study, which compares L.IVE with existing popular video-based learning environments, suggests advantages in this integrated approach as compared to the separated approach in learning.",
        "session": "SESSION: Learning and games"
    },
    {
        "title": "Persuasive technology for overcoming food cravings and improving snack choices",
        "authors": "Anne Hsu, Jing Yang, Yigit Han Yilmaz, Md Sanaul Haque, Cengiz Can, Ann E. Blandford",
        "abstract": "A central challenge in weight management is the difficulty of overcoming desires for excessive and unhealthy food. Yet, studies show that when people are able to resist their desires for unhealthy choices, they experience pride and satisfaction. In order to alleviate the former and support the latter, we designed, implemented and tested a mobile application for improving snacking behavior. Our application delivers a food craving reduction intervention at the moment of need and allows users to track how often they successfully resisted cravings. Our craving reduction intervention is based on recent research that shows that food cravings can be reduced through imagery techniques. We conducted a week-long evaluation of our application, comparing the effectiveness of our application to a basic tracking application. We found that our imagery application significantly reduced both overall snacking and unhealthy snacking compared to a simple snack-tracking application.",
        "session": "SESSION: Persuasive technologies and applications"
    },
    {
        "title": "The effects of embodied persuasive games on player attitudes toward people using wheelchairs",
        "authors": "Kathrin Maria Gerling, Regan L. Mandryk, Max Valentin Birk, Matthew Miller, Rita Orji",
        "abstract": "People using wheelchairs face barriers in their daily lives, many of which are created by people who surround them. Promoting positive attitudes towards persons with disabilities is an integral step in removing these barriers and improving their quality of life. In this context, persuasive games offer an opportunity of encouraging attitude change. We created a wheelchair-controlled persuasive game to study how embodied interaction can be applied to influence player attitudes over time. Our results show that the game intervention successfully raised awareness for challenges that people using wheelchairs face, and that embodied interaction is a more effective approach than traditional input in terms of retaining attitude change over time. Based on these findings, we provide design strategies for embodied interaction in persuasive games, and outline how our findings can be leveraged to help designers create effective persuasive experiences beyond games.",
        "session": "SESSION: Persuasive technologies and applications"
    },
    {
        "title": "Spent: changing students' affective learning toward homelessness through persuasive video game play",
        "authors": "Dana N. Ruggiero",
        "abstract": "To investigate whether a persuasive game may serve as a way to increase affective learning about homelessness, this study examined the effects of procedural rhetoric and ethos in a video game designed to put the player in the shoes of an almost-homeless person. Data were collected from 5139 students across four states. Examination revealed that playing the game or doing the reading significantly increased the affective learning score after treatment with the game group scoring 1.57 points higher and the reading group scoring .66 points higher out of a score of 6. Findings indicate that students who played Spent sustained significantly higher scores after three weeks. Overall, findings suggest that when students play a video game that is designed using persuasive mechanics an affective change can be measured empirically.",
        "session": "SESSION: Persuasive technologies and applications"
    },
    {
        "title": "Incentives to participate in online research: an experimental examination of \"surprise\" incentives",
        "authors": "Andrew T. Fiore, Coye Cheshire, Lindsay Shaw Taylor, G.A. Mendelsohn",
        "abstract": "The recruitment of participants for online survey research presents many challenges. In this work, we present four experiments examining how two different kinds of \"surprise\" financial incentives affect the rate of participation in a longitudinal study when participants are initially solicited with either an appeal to intrinsic motivation to participate in research or one that also offers extrinsic financial incentives. We find that unexpected financial incentives (\"existence surprises\") presented to people who click a recruitment advertisement focused on intrinsic incentives lead to a lower recruitment rate than do the same incentives offered to those who clicked an advertisement that led them to expect it. However, when potential participants expect a financial incentive, surprising them with a higher amount (\"amount surprises\") yields a higher recruitment rate. We interpret these results in the context of crowding theory. Neither type of surprise affected ongoing participation, measured as the number of questions and questionnaires completed over the course of the study.",
        "session": "SESSION: Persuasive technologies and applications"
    },
    {
        "title": "Combining body pose, gaze, and gesture to determine intention to interact in vision-based interfaces",
        "authors": "Julia Schwarz, Charles Claudius Marais, Tommer Leyvand, Scott E. Hudson, Jennifer Mankoff",
        "abstract": "Vision-based interfaces, such as those made popular by the Microsoft Kinect, suffer from the Midas Touch problem: every user motion can be interpreted as an interaction. In response, we developed an algorithm that combines facial features, body pose and motion to approximate a user's intention to interact with the system. We show how this can be used to determine when to pay attention to a user's actions and when to ignore them. To demonstrate the value of our approach, we present results from a 30-person lab study conducted to compare four engagement algorithms in single and multi-user scenarios. We found that combining intention to interact with a 'raise an open hand in front of you' gesture yielded the best results. The latter approach offers a 12% improvement in accuracy and a 20% reduction in time to engage over a baseline 'wave to engage' gesture currently used on the Xbox 360.",
        "session": "SESSION: Whole body sensing and interaction"
    },
    {
        "title": "Wave to me: user identification using body lengths and natural gestures",
        "authors": "Eiji Hayashi, Manuel Maas, Jason I. Hong",
        "abstract": "We introduce a body-based identification system that leverages individual differences in body segment lengths and hand waving gesture patterns. The system identifies users based on a two-second hand waving gesture captured by a Microsoft Kinect. To evaluate our system, we collected 8640 gesture measurements from 75 participants through two lab studies and a field study. In the first lab study, we evaluated the feasibility of our concept and basic properties of features to narrow down the design space. In the second lab study, our system achieved a 1% equal error rate in user identification among seven registered users after two weeks following initial registration. We also found that our system was robust even when lower body segments could not be measured because of occlusions. In the field study, our system achieved 0.5 to 1.6% equal error rates, demonstrating that the system also works well in ecologically valid situations. Lastly, throughout the studies, our participants were positive about the system.",
        "session": "SESSION: Whole body sensing and interaction"
    },
    {
        "title": "Haptic turk: a motion platform based on people",
        "authors": "Lung-Pan Cheng, Patrick Lühne, Pedro Lopes, Christoph Sterz, Patrick Baudisch",
        "abstract": "Motion platforms are used to increase the realism of virtual interaction. Unfortunately, their size and weight is proportional to the size of what they actuate. We present haptic turk, a different approach to motion platforms that is light and mobile. The key idea is to replace motors and mechanical components with humans. All haptic turk setups consist of a player who is supported by one or more turkers. The player enjoys an interactive experience, such as a flight simulation. The motion in the player's experience is generated by the turkers who manually lift, tilt, and push the player's limbs or torso. To get the timing and force right, timed motion instructions in a format familiar from rhythm games are displayed on turkers' mobile devices, which they attach to the player's body. We demonstrate a range of installations based on mobile phones, projectors, and head-mounted displays. In our user study, participants rated not only the experience as player as enjoyable (6.1/7), but also the experience as a turker (4.4/7). The approach of leveraging humans allows us to deploy our approach anytime anywhere, as we demonstrate by experimentally deploying at an art festival in the Nevada desert.",
        "session": "SESSION: Whole body sensing and interaction"
    },
    {
        "title": "Audience experience in social videogaming: effects of turn expectation and game physicality",
        "authors": "John Downs, Frank Vetere, Steve Howard, Steve Loughnan, Wally Smith",
        "abstract": "Videogames are often played socially with both co-players and audiences. Audience members' experiences are not well understood, nor are the factors of videogaming sessions that influence their experience. We conducted a study to examine the effects of game physicality and turn anticipation on audience members' experiences in social videogaming sessions. Pairs of participants played games under three conditions of physicality (controller-based, Wii, and Kinect) and their expectation of turn-taking was manipulated. Their enjoyment, game engagement, social engagement and sense of participation were measured. We found that the introduction of turn-taking into the session had positive effects for audience members -- both anticipated and residual play effects -- and that Kinect gameplay resulted in a more enjoyable experience for audience members. We argue that audience members' experience changes as they become more active within a session, and suggest there are design opportunities between purely active 'players' and passive 'audience members'.",
        "session": "SESSION: Whole body sensing and interaction"
    },
    {
        "title": "Exploiting thermal reflection for interactive systems",
        "authors": "Alireza Sahami Shirazi, Yomna Abdelrahman, Niels Henze, Stefan Schneegass, Mohammadreza Khalilbeigi, Albrecht Schmidt",
        "abstract": "Thermal cameras have recently drawn the attention of HCI researchers as a new sensory system enabling novel interactive systems. They are robust to illumination changes and make it easy to separate human bodies from the image background. Far-infrared radiation, however, has another characteristic that distinguishes thermal cameras from their RGB or depth counterparts, namely thermal reflection. Common surfaces reflect thermal radiation differently than visual light and can be perfect thermal mirrors. In this paper, we show that through thermal reflection, thermal cameras can sense the space beyond their direct field-of-view. A thermal camera can sense areas besides and even behind its field-of-view through thermal reflection. We investigate how thermal reflection can increase the interaction space of projected surfaces using camera-projection systems. We moreover discuss the reflection characteristics of common surfaces in our vicinity in both the visual and thermal radiation bands. Using a proof-of-concept prototype, we demonstrate the increased interaction space for hand-held camera-projection system. Furthermore, we depict a number of promising application examples that can benefit from the thermal reflection characteristics of surfaces.",
        "session": "SESSION: Novel mobile displays and devices"
    },
    {
        "title": "MisTable: reach-through personal screens for tabletops",
        "authors": "Diego Martinez Plasencia, Edward Joyce, Sriram Subramanian",
        "abstract": "We present MisTable, a tabletop system that combines a conventional horizontal interactive surface with personal screens between the user and the tabletop surface. These personal screens, built using fog, are both see-through and reach-through. Being see-through provides direct line of sight of the personal screen and the elements behind it on the tabletop. Being reach-through allows the user to switch from interacting with the personal screen to reaching through it to interact with the tabletop or the space above it. The personal screen allows a range of customisations and novel interactions such as presenting 2D personal contents on the screen, 3D contents above the tabletop or augmenting and relighting tangible objects differently for each user. Besides, having a personal screen for each user allows us to customize the view of each of them according to their identity or preferences. Finally, the personal screens preserve all well-established tabletop interaction techniques like touch and tangible interactions. We explore the challenges in building such a reach-through system through a proof-of-concept implementation and discuss the possibilities afforded by the system.",
        "session": "SESSION: Novel mobile displays and devices"
    },
    {
        "title": "What is a device bend gesture really good for?",
        "authors": "Teemu T. Ahmaniemi, Johan Kildal, Merja Haveri",
        "abstract": "Device deformation allows new types of gestures to be used in interaction. We identify that the gesture/use-case pairings proposed by interaction designers are often driven by factors relating improved tangibility, spatial directionality and strong metaphorical bonds. With this starting point, we argue that some of the designs may not make use of the full potential of deformation gestures as continuous, bipolar input techniques. In two user studies, we revisited the basics of deformation input by taking a new systematic look at the question of matching gestures with use cases. We observed comparable levels of UX when using bend input in different continuous bipolar interactions, irrespective of the choice of tangibility, directionality and metaphor. We concluded that device bend gestures use their full potential when used to control continuous bipolar parameters, and when quick reactions are needed. From our studies, we also identify relative strengths of absolute and relative mappings, and report a Fitts' law study for device bending input.",
        "session": "SESSION: Novel mobile displays and devices"
    },
    {
        "title": "SurfacePhone: a mobile projection device for single- and multiuser everywhere tabletop interaction",
        "authors": "Christian Winkler, Markus Löchtefeld, David Dobbelstein, Antonio Krüger, Enrico Rukzio",
        "abstract": "To maintain a mobile form factor, the screen real estate of a mobile device canIn this paper we present SurfacePhone; a novel configuration of a projector phone which aligns the projector to project onto a physical surface to allow tabletop-like interaction in a mobile setup. The projection is created behind the upright standing phone and is touch and gesture-enabled. Multiple projections can be merged to create shared spaces for multi-user collaboration. We investigate this new setup, starting with the concept that we evaluated with a concept prototype. Furthermore we present our technical prototype, a mobile phone case with integrated projector that allows for the aforementioned interaction. We discuss its technical requirements and evaluate the accuracy of interaction in a second user study. We conclude with lessons learned and design guidelines.",
        "session": "SESSION: Novel mobile displays and devices"
    },
    {
        "title": "Is once enough?: on the extent and content of replications in human-computer interaction",
        "authors": "Kasper Hornbæk, Søren S. Sander, Javier Andrés Bargas-Avila, Jakob Grue Simonsen",
        "abstract": "A replication is an attempt to confirm an earlier study's findings. It is often claimed that research in Human-Computer Interaction (HCI) contains too few replications. To investigate this claim we examined four publication outlets (891 papers) and found 3% attempting replication of an earlier result. The replications typically confirmed earlier findings, but treated replication as a confirm/not-confirm decision, rarely analyzing effect sizes or comparing in depth to the replicated paper. When asked, most authors agreed that their studies were replications, but rarely planned them as such. Many non-replication studies could have corroborated earlier work if they had analyzed data differently or used minimal effort to collect extra data. We discuss what these results mean to HCI, including how reporting of studies could be improved and how conferences/journals may change author instructions to get more replications.",
        "session": "SESSION: HCI paradigms: past, present and future"
    },
    {
        "title": "Binding the material and the discursive with a relational approach of affordances",
        "authors": "Huatong Sun, William F. Hart-Davidson",
        "abstract": "As Norman's vision of affordances developed twenty-six years ago is unable to address complex challenges faced by today's designers, we outline a view of affordances as discursive relations in HCI design. This argument is framed in the discussion of a larger trend of work beyond the HCI field, the scholarship on relational affordances from the fields of communication and organization studies. Through comparison and interrogation, we maintain a relational approach of affordances that bind the material and the discursive will help us to address design issues such as discursive power, cultural values, performed identities, mediated agency, and articulated voices in this increasingly globalized world and design culturally sensitive technology for transformation and emancipation. With a few cases, this paper deciphers the hidden power relationship of interaction design and suggests ways of we should design for social affordances.",
        "session": "SESSION: HCI paradigms: past, present and future"
    },
    {
        "title": "The turn to practice in HCI: towards a research agenda",
        "authors": "Kari Kuutti, Liam J. Bannon",
        "abstract": "This paper argues that a new paradigm for HCI research, which we label the 'practice' perspective, has been emerging in recent years. This stands in contrast to the prevailing mainstream HCI paradigm, which we term the 'interaction' perspective. The 'practice turn', as it has been dubbed in the social sciences, provides a conceptual frame to organize a variety of issues emerging in more recent HCI research. While this approach has been present in certain strands of HCI research for some time, it has not been articulated fully to date. In this paper, we provide a short account of the main tenets of this perspective, and then show how it can illuminate some of the recent debates within HCI. Our argument is one which does not seek to replace extant HCI theories, but rather to provide an alternative, complementary theoretical lens which may illuminate the present confusion among both researchers and practitioners as to the direction of HCI. The paper articulates a set of issues which can help direct HCI research programs, as well as highlighting the potential contribution of the HCI field to this practice approach itself, in terms of a more nuanced understanding of emerging practices.",
        "session": "SESSION: HCI paradigms: past, present and future"
    },
    {
        "title": "CHI 1994-2013: mapping two decades of intellectual progress through co-word analysis",
        "authors": "Yong Liu, Jorge Goncalves, Denzil Ferreira, Bei Xiao, Simo Hosio, Vassilis Kostakos",
        "abstract": "This study employs hierarchical cluster analysis, strategic diagrams and network analysis to map and visualize the intellectual landscape of the CHI conference on Human Computer Interaction through the use of co-word analysis. The study quantifies and describes the thematic evolution of the field based on a total of 3152 CHI articles and their associated 16035 keywords published between 1994 and 2013. The analysis is conducted for two time periods (1994-2003, 2004-2013) and a comparison between them highlights the underlying trends in our community. More significantly, this study identifies the evolution of major themes in the discipline, and highlights individual topics as popular, core, or backbone research topics within HCI.",
        "session": "SESSION: HCI paradigms: past, present and future"
    },
    {
        "title": "\"Narco\" emotions: affect and desensitization in social media during the mexican drug war",
        "authors": "Munmun De Choudhury, Andrés Monroy-Hernández, Gloria Mark",
        "abstract": "Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. Specifically, we examine three established affect measures: negative affect, activation, and dominance as observed on Twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War. During a two year period (Aug 2010 - Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: aspects known to be psychological markers of desensitization. We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.",
        "session": "SESSION: PolitiCHI"
    },
    {
        "title": "A pool of dreams: facebook, politics and the emergence of a social movement",
        "authors": "Clara Crivellaro, Rob Comber, John Bowers, Peter C. Wright, Patrick Olivier",
        "abstract": "In this paper we present insights from an empirical analysis of data from an emergent social movement primarily located on a Facebook page to contribute understanding of the conduct of everyday politics in social media and through this open up research agendas for HCI. The analysis focuses on how interactions and contributions facilitated the emergence of a collective with political will. We lay out an exploration of the intrinsic relationship between cultural memories, cultural expression and everyday politics and show how diverging voices co-constructed dynamic collectives capable of political action. We look at how interactions through the Facebook page challenge traditional ways for conceiving politics and the political. We outline possible research agendas in the field of everyday politics, which are sensitive to the everyday acts of resistance enclosed in the ordinary.",
        "session": "SESSION: PolitiCHI"
    },
    {
        "title": "Shared values/conflicting logics: working around e-government systems",
        "authors": "Amy Voida, Lynn Dombrowski, Gillian R. Hayes, Melissa Mazmanian",
        "abstract": "In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.",
        "session": "SESSION: PolitiCHI"
    },
    {
        "title": "Rethinking plan A for sustainable HCI",
        "authors": "Bran Knowles, Lynne Blair, Paul Coulton, Mark Lochrie",
        "abstract": "This paper challenges the sustainable HCI community to move away from a focus on demand and instead address climate change as a supply problem. We identify a new route to impact, namely addressing the psychological barriers that interfere with political mobilization toward limiting the use of fossil fuels. Five barriers are explored as a means of re-focusing research objectives for the community.",
        "session": "SESSION: PolitiCHI"
    },
    {
        "title": "HaptiMoto: turn-by-turn haptic route guidance interface for motorcyclists",
        "authors": "Manoj Prasad, Paul Taele, Daniel Goldberg, Tracy A. Hammond",
        "abstract": "A national study by the Australian Transport Safety Bureau revealed that motorcyclist deaths were nearly thirty times more prevalent than that of drivers of other vehicles. These fatalities represent approximately 5% of all highway deaths each year, yet motorcycles account for only 2% of all registered vehicles in the USA. Motorcyclists are highly exposed on the road, so maintaining situational awareness at all times is crucial. Route guidance systems enable users to efficiently navigate between locations using dynamic visual maps and audio directions, and have been well tested with motorists, but remain unsafe for use by motorcyclists. Audio/visual routing systems decrease motorcyclists' situational awareness and vehicle control, and thus elevate chances of an accident. To enable motorcyclists to take advantage of route guidance while maintaining situational awareness, we created HaptiMoto, a wearable haptic route guidance system. HaptiMoto uses tactile signals to encode the distance and direction of approaching turns, thus avoiding interference with audio/visual awareness. Our evaluations demonstrate that HaptiMoto is both intuitive and a safer alternative for motorcyclists compared to existing solutions.",
        "session": "SESSION: Location-based services and navigation"
    },
    {
        "title": "Experimental evaluation of user interfaces for visual indoor navigation",
        "authors": "Andreas Möller, Matthias Kranz, Stefan Diewald, Luis Roalter, Robert Huitl, Tobias Stockinger, Marion Koelle, Patrick A. Lindemann",
        "abstract": "Mobile location recognition by capturing images of the environment (visual localization) is a promising technique for indoor navigation in arbitrary surroundings. However, it has barely been investigated so far how the user interface (UI) can cope with the challenges of the vision-based localization technique, such as varying quality of the query images. We implemented a novel UI for visual localization, consisting of Virtual Reality (VR) and Augmented Reality (AR) views that actively communicate and ensure localization accuracy. If necessary, the system encourages the user to point the smartphone at distinctive regions to improve localization quality. We evaluated the UI in a experimental navigation task with a prototype, informed by initial evaluation results using design mockups. We found that VR can contribute to efficient and effective indoor navigation even at unreliable location and orientation accuracy. We discuss identified challenges and share lessons learned as recommendations for future work.",
        "session": "SESSION: Location-based services and navigation"
    },
    {
        "title": "Digitally driven: how location based services impact the work practices of London bus drivers",
        "authors": "Gary Pritchard, John Vines, Pam Briggs, Lisa Thomas, Patrick Olivier",
        "abstract": "This paper examines how an occupational group has adapted to the demands of working with a Location Based Service (LBS). Instead of following a rigid timetable, London's bus drivers are now required to maintain an equal distance between the bus in front and the one behind. Our qualitative study employs ethnographic fieldwork and in-depth semi-structured interviews to elicit drivers' perspectives of the new system and show how it has modified their driving and general work conditions. We explore how passengers influence the movement of the bus and how the technology frames bus drivers' relationships to their managers and commuters. This work contributes to our understanding of the impact of LBS in the workplace and shows how technological imperatives can be established that cause unanticipated consequences and gradually undermine human relationships.",
        "session": "SESSION: Location-based services and navigation"
    },
    {
        "title": "Smart flashlight: map navigation using a bike-mounted projector",
        "authors": "Alexandru Dancu, Zlatko Franjcic, Morten Fjeld",
        "abstract": "While mobile phones affect our behavior and tend to separate us from our physical environment, this very environment could instead become a responsive part of the information domain. For navigation using a map while cycling in an urban environment, we studied two alternative solutions: smartphone display and projection on the road. This paper firstly demonstrates by proof-of-concept a GPS-based map navigation using a bike-mounted projector. Secondly, it implements a prototype using both a projector and a smartphone mounted on a bike, comparing them for use in a navigation system for nighttime cycling. Thirdly, it examines how visuo-spatial factors influence navigation. We believe that our findings will be useful for designing navigation systems for bikes and even for cars, helping cyclists and drivers be more attentive to their environment while navigating, and to provide useful information while moving.",
        "session": "SESSION: Location-based services and navigation"
    },
    {
        "title": "Partially intelligent automobiles and driving experience at the moment of system transition",
        "authors": "Key Jung Lee, Yeon Kyoung Joo, Clifford Nass",
        "abstract": "The current study (N = 49) took a user-centered approach to explore how level of automation (pedal automated, wheel automated or fully automated driving) and the interface modality (switching automation on or off via touch or voice control) in automated vehicles influence drivers' perceived experience and performance. The results found that full or wheel automation in vehicles was perceived significantly more intelligent than pedal automation. Furthermore, drivers in the pedal automation condition reported greater nervousness when using the touch interface than the voice interface. This tendency was not found among drivers in the full and wheel automation conditions. Drivers who used the voice interface to control automated driving had fewer driving mistakes than those who operated the touch interface. Our findings have important psychological and practical implications for designing a user interface for automated vehicles.",
        "session": "SESSION: Location-based services and navigation"
    },
    {
        "title": "Slide to X: unlocking the potential of smartphone unlocking",
        "authors": "Khai N. Truong, Thariq Shihipar, Daniel J. Wigdor",
        "abstract": "Unlock gestures are performed by billions of users across the world multiple times a day. Beyond preventing accidental input on mobile devices, they currently serve little to no other purpose. In this paper, we explore how replacing the regular unlock screen with one that asks the user to perform a simple, optional task, can benefit a wealth of application domains, including data collection, personal-health metrics collection, and human intelligence tasks. We evaluate this concept, which we refer to as Slide to X. Further, we show that people are willing to perform microtasks presented through this interface and continue to do so throughout the day while they visit different locations as part of their daily routines. We then discuss how to implement this concept and demonstrate three applications.",
        "session": "SESSION: Crowdsourcing"
    },
    {
        "title": "Twitch crowdsourcing: crowd contributions in short bursts of time",
        "authors": "Rajan Vaish, Keith Wyngarden, Jingshu Chen, Brandon Cheung, Michael S. Bernstein",
        "abstract": "To lower the threshold to participation in crowdsourcing, we present twitch crowdsourcing: crowdsourcing via quick contributions that can be completed in one or two seconds. We introduce Twitch, a mobile phone application that asks users to make a micro-contribution each time they unlock their phone. Twitch takes advantage of the common habit of turning to the mobile phone in spare moments. Twitch crowdsourcing activities span goals such as authoring a census of local human activity, rating stock photos, and extracting structured data from Wikipedia pages. We report a field deployment of Twitch where 82 users made 11,240 crowdsourcing contributions as they used their phone in the course of everyday life. The median Twitch activity took just 1.6 seconds, incurring no statistically distinguishable costs to unlock speed or cognitive load compared to a standard slide-to-unlock interface.",
        "session": "SESSION: Crowdsourcing"
    },
    {
        "title": "Crowdsourcing the future: predictions made with a social network",
        "authors": "Clifton Forlines, Sarah Miller, Leslie Guelcher, Robert Bruzzi",
        "abstract": "Researchers have long known that aggregate estimations built from the collected opinions of a large group of people often outperform the estimations of individual experts. This phenomenon is generally described as the \"Wisdom of Crowds\". This approach has shown promise with respect to the task of accurately forecasting future events. Previous research has demonstrated the value of utilizing meta-forecasts (forecasts about what others in the group will predict) when aggregating group predictions. In this paper, we describe an extension to meta-forecasting and demonstrate the value of modeling the familiarity among a population's members (its social network) and applying this model to forecast aggregation. A pair of studies demonstrates the value of taking this model into account, and the described technique produces aggregate forecasts for future events that are significantly better than the standard Wisdom of Crowds approach as well as previous meta-forecasting techniques.",
        "session": "SESSION: Crowdsourcing"
    },
    {
        "title": "Cognitively inspired task design to improve user performance on crowdsourcing platforms",
        "authors": "Harini Alagarai Sampath, Rajeev Rajeshuni, Bipin Indurkhya",
        "abstract": "Recent research in human computation has focused on improving the quality of work done by crowd workers on crowdsourcing platforms. Multiple approaches have been adopted like filtering crowd workers through qualification tasks, and aggregating responses from multiple crowd workers to obtain consensus. We investigate here how improving the presentation of the task itself by using cognitively inspired features affects the performance of crowd workers. We illustrate this with a case-study for the task of extracting text from scanned images. We generated six task-presentation designs by modifying two parameters - visual saliency of the target fields and working memory requirements - and conducted experiments on Amazon Mechanical Turk (AMT) and with an eye-tracker in the lab setting. Our results identify which task-design parameters (e.g. highlighting target fields) result in improved performance, and which ones do not (e.g. reducing the number of distractors). In conclusion, we claim that the use of cognitively inspired features for task design is a powerful technique for maximizing the performance of crowd workers.",
        "session": "SESSION: Crowdsourcing"
    },
    {
        "title": "Searching for myself: motivations and strategies for self-search",
        "authors": "Catherine C. Marshall, Siân E. Lindley",
        "abstract": "We present findings from a qualitative study of self-search, also known as ego or vanity search. In the context of a broader study about personal online content, participants were asked to search for themselves using their own computers and the browsers and queries they would normally adopt. Our analysis highlights five motivations for self-search: as a form of identity management; to discover reactions to and reuse of user-generated media; to re-find personal content; as a form of entertainment; and to reveal lost or forgotten content. Strategies vary according to motivation, and may differ markedly from typical information-seeking, with users looking deep into the results and using image search to identify content about themselves. We argue that two dimensions underpin ways of improving self-search: controllability and expectedness, and discuss what these dimensions imply for design.",
        "session": "SESSION: Desktop search and history"
    },
    {
        "title": "Finder highlights: field evaluation and design of an augmented file browser",
        "authors": "Stephen Fitchett, Andy Cockburn, Carl Gutwin",
        "abstract": "Navigating to files through a hierarchy is often a slow, laborious, and repetitive task. Recent lab studies showed that file browser interface augmentations, such as Icon Highlights and Search Directed Navigation, have the potential to reduce file retrieval times. However, for this potential to be realised in actual systems, further study is necessary to address two important issues. First, there are important design and implementation challenges in advancing the research prototypes previously evaluated into complete interactive systems that can be used for real work. Second, it is unknown how real users would employ these systems while engaged in actual work; would the potential performance improvements suggested by the earlier lab studies be realised? We therefore describe the design, implementation, and longitudinal field study evaluation of Finder Highlights, a file browser plugin for the OS X 'Finder' that adds support for Icon Highlights and Search Directed Navigation. Study results confirm that the augmentations are effective in reducing real-world file retrieval times, with retrieval times 13% faster when using Finder Highlights compared to the standard tool (10.6 s versus 12.2 s), while also emphasising important differences between lab and field studies. In summary, the paper strongly suggests that large-scale deployment of interface augmentations to file browsers, particularly Icon Highlights, will have a marked effect in improving users' real-world file retrieval.",
        "session": "SESSION: Desktop search and history"
    },
    {
        "title": "PIM and personality: what do our personal file systems say about us?",
        "authors": "Charlotte Massey, Sean TenBrook, Chaconne Tatum, Steve Whittaker",
        "abstract": "Individual differences are prevalent in personal information management (PIM). There is large variation between individuals in how they structure and retrieve information from personal archives. These differences make it hard to develop general PIM tools. However we know little about the origins of these differences. We present two studies evaluating whether differences arise from personality traits, by exploring whether different personalities structure personal archives differently. The first exploratory study asks participants to identify PIM cues that signal personality traits. While the aim was to identify cues, these cues also proved surprisingly accurate indicators of personality. In a second study, to evaluate these cues, we directly measure relations between structure and traits. We demonstrate that Conscientiousness predicts file organization, particularly PC users' desktops. Neurotic people may also keep more desktop files. One implication is that systems might be customized for different personalities. We also advance personality theory, showing that personal digital artifacts signal personality.",
        "session": "SESSION: Desktop search and history"
    },
    {
        "title": "Show me the invisible: visualizing hidden content",
        "authors": "Thomas Geymayer, Markus Steinberger, Alexander Lex, Marc Streit, Dieter Schmalstieg",
        "abstract": "Content on computer screens is often inaccessible to users because it is hidden, e.g., occluded by other windows, outside the viewport, or overlooked. In search tasks, the efficient retrieval of sought content is important. Current software, however, only provides limited support to visualize hidden occurrences and rarely supports search synchronization crossing application boundaries. To remedy this situation, we introduce two novel visualization methods to guide users to hidden content. Our first method generates awareness for occluded or out-of-viewport content using see-through visualization. For content that is either outside the screen's viewport or for data sources not opened at all, our second method shows off-screen indicators and an on-demand smart preview. To reduce the chances of overlooking content, we use visual links, i.e., visible edges, to connect the visible content or the visible representations of the hidden content. We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.",
        "session": "SESSION: Desktop search and history"
    },
    {
        "title": "\"Maybe it was a joke\": emotion detection in text-only communication by non-native english speakers",
        "authors": "Ari MJ Hautasaari, Naomi Yamashita, Ge Gao",
        "abstract": "Previous studies have shown that people can effectively detect emotions in text-only messages written in their native languages. But is this the same for non-native speakers' In this paper, we conduct an experiment where native English speakers (NS) and Japanese non-native English speakers (NNS) rate the emotional valence in text-only messages written by native English-speaking authors. They also annotate all emotional cues (words, symbols and emoticons) that affected their rating. Accuracy of NS and NNS ratings and annotations are calculated by comparing their average correlations with author ratings and annotations used as a gold standard. Our results conclude that NNS are significantly less accurate at detecting the emotional valence of messages, especially when the messages include highly negative words. Although NNS are as accurate as NS at detecting emotional cues, they are not able to make use of symbols (exclamation marks) and emoticons to detect the emotional valence of text-only messages.",
        "session": "SESSION: Lost and found in translation"
    },
    {
        "title": "TransPhoner: automated mnemonic keyword generation",
        "authors": "Manolis Savva, Angel X. Chang, Christopher D. Manning, Pat Hanrahan",
        "abstract": "We present TransPhoner: a system that generates keywords for a variety of scenarios including vocabulary learning, phonetic transliteration, and creative word plays. We select effective keywords by considering phonetic, orthographic and semantic word similarity, and word concept imageability. We show that keywords provided by TransPhoner improve learner performance in an online vocabulary learning study, with the improvement being more pronounced for harder words. Participants rated TransPhoner keywords as more helpful than a random keyword baseline, and almost as helpful as manually selected keywords. Comments also indicated higher engagement in the learning task, and more desire to continue learning. We demonstrate additional applications to tasks such as pure phonetic transliteration, generation of mnemonics for complex vocabulary, and topic-based transformation of song lyrics.",
        "session": "SESSION: Lost and found in translation"
    },
    {
        "title": "AudioCanvas: internet-free interactive audio photos",
        "authors": "Simon Robinson, Jennifer S. Pearson, Matt Jones",
        "abstract": "In this paper we present a novel interaction technique that helps to make textual information more accessible to those with low or no textual literacy skills. AudioCanvas allows cameraphone users to interact directly with their own photos of printed media to receive audio feedback or narration. The use of a remote telephone-based service also allows our design to be used over a standard phone line, removing the need for data connections, which can be problematic in developing regions. We show the value of the technique via user evaluations in both a rural Indian village and a South African township.",
        "session": "SESSION: Lost and found in translation"
    },
    {
        "title": "The impact of visual contextualization on UI localization",
        "authors": "Luis A. Leiva, Vicent Alabau",
        "abstract": "Translating the text in an interface is a challenging task. Besides the jargon and technical terms, many of the strings are often very short, such as those shown in buttons and pull-down menus. Then, as a result of the lack of visual context in the traditional localization process, an important ambiguity problem arises. We study three approaches to solve this problem: using plain gettext (baseline condition), using gettext plus being able to operate the UI, and translating the UI in-place. We found that translators are substantially faster with plain gettext but commit a significantly higher number of errors in comparison to the other approaches. Unexpectedly, the mixed condition was slower and more error-prone than in-place translation. The latter was found to be comparable to plain gettext in terms of time, although some strings passed unnoticed as the UI was operated. Based on our results, we arrive at a set of recommendations to augment localization tools to improve translator's productivity.",
        "session": "SESSION: Lost and found in translation"
    },
    {
        "title": "Improving machine translation by showing two outputs",
        "authors": "Bin Xu, Ge Gao, Susan R. Fussell, Dan Cosley",
        "abstract": "We propose to improve real-time communication between people who do not share a common language by foregrounding potential problems in machine translation. We developed a prototype chat tool that displays two parallel translations of each chat turn, with the thought that comparing the translations might both highlight problems and provide resources for resolving them. We conducted a user study to investigate how people use and like such an interface compared to a standard one-translation interface. On balance, users preferred two translations to one, using them to both notice differences and infer meaning from uncertain translations, with no increase in workload. This suggests that this interface may help improve cross-lingual communication in practical applications and lays the groundwork for a larger design space around systems that highlight possible errors to support communication.",
        "session": "SESSION: Lost and found in translation"
    },
    {
        "title": "Diversity for design: a framework for involving neurodiverse children in the technology design process",
        "authors": "Laura Benton, Asimina Vasalou, Rilla Khaled, Hilary Johnson, Daniel Gooch",
        "abstract": "The neurodiversity movement seeks to positively reframe certain neurological conditions, such as autism spectrum disorders (ASD) and dyslexia, by concentrating on their strengths. In recent years, neurodiverse children have increasingly been involved in the technology design process, but the design approaches adopted have focused mostly on overcoming difficulties of working with these children, leaving their strengths untapped. We present a new participatory design (PD) framework, Diversity for Design (D4D), which provides guidance for technology designers working with neurodiverse children in establishing PD methods that capitalize on children's strengths and also support potential difficulties. We present two case studies of use of the D4D framework, involving children with ASD and dyslexia, showing how it informed the development and refinement of PD methods tailored to these populations. In addition, we show how to apply the D4D framework to other neurodiverse populations.",
        "session": "SESSION: Participatory design"
    },
    {
        "title": "Canine-centered interface design: supporting the work of diabetes alert dogs",
        "authors": "Charlotte L. Robinson, Clara Mancini, Janet van der Linden, Claire Guest, Robert Harris",
        "abstract": "Many people with Diabetes live with the continuous threat of hypoglycemic attacks and the danger of going into coma. Diabetes Alert Dogs are trained to detect the onset of an attack before the condition of the human handler they are paired with deteriorates, giving them time to take action. We investigated requirements for designing an alarm system allowing dogs to remotely call for help when their human falls unconscious before being able to react to an alert. Through a multispecies ethnographic approach we focus on the requirements for a physical canine user interface, involving dogs, their handlers and specialist dog trainers in the design process. We discuss tensions between the requirements for canine and the human users, argue the need for increased sensitivity towards the needs of individual dogs that goes beyond breed specific physical characteristics, and reflect on how we can move from designing for dogs to designing with dogs.",
        "session": "SESSION: Participatory design"
    },
    {
        "title": "Co-constructing child personas for health-promoting services with vulnerable children",
        "authors": "Pontus Wärnestål, Petra Svedberg, Jens Nygren",
        "abstract": "The availability of health-promoting resources for young children diagnosed with cancer who are transitioning from intensive care to everyday life is limited. In the context of designing digital peer support services for children who are considered vulnerable due to clinical and age-related aspects, there are several challenges that put critical requirements on a user-centered design process. This paper reports on a new method for co-constructing child-personas that are tailored for developing health-promoting services where empirical data is restricted due to practical and ethical reasons. In particular, we are proposing to focus children design workshop sessions on salutogenesis, and complement this with a pathogenic perspective by interviewing healthcare professionals and parents. We also introduce the use of proxy personas, and redemption scenarios in the form of comicboards, both collaboratively constructed by children and designers through storytelling. By applying four progressive steps of data collection and analysis we arrive at authentic child-personas that can be used to design and develop health-promoting services for children in vulnerable life stages.",
        "session": "SESSION: Participatory design"
    },
    {
        "title": "Balancing design tensions: iterative display design to support ad hoc and multidisciplinary medical teamwork",
        "authors": "Diana S. Kusunoki, Aleksandra Sarcevic, Nadir Weibel, Ivan Marsic, Zhan Zhang, Genevieve Tuveson, Randall S. Burd",
        "abstract": "In this paper, we describe how we developed an information display prototype for trauma resuscitation teams based on design ideas and feedback from clinicians. Our approach is grounded in participatory design, emphasizing the importance of gaining long-term commitment from clinicians in system development. Through a series of participatory design workshops, heuristic evaluation, and simulated resuscitation sessions, we identified the main information features to include on our display. Our results focus on how we balanced the design tensions that emerged when addressing the ad hoc, hierarchical, and multidisciplinary nature of trauma teamwork. We discuss the implications of balancing role-based differences for each information feature, as well as two major design tensions: process-based vs. state-based designs and role-based vs. team-based displays.",
        "session": "SESSION: Participatory design"
    },
    {
        "title": "Error related negativity in observing interactive tasks",
        "authors": "Chi Thanh Vi, Izdihar Jamil, David Coyle, Sriram Subramanian",
        "abstract": "Error Related Negativity is triggered when a user either makes a mistake or the application behaves differently from their expectation. It can also appear while observing another user making a mistake. This paper investigates ERN in collaborative settings where observing another user (the executer) perform a task is typical and then explores its applicability to HCI. We first show that ERN can be detected on signals captured by commodity EEG headsets like an Emotiv headset when observing another person perform a typical multiple-choice reaction time task. We then investigate the anticipation effects by detecting ERN in the time interval when an executer is reaching towards an answer. We show that we can detect this signal with both a clinical EEG device and with an Emotiv headset. Our results show that online single trial detection is possible using both headsets during tasks that are typical of collaborative interactive applications. However there is a trade-off between the detection speed and the quality/prices of the headsets. Based on the results, we discuss and present several HCI scenarios for use of ERN in observing tasks and collaborative settings.",
        "session": "SESSION: Brain computer interfaces"
    },
    {
        "title": "Dynamic difficulty using brain metrics of workload",
        "authors": "Daniel Afergan, Evan M. Peck, Erin T. Solovey, Andrew Jenkins, Samuel W. Hincks, Eli T. Brown, Remco Chang, Robert J.K. Jacob",
        "abstract": "Dynamic difficulty adjustments can be used in human-computer systems in order to improve user engagement and performance. In this paper, we use functional near-infrared spectroscopy (fNIRS) to obtain passive brain sensing data and detect extended periods of boredom or overload. From these physiological signals, we can adapt a simulation in order to optimize workload in real-time, which allows the system to better fit the task to the user from moment to moment. To demonstrate this idea, we ran a laboratory study in which participants performed path planning for multiple unmanned aerial vehicles (UAVs) in a simulation. Based on their state, we varied the difficulty of the task by adding or removing UAVs and found that we were able to decrease error by 35% over a baseline condition. Our results show that we can use fNIRS brain sensing to detect task difficulty in real-time and construct an interface that improves user performance through dynamic difficulty adjustment.",
        "session": "SESSION: Brain computer interfaces"
    },
    {
        "title": "Measuring the effect of think aloud protocols on workload using fNIRS",
        "authors": "Matthew F. Pike, Horia A. Maior, Martin Porcheron, Sarah C. Sharples, Max L. Wilson",
        "abstract": "The Think Aloud Protocol (TAP) is a verbalisation technique widely employed in HCI user studies to give insight into user experience, yet little work has explored the impact that TAPs have on participants during user studies. This paper utilises a brain sensing technique, fNIRS, to observe the effect that TAPs have on participants. Functional Near-Infrared Spectroscopy (fNIRS) is a brain sensing technology that offers the potential to provide continuous, detailed insight into brain activity, enabling an objective view of cognitive processes during complex tasks. Participants were asked to perform a mathematical task under 4 conditions: nonsense verbalisations, passive concurrent think aloud protocol, invasive concurrent think aloud protocol, and a baseline of silence. Subjective ratings and performance measures were collected during the study. Our results provide a novel view into the effect that different forms of verbalisation have on workload during tasks. Further, the results provide a means for estimating the effect of spoken artefacts when measuring workload, which is another step towards our goal of proactively involving fNIRS analysis in ecologically valid user studies.",
        "session": "SESSION: Brain computer interfaces"
    },
    {
        "title": "An EEG-based approach for evaluating audio notifications under ambient sounds",
        "authors": "Yi-Chieh Lee, Wen-Chieh Lin, Jung-Tai King, Li-Wei Ko, Yu-Ting Huang, Fu-Yin Cherng",
        "abstract": "Audio notifications are an important means of prompting users of electronic products. Although useful in most environments, audio notifications are ineffective in certain situations, especially against particular auditory backgrounds or when the user is distracted. Several studies have used behavioral performance to evaluate audio notifications, but these studies failed to achieve consistent results due to factors including user subjectivity and environmental differences; thus, a new method and more objective indicators are necessary. In this study, we propose an approach based on electroencephalography (EEG) to evaluate audio notifications by measuring users' auditory perceptual responses (mismatch negativity) and attention shifting (P3a). We demonstrate our approach by applying it to the usability testing of audio notifications in realistic scenarios, such as users performing a major task amid ambient noises. Our results open a new perspective for evaluating the design of the audio notifications.",
        "session": "SESSION: Brain computer interfaces"
    },
    {
        "title": "faBrickation: fast 3D printing of functional objects by integrating construction kit building blocks",
        "authors": "Stefanie Mueller, Tobias Mohr, Kerstin Guenther, Johannes Frohnhofen, Patrick Baudisch",
        "abstract": "We present a new approach to rapid prototyping of functional objects, such as the body of a head-mounted display. The key idea is to save 3D printing time by automatically substituting sub-volumes with standard building blocks'in our case Lego bricks. When making the body for a head-mounted display, for example, getting the optical path right is paramount. Users thus mark the lens mounts as \"high-resolution\" to indicate that these should later be 3D printed. faBrickator then 3D prints these parts. It also generates instructions that show users how to create everything else from Lego bricks. If users iterate on the design later, faBrickator offers even greater benefit as it allows re-printing only the elements that changed. We validated our system at the example of three 3D models of functional objects. On average, our system fabricates objects 2.44 times faster than traditional 3D printing while requiring only 14 minutes of manual assembly.",
        "session": "SESSION: 3D printing and fabrication"
    },
    {
        "title": "Understanding physical activity through 3D printed material artifacts",
        "authors": "Rohit Ashok Khot, Larissa Hjorth, Florian 'Floyd' Mueller",
        "abstract": "In this paper, we advocate a novel approach of representing physical activity in the form of material artifacts. By designing such material representations, we aim to understand what these artifacts might offer in terms of reflecting upon physical activity. For example, what types of affect do material artifacts, representing ones' physical activity create for the user' In order to advance this understanding, we designed a system called SweatAtoms that transforms the physical activity data based on heart rate into 3D printed material artifacts. We conducted an 'in the wild study' by deploying our system in six households where participants were experiencing five different material representations of their physical activity for a period of two weeks each. We found that the material artifacts made participants more conscious about their involvement in physical activity and illustrated different levels of engagement with the artifacts. Along with reporting the gained insights from the deployments, we offer reflections on designing material representations for physical activity. We hope that our work will inspire designers to consider new possibilities afforded by digital fabrication to support user's experience with physical activity by utilizing interactive technologies at our disposal.",
        "session": "SESSION: 3D printing and fabrication"
    },
    {
        "title": "Supporting the design and fabrication of physical visualizations",
        "authors": "Saiganesh Swaminathan, Conglei Shi, Yvonne Jansen, Pierre Dragicevic, Lora A. Oehlberg, Jean-Daniel Fekete",
        "abstract": "Physical visualizations come in increasingly diverse forms, and are used in domains including art and entertainment, business analytics, and scientific research. However, creating physical visualizations requires laborious craftsmanship and demands expertise in both data visualization and digital fabrication. We present three case studies that illustrate limitations of current visualization fabrication workflows. We then present MakerVis, a prototype tool that integrates the entire process of creating physical visualizations, from data filtering to physical fabrication. Design sessions with three end users demonstrate how tools such as MakerVis can dramatically lower the barriers to producing physical visualizations. Observations and interviews from these sessions highlighted future research areas, including customization support, using material properties to represent data variables, and allowing the reuse of physical data objects in new visualizations.",
        "session": "SESSION: 3D printing and fabrication"
    },
    {
        "title": "MixFab: a mixed-reality environment for personal fabrication",
        "authors": "Christian Weichel, Manfred Lau, David Kim, Nicolas Villar, Hans W. Gellersen",
        "abstract": "Personal fabrication machines, such as 3D printers and laser cutters, are becoming increasingly ubiquitous. However, designing objects for fabrication still requires 3D modeling skills, thereby rendering such technologies inaccessible to a wide user-group. In this paper, we introduce MixFab, a mixed-reality environment for personal fabrication that lowers the barrier for users to engage in personal fabrication. Users design objects in an immersive augmented reality environment, interact with virtual objects in a direct gestural manner and can introduce existing physical objects effortlessly into their designs. We describe the design and implementation of MixFab, a user-defined gesture study that informed this design, show artifacts designed with the system and describe a user study evaluating the system's prototype.",
        "session": "SESSION: 3D printing and fabrication"
    },
    {
        "title": "Model of visual search and selection time in linear menus",
        "authors": "Gilles Bailly, Antti Oulasvirta, Duncan P. Brumby, Andrew Howes",
        "abstract": "This paper presents a novel mathematical model for visual search and selection time in linear menus. Assuming two visual search strategies, serial and directed, and a pointing sub-task, it captures the change of performance with five fac- tors: 1) menu length, 2) menu organization, 3) target position, 4) absence/presence of target, and 5) practice. The novel aspect is that the model is expressed as probability density distribution of gaze, which allows for deriving total selection time. We present novel data that replicates and extends the Nielsen menu selection paradigm and uses eye-tracking and mouse tracking to confirm model predictions. The same parametrization yielded a high fit to both menu selection time and gaze distributions. The model has the potential to improve menu designs by helping designers identify more effective solutions without conducting empirical studies.",
        "session": "SESSION: Modeling users and interaction"
    },
    {
        "title": "Towards accurate and practical predictive models of active-vision-based visual search",
        "authors": "David E. Kieras, Anthony J. Hornof",
        "abstract": "Being able to predict the performance of interface designs using models of human cognition and performance is a long-standing goal of HCI research. This paper presents recent advances in cognitive modeling which permit increasingly realistic and accurate predictions for visual human-computer interaction tasks such as icon search by incorporating an \"active vision\" approach which emphasizes eye movements to visual features based on the availability of features in relationship to the point of gaze. A high fidelity model of a classic visual search task demonstrates the value of incorporating visual acuity functions into models of visual performance. The features captured by the high-fidelity model are then used to formulate a model simple enough for practical use, which is then implemented in an easy-to-use GLEAN modeling tool. Easy-to-use predictive models for complex visual search are thus feasible and should be further developed.",
        "session": "SESSION: Modeling users and interaction"
    },
    {
        "title": "Understanding multitasking through parallelized strategy exploration and individualized cognitive modeling",
        "authors": "Yunfeng Zhang, Anthony J. Hornof",
        "abstract": "Human multitasking often involves complex task interactions and subtle tradeoffs which might be best understood through detailed computational cognitive modeling, yet traditional cognitive modeling approaches may not explore a sufficient range of task strategies to reveal the true complexity of multitasking behavior. This study proposes a systematic approach for exploring a large number of strategies using a computer-cluster-based parallelized modeling system. The paper demonstrates the efficacy of the approach for investigating and revealing the effects of different microstrategies on human performance, both within and across individuals, for a time-pressured multimodal dual task. The modeling results suggest that multitasking performance is not simply a matter of interleaving cognitive and sensorimotor processing but is instead heavily influenced by the selection of subtask microstrategies.",
        "session": "SESSION: Modeling users and interaction"
    },
    {
        "title": "How does knowing what you are looking for change visual search behavior?",
        "authors": "Duncan P. Brumby, Anna L. Cox, Jacqueline Chung, Byron Fernandes",
        "abstract": "When searching a display, users sometimes know what the target is but sometimes do not. It has generally been assumed that for this latter case people must engage in a deeper semantic evaluation of items during the search process. This idea is central to Information Foraging theory. But do people actually spend longer assessing items when engaged in a semantically demanding search task' We investigate this by having participants locate target items in 16-item menus. Participants were either told exactly what to look for (known-item search) or they were told the category that the target belonged to (semantic search). Participants were faster and more accurate at known-item searches. Eye-movement data show that this was because participants were more likely to skip over items when performing known-item searches. Contrary to expectation, we found limited empirical evidence to support the idea that deeper semantic evaluations of items lead to longer gaze durations (this occurred only when items were arranged very close together). This finding is important because it reveals how people adopt different eye gaze strategies depending on the kind of search activity they are engaged in.",
        "session": "SESSION: Modeling users and interaction"
    },
    {
        "title": "Automated nonlinear regression modeling for HCI",
        "authors": "Antti Oulasvirta",
        "abstract": "Predictive models in HCI, such as models of user performance, are often expressed as multivariate nonlinear regressions. This approach has been preferred, because it is compact and allows scrutiny. However, existing modeling tools in HCI, along with the common statistical packages, are limited to predefined nonlinear models or support linear models only. To assist researchers in the task of identifying novel nonlinear models, we propose a stochastic local search method that constructs equations iteratively. Instead of predefining a model equation, the researcher defines constraints that guide the search process. Comparison of outputs to published baselines in HCI shows improvements in model fit in seven out of 11 cases. We present a few ways in which the method can help HCI researchers explore modeling problems. We conclude that the approach is particularly suitable for complex datasets that have many predictor variables.",
        "session": "SESSION: Modeling users and interaction"
    },
    {
        "title": "Understanding digital and material social communications for older adults",
        "authors": "Alexis Hope, Ted Schwaba, Anne Marie Piper",
        "abstract": "Online technologies are promising for helping older adults maintain social connectedness, particularly with younger people, yet many older adults resist or participate minimally in the mainstream technologies used by younger members of their social network. We present results from an interview study involving 22 older adults (age 71-92) to understand communication preferences and values related to social media. Seniors articulate many concerns with online social media, including the time required for legitimate participation, the loss of deeper communication, content irrelevance, and privacy. Additionally, older adults engage in social practices that could be supported by online social technologies, but they rarely use such tools. The theme of material social communications emerges from our data, and we examine this in context of online social media. We conclude with design considerations for the development of social media for older adults, and as part of this we describe the notion of bridging technologies as a framework for intergenerational communication design.",
        "session": "SESSION: Engaging older adults through technology"
    },
    {
        "title": "Never too old: engaging retired people inventing the future with MaKey MaKey",
        "authors": "Yvonne Rogers, Jeni Paay, Margot Brereton, Kate L. Vaisutis, Gary Marsden, Frank Vetere",
        "abstract": "Within HCI, aging is often viewed in terms of designing assistive technologies to improve the lives of older people, such as those who are suffering from frailty or memory loss. Our research adopts a very different approach, reframing the relationship in terms of wisdom, creativity and invention. We ran a series of workshops where groups of retirees, aged between early 60s and late 80s, used the MaKey MaKey inventor's toolkit. We asked them to think about inventing the future and suggest ideas for new technologies. Our findings showed that they not only rose to the challenge but also mastered the technology, collaborated intensely together while using it and freely and at length discussed their own, their family's and others' relationship with technology. We discuss the value of empowering people in this way and consider what else could be invented to enable more people to be involved in the design and use of creative technologies.",
        "session": "SESSION: Engaging older adults through technology"
    },
    {
        "title": "What's on your mind?: investigating recommendations for inclusive social networking and older adults",
        "authors": "Chris Norval, John L. Arnott, Vicki L. Hanson",
        "abstract": "Social networking sites (SNSs) are becoming increasingly popular as a method for social interaction. While research has reported benefits associated with components of SNS usage, a digital divide has emerged between younger and older users. SNSs can be useful for communicating with family members and helping one feel digitally included; however, there are a wide range of reasons why many older adults choose not to use this kind of technology. We present a series of user studies investigating the barriers and challenges that SNSs can present to older users. These user studies led to the derivation of user recommendations to mitigate these barriers. The recommendations were then evaluated within a comparative evaluation which involved 25 older adults completing tasks on two interface versions of a simulation SNS. We present the recommendations and the methods of their creation and evaluation. Implications for developers of SNSs are discussed.",
        "session": "SESSION: Engaging older adults through technology"
    },
    {
        "title": "Being senior and ICT: a study of seniors using ICT in China",
        "authors": "Yuling Sun, Xianghua Ding, Silvia Lindtner, Tun Lu, Ning Gu",
        "abstract": "System design for seniors often focuses on the decline of their biological capabilities and social connectedness. This approach has been challenged as too simplistic to capture what it really means to be senior. This paper presents a qualitative study of 17 seniors in urban China (age ranging from 50s to 70s), who have adopted and incorporated ICT into their daily lives. Findings from this study show that the ways in which seniors attend to ICT are not simply shaped by changes in health or other wellbeing, but also by their life attitudes, value systems, relationships to younger generations as well as historical specifics during their coming of age. This paper contributes by showing that 1) what it means to be senior is shaped from within a whole social ecology of past and current experiences, values and interactions; 2) senior identities are not fixed, but continuously negotiated, articulated and enacted through ICT; 3) social interaction and access of technologies are highly intertwined.",
        "session": "SESSION: Engaging older adults through technology"
    },
    {
        "title": "The lonely raccoon at the ball: designing for intimacy, sociability, and selfhood",
        "authors": "Jeffrey Bardzell, Shaowen Bardzell, Guo Zhang, Tyler Pace",
        "abstract": "Designing for sociable systems requires, among other abilities, a sensitivity to the meanings, structures, and nuances of technology-mediated experiences that are simultaneously felt by users to be intimate and also social. Such a sensitivity is not easily acquired, and design researchers have recommended the use of social theories to guide designers' readings of technology-mediated social experiences. We use philosopher Michel Foucault's theory of identity (and social power, discourse, sexuality, creativity, and style) known as \"the care of the self,\" as a scaffold with which to produce a sensitive interpretation of the intimacy (and expert social creative) practices of adult users of the virtual world Second Life (SL). This reading sheds light on several skilled and creative intimacy practices in SL. It also offers a philosophically grounded hermeneutic strategy for designers interested in analyzing intimate experiences.",
        "session": "SESSION: Computer mediated intimacy and romance"
    },
    {
        "title": "Room for interpretation: the role of self-esteem and CMC in romantic couple conflict",
        "authors": "Lauren E. Scissors, Michael E Roloff, Darren Gergle",
        "abstract": "This work explores the role of communication technologies during romantic couple conflict, and the impact that self-esteem has on behavior, preferences for communication channels, and attitudes about mediated communication during conflict. Results revealed that lower levels of self-esteem and communicating via text messaging (vs. face-to-face) were associated with increased distancing and perceived partner distancing behaviors. Lower levels of self-esteem and using mediated communication were also associated with a greater likelihood of thinking that a conflict had a negative impact on the relationship. Yet, there was no evidence to suggest that individuals with lower levels of self-esteem exhibited more negative behaviors and perceptions in text-based communication than in FtF communication. In addition, lower levels of self-esteem were associated with increased use of and preferences for text-based mediated communication over FtF communication during conflict. Overall, this study suggests that both self-esteem and communication channel impact the nature of romantic couple conflict.",
        "session": "SESSION: Computer mediated intimacy and romance"
    },
    {
        "title": "Exploring affective communication through variable-friction surface haptics",
        "authors": "Joe Mullenbach, Craig Shultz, J. Edward Colgate, Anne Marie Piper",
        "abstract": "This paper explores the use of variable friction surface haptics enabled by the TPad Tablet to support affective communication between pairs of users. We introduce three haptic applications for the TPad Tablet (text messaging, image sharing, and virtual touch) and evaluate the applications with 24 users, including intimate couples and strangers. Participants used haptics to communicate literal texture, denote action within a scene, convey emotional information, highlight content, express and engage in physical playfulness, and to provide one's partner with an experience or sensation. We conclude that users readily associate haptics with emotional expression and that the intimacy of touch in the contexts we study is best suited for communications with close social partners.",
        "session": "SESSION: Computer mediated intimacy and romance"
    },
    {
        "title": "Wrigglo: shape-changing peripheral for interpersonal mobile communication",
        "authors": "Joohee Park, Young-Woo Park, Tek-Jin Nam",
        "abstract": "We introduce Wrigglo, a shape-changing smart phone peripheral that allows pairs of users to share wriggling movements with one another. Attached to a smart phone, Wrigglo captures the sender's motions and activates the receiver's Wrigglo which repeats the motion simultaneously. The result of our in-lab use observation with twelve couples showed that Wrigglo supported emotional and functional roles of body gestures and postures, creating vocabularies related to the motion of specific body parts and, to some extent, reflected the connected user's presence through the device's movement. Through its peripheral anthropomorphization, Wrigglo can deliver new forms of telepresence by embodied posturing and gesturing in mobile communication.",
        "session": "SESSION: Computer mediated intimacy and romance"
    },
    {
        "title": "Recreating living experiences from past memories through virtual worlds for people with dementia",
        "authors": "Panote Siriaraya, Chee Siang Ang",
        "abstract": "This paper describes a study aimed to understand the use of 3D virtual world (VW) technology to support life engagement for people with dementia in long-term care. Three versions of VW prototypes (reminiscence room, virtual tour and gardening) utilising gestured-base interaction were developed iteratively. These prototypes were tested with older residents (80+) with dementia in care homes and their caregivers. Data collection was based on observations of how the residents and care staff interacted collaboratively with the VW. We discussed in depth the use of VWs in stimulating past memories and how this technology could help enhance their sense of self through various means. We also highlighted key approaches in designing VWs to sustain attention, create ludic experiences and facilitate interaction for older people with dementia.",
        "session": "SESSION: Network of care"
    },
    {
        "title": "Addressing the subtleties in dementia care: pre-study & evaluation of a GPS monitoring system",
        "authors": "Lin Wan, Claudia Müller, Volker Wulf, David William Randall",
        "abstract": "In this work we present a user-centered development process for a GPS-based monitoring system to be used in dementia care. Our research covers a full design process including a qualitative-empirical pre-study, the prototyping process and the investigation of long-term appropriation processes of the stable prototypes in three different practice environments. Specifically, we deal with the problem of 'wandering' by persons suffering from late-phase dementia. Although GPS tracking is not a novel technological objective, the usage of those systems in dementia care remains very low. The paper therefore takes a socio-technical stance on development and appropriation of GPS technology in dementia care and assesses the practical and ideological issues surrounding care to understand why. We additionally provide design research in two different settings, familial and institutional care, and report on the design of a GPS-based tracking system reflecting these considerations. What comes to the fore is the need for ICT to reflect complex organizational, ideological and practical issues that form part of a moral universe where sensitivity is crucial.",
        "session": "SESSION: Network of care"
    },
    {
        "title": "Sweet Home: understanding diabetes management via a chinese online community",
        "authors": "Xiaomu Zhou, Si Sun, Jiang Yang",
        "abstract": "China has overtaken India and the U.S. as host to the largest diabetic population in the world. Many problems exist in the Chinese healthcare system and very small number of diabetes patients receives treatment. Our paper reports on a case study through the lens of an online diabetes patient community, Sweet Home. We conducted participant observations, text analysis, and interviews, to understand the health management of patients at Sweet Home. Our findings reveal that patients' understanding of diabetes, their choice of treatments, their routine management, and their interactions with others (in the physical world) and among themselves (in the online world) are influenced by many factors: belief in traditional Chinese versus western medicine, cultural and social norms regarding social eating and drinking, conflicts over self-images, and responses to comments and pressures of coworkers. That is, social context may significantly affect patients' behaviors and each individual patient's actions may also help reshape the social context. We draw out implications for how our society as a whole may respond to these issues, from the perspective of public health, education, and information technology design.",
        "session": "SESSION: Network of care"
    },
    {
        "title": "Investigating the feasibility of extracting tool demonstrations from in-situ video content",
        "authors": "Ben Lafreniere, Tovi Grossman, Justin Matejka, George Fitzmaurice",
        "abstract": "Short video demonstrations are effective resources for helping users to learn tools in feature-rich software. However manually creating demonstrations for the hundreds (or thousands) of individual features in these programs would be impractical. In this paper, we investigate the potential for identifying good tool demonstrations from within screen recordings of users performing real-world tasks. Using an instrumented image-editing application, we collected workflow video content and log data from actual end users. We then developed a heuristic for identifying demonstration clips, and had the quality of a sample set of clips evaluated by both domain experts and end users. This multi-step approach allowed us to characterize the quality of 'naturally occurring' tool demonstrations, and to derive a list of good and bad features of these videos. Finally, we conducted an initial investigation into using machine learning techniques to distinguish between good and bad demonstrations.",
        "session": "TUTORIAL SESSION: Tutorials"
    },
    {
        "title": "Crowdsourcing step-by-step information extraction to enhance existing how-to videos",
        "authors": "Juho Kim, Phu Tran Nguyen, Sarah Weir, Philip J. Guo, Robert C. Miller, Krzysztof Z. Gajos",
        "abstract": "Millions of learners today use how-to videos to master new skills in a variety of domains. But browsing such videos is often tedious and inefficient because video player interfaces are not optimized for the unique step-by-step structure of such videos. This research aims to improve the learning experience of existing how-to videos with step-by-step annotations. We first performed a formative study to verify that annotations are actually useful to learners. We created ToolScape, an interactive video player that displays step descriptions and intermediate result thumbnails in the video timeline. Learners in our study performed better and gained more self-efficacy using ToolScape versus a traditional video player. To add the needed step annotations to existing how-to videos at scale, we introduce a novel crowdsourcing workflow. It extracts step-by-step structure from an existing video, including step times, descriptions, and before and after images. We introduce the Find-Verify-Expand design pattern for temporal and visual annotation, which applies clustering, text processing, and visual analysis algorithms to merge crowd output. The workflow does not rely on domain-specific customization, works on top of existing videos, and recruits untrained crowd workers. We evaluated the workflow with Mechanical Turk, using 75 cooking, makeup, and Photoshop videos on YouTube. Results show that our workflow can extract steps with a quality comparable to that of trained annotators across all three domains with 77% precision and 81% recall.",
        "session": "TUTORIAL SESSION: Tutorials"
    },
    {
        "title": "EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration",
        "authors": "Cheng-Yao Wang, Wei-Chen Chu, Hou-Ren Chen, Chun-Yen Hsu, Mike Y. Chen",
        "abstract": "We present EverTutor, a system that automatically generates interactive tutorials on smartphone from user demonstration. For tutorial authors, it simplifies the tutorial creation. For tutorial users, it provides contextual step-by-step guidance and avoids the frequent context switching between tutorials and users' primary tasks. In order to generate the tutorials automatically, EverTutor records low-level touch events to detect gestures and identify on-screen targets. When a tutorial is browsed, the system uses vision-based techniques to locate the target regions and overlays the corresponding input prompt contextually. It also identifies the correctness of users' interaction to guide the users step by step. We conducted a 6-person user study for creating tutorials and a 12-person user study for browsing tutorials, and we compared EverTutor's interactive tutorials to static and video ones. Study results show that creating tutorials by EverTutor is simpler and faster than producing static and video tutorials. Also, when using the tutorials, the task completion time for interactive tutorials were 3-6 times faster than static and video tutorials regardless of age group. In terms of user preference, 83% of the users chose interactive type as the preferred tutorial type and rated it easiest to follow and easiest to understand.",
        "session": "TUTORIAL SESSION: Tutorials"
    },
    {
        "title": "TaggedComments: promoting and integrating user comments in online application tutorials",
        "authors": "Andrea Bunt, Patrick Dubois, Ben Lafreniere, Michael A. Terry, David T. Cormack",
        "abstract": "User comments posted to popular online tutorials constitute a rich additional source of information for readers, yet current designs for displaying user comments on tutorial webpages do little to support their use. Instead, comments are separated from the tutorial content they reference and tend to be ordered according to post date. We propose and evaluate the TaggedComments system, a new approach to displaying comments that users post to online tutorials. Using tags supplied by commenters, TaggedComments seeks to enhance the role of user comments by 1) improving their visibility, 2) allowing users to personalize their use of the comments according to their particular information needs, and 3) providing direct access to potentially helpful comments from the tutorial content. A laboratory evaluation with 16 participants shows that, in comparison to the standard comment layout, TaggedComments significantly improves users' subjective impressions of comment utility when interacting with Photoshop tutorials.",
        "session": "TUTORIAL SESSION: Tutorials"
    },
    {
        "title": "A smartphone-based sensing platform to model aggressive driving behaviors",
        "authors": "Jin-Hyuk Hong, Ben Margines, Anind K. Dey",
        "abstract": "Driving aggressively increases the risk of accidents. Assessing a person's driving style is a useful way to guide aggressive drivers toward having safer driving behaviors. A number of studies have investigated driving style, but they often rely on the use of self-reports or simulators, which are not suitable for the real-time, continuous, automated assessment and feedback on the road. In order to understand and model aggressive driving style, we construct an in-vehicle sensing platform that uses a smartphone instead of using heavyweight, expensive systems. Utilizing additional cheap sensors, our sensing platform can collect useful information about vehicle movement, maneuvering and steering wheel movement. We use this data and apply machine learning to build a driver model that evaluates drivers' driving styles based on a number of driving-related features. From a naturalistic data collection from 22 drivers for 3 weeks, we analyzed the characteristics of drivers who have an aggressive driving style. Our model classified those drivers with an accuracy of 90.5% (violation-class) and 81% (questionnaire-class). We describe how, in future work, our model can be used to provide real-time feedback to drivers using only their current smartphone.",
        "session": "SESSION: Driving interfaces and evaluations"
    },
    {
        "title": "Classifying driver workload using physiological and driving performance data: two field studies",
        "authors": "Erin T. Solovey, Marin Zec, Enrique Abdon Garcia Perez, Bryan Reimer, Bruce Mehler",
        "abstract": "Understanding the driver's cognitive load is important for evaluating in-vehicle user interfaces. This paper describes experiments to assess machine learning classification algorithms on their ability to automatically identify elevated cognitive workload levels in drivers, leading towards the development of robust tools for automobile user interface evaluation. We look at using both driver performance as well as physiological data. These measures can be collected in real-time and do not interfere with the primary task of driving the vehicle. We report classification accuracies of up to 90% for detecting elevated levels of cognitive load, and show that the inclusion of physiological data leads to higher classification accuracy than vehicle sensor data evaluated alone. Finally, we show results suggesting that models can be built to classify cognitive load across individuals, instead of building individual models for each per-son. By collecting data from drivers in two large field studies on the highway (20 drivers and 99 drivers), this work extends prior work and demonstrates feasibility and potential of such measures for HCI research in vehicles.",
        "session": "SESSION: Driving interfaces and evaluations"
    },
    {
        "title": "Evaluating multimodal driver displays under varying situational urgency",
        "authors": "Ioannis Politis, Stephen A. Brewster, Frank Pollick",
        "abstract": "Previous studies have investigated audio, visual and tactile driver warnings, indicating the importance of communicating the appropriate level of urgency to the drivers. However, these modalities have never been combined exhaustively and tested under conditions of varying situational urgency to assess their effectiveness both in the presence and absence of critical driving events. This paper describes an experiment evaluating all multimodal combinations of such warnings under two contexts of situational urgency: a lead car braking and not braking. The results showed that participants responded quicker to more urgent warnings, especially in the presence of a car braking. They also responded faster to the multimodal as opposed to unimodal signals. Driving behaviour improved in the presence of the warnings and the absence of a car braking. These results highlight the influence of urgency and number of modalities in warning design and indicate the utility of non-visual warnings in driving.",
        "session": "SESSION: Driving interfaces and evaluations"
    },
    {
        "title": "Multi-viewer gesture-based interaction for omni-directional video",
        "authors": "Gustavo Alberto Rovelo Ruiz, Davy Vanacken, Kris Luyten, Francisco Abad, Emilio Camahort",
        "abstract": "Omni-directional video (ODV) is a novel medium that offers viewers a 360º panoramic recording. This type of content will become more common within our living rooms in the near future, seeing that immersive displaying technologies such as 3D television are on the rise. However, little attention has been given to how to interact with ODV content. We present a gesture elicitation study in which we asked users to perform mid-air gestures that they consider to be appropriate for ODV interaction, both for individual as well as collocated settings. We are interested in the gesture variations and adaptations that come forth from individual and collocated usage. To this end, we gathered quantitative and qualitative data by means of observations, motion capture, questionnaires and interviews. This data resulted in a user-defined gesture set for ODV, alongside an in-depth analysis of the variation in gestures we observed during the study.",
        "session": "SESSION: Gesture-based interaction"
    },
    {
        "title": "Making big gestures: effects of gesture size on observability and identification for co-located group awareness",
        "authors": "Adrian Reetz, Carl Gutwin",
        "abstract": "Co-located work environments allow people to maintain awareness by observing others' actions (called consequen-tial communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.",
        "session": "SESSION: Gesture-based interaction"
    },
    {
        "title": "A chair as ubiquitous input device: exploring semaphoric chair gestures for focused and peripheral interaction",
        "authors": "Kathrin Probst, David Lindlbauer, Michael Haller, Bernhard Schwartz, Andreas Schrempf",
        "abstract": "During everyday office work we are used to controlling our computers with keyboard and mouse, while the majority of our body remains unchallenged and the physical workspace around us stays largely unattended. Addressing this untapped potential, we explore the concept of turning a flexible office chair into a ubiquitous input device. To facilitate daily desktop work, we propose the utilization of semaphoric chair gestures that can be assigned to specific application functionalities. The exploration of two usage scenarios in the context of focused and peripheral interaction demonstrates high potential of chair gestures as additional input modality for opportunistic, hands-free interaction.",
        "session": "SESSION: Gesture-based interaction"
    },
    {
        "title": "Exploring the design space of gestural interaction with active tokens through user-defined gestures",
        "authors": "Consuelo Valdes, Diana Eastman, Casey Grote, Shantanu Thatte, Orit Shaer, Ali Mazalek, Brygg Ullmer, Miriam K. Konkel",
        "abstract": "Multi-touch and tangible interfaces provide unique opportunities for enhancing learning and discovery with big data. However, existing interaction techniques have limitations when manipulating large data sets. Our goal is to define novel interaction techniques for multi-touch and tangible interfaces, which support the construction of complex queries for big data. In this paper, we present results from a study which investigates the use of gestural interaction with active tokens for manipulating large data sets. In particular, we studied user expectations of a hybrid tangible and gestural language engaging this space. Our main results include a vocabulary of user-defined gestures for interaction with active tokens, which extends beyond familiar multi-touch gestures; characterization of the design space of gestural interaction with active tokens; and insight into participants' mental models, including common metaphors. We also present implications for the design of multi-touch and tangible interfaces with active tokens.",
        "session": "SESSION: Gesture-based interaction"
    },
    {
        "title": "Pervasive information through constant personal projection: the ambient mobile pervasive display (AMP-D)",
        "authors": "Christian Winkler, Julian Seifert, David Dobbelstein, Enrico Rukzio",
        "abstract": "The vision of pervasive ambient information displays which show relevant information has not yet come true. One of the main reasons is the limited number of available displays in the environment which is a fundamental requirement of the original vision. We introduce the concept of an Ambient Mobile Pervasive Display AMP-D which is a wearable projector system that constantly projects an ambient information display in front of the user. The floor display provides serendipitous access to public and personal information. The display is combined with a projected display on the user's hand, forming a continuous interaction space that is controlled by hand gestures. The paper introduces this novel device concept, discusses its interaction design, and explores its advantages through various implemented application examples. Furthermore, we present the AMP-D prototype which illustrates the involved challenges concerning hardware, sensing, and visualization.",
        "session": "SESSION: Interactive surfaces and pervasive displays"
    },
    {
        "title": "Bigger is not always better: display size, performance, and task load during peephole map navigation",
        "authors": "Roman Rädle, Hans-Christian Jetter, Jens Müller, Harald Reiterer",
        "abstract": "Dynamic peephole navigation is an increasingly popular technique for navigating large information spaces such as maps. Users can view the map through handheld, spatially aware displays that serve as peepholes and navigate the map by moving these displays in physical space. We conducted a controlled experiment of peephole map navigation with 16 participants to better understand the effect of a peephole's size on users' map navigation behavior, navigation performance, and task load. Simulating different peephole sizes from 4' (smartphone) up to 120' (control condition), we confirmed that larger peepholes significantly improve learning speed, navigation speed, and reduce task load; however, this added benefit diminishes with growing sizes. Our data shows that a relatively small, tablet-sized peephole can serve as a 'sweet spot' between peephole size and both user navigation performance and user task load.",
        "session": "SESSION: Interactive surfaces and pervasive displays"
    },
    {
        "title": "Mechanical force redistribution: enabling seamless, large-format, high-accuracy surface interaction",
        "authors": "Alex M. Grau, Charles Hendee, John-Ross Rizzo, Ken Perlin",
        "abstract": "We present Mechanical Force Redistribution (MFR): a method of sensing which creates an anti-aliased image of forces applied to a surface. This technique mechanically focuses the force from a surface onto adjacent discrete forcels (force sensing cells) by way of protrusions (small bumps or pegs), allowing for high-accuracy interpolation between adjacent discrete forcels. MFR works with any force transducing technique or material, including force variable resistive inks, piezoelectric materials and capacitive force plates. MFR sensors can be tiled such that the signal is continuous across contiguous tiles. By minimizing active materials and computational complexity, MFR makes large-format interactive walls, collaborative tabletops and high-resolution floor tiles possible and economically feasible.",
        "session": "SESSION: Interactive surfaces and pervasive displays"
    },
    {
        "title": "Effects of display size and navigation type on a classification task",
        "authors": "Can Liu, Olivier Chapuis, Michel Beaudouin-Lafon, Eric Lecolinet, Wendy E. Mackay",
        "abstract": "The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.",
        "session": "SESSION: Interactive surfaces and pervasive displays"
    },
    {
        "title": "Stewarding a legacy: responsibilities and relationships in the management of post-mortem data",
        "authors": "Jed R. Brubaker, Lynn S. Dombrowski, Anita M. Gilbert, Nafiri Kusumakaulika, Gillian R. Hayes",
        "abstract": "This paper extends research on the giving and inheriting of digital artifacts by examining social network site accounts post-mortem. Given the important role that social network sites play in online bereavement practices, we conducted a series of in-depth qualitative interviews to explore issues around inheritance and post-mortem data management of Facebook accounts. We found that participants focused less on ownership of the data, and instead on the duties and potential conflicts associated with maintaining an account post-mortem. Subsequently, we argue for 'stewardship' as an alternative to inheritance for framing post-mortem data management practices. Analysis of post-mortem data management activities highlights how stewards are accountable and responsible to the deceased and various survivors. However, weighing competing responsibilities is complicated by varied relationships with disparate survivors, as well as the inability to consult with the deceased. Based on our findings, we claim that post-mortem solutions need to account for the needs of stewards in addition to those of the deceased and survivors. We suggest that a model of stewardship better accounts for the interpersonal responsibilities that accompany online data than inheritance alone.",
        "session": "SESSION: Social Media for Relationships"
    },
    {
        "title": "Captioned photographs in psychosocial aged care: relationship building and boundary work",
        "authors": "Jenny Waycott, Hilary Davis, Frank Vetere, Amee Morgans, Alan Gruner, Elizabeth Ozanne, Lars Kulik",
        "abstract": "In this paper we examine the use of a novel social technology to support the provision of formal aged care services to clients who live in their own homes. Social technologies offer enormous potential for enhancing aged care, but research on their use in aged care has largely focused on institutional or informal care settings, rather than formal care in the home. Meanwhile, technologies for aging in place typically focus on monitoring and security, rather than psychosocial support. We conducted a field study in which aged care managers used a photo and message-sharing tool to communicate with clients living in their own homes. Our findings demonstrate that visual and social forms of communication are valuable for supporting psychosocial care-giving, but there are barriers to effectively adopting new communication tools in this setting. Time constraints inhibited care managers' use of the technology, which was also influenced by their efforts to carefully maintain boundaries between their personal and professional lives.",
        "session": "SESSION: Social Media for Relationships"
    },
    {
        "title": "The routines and needs of grandparents and parents for grandparent-grandchild conversations over distance",
        "authors": "Azadeh Forghani, Carman Neustaedter",
        "abstract": "A variety of systems have been designed to support communication between distance-separated grandparents and grandchildren. Yet there are few studies of the actual conversational routines of these groups as well as the social challenges that might arise as a result of technology usage. To address this gap, we conducted an interview and diary study that explores the conversational practices of distance-separated grandparents and young grandchildren (aged 3-10) from the perspective of the grandparents and parents of the children. Our results describe the focus of grandparent-grandchild conversations and show that grandparent-grandchild communication is not without its challenges: grandparents sometimes feel self-conscious, perceive that parents or children will be annoyed if they ask too many questions, and do not want to interfere too much in their grandchildren's lives. The implication is that designs should attempt to support the conversation routines and needs of grandparents and grandchildren while attempting to mitigate the social challenges.",
        "session": "SESSION: Social Media for Relationships"
    },
    {
        "title": "Growing closer on facebook: changes in tie strength through social network site use",
        "authors": "Moira Burke, Robert E. Kraut",
        "abstract": "Scientists debate whether people grow closer to their friends through social networking sites like Facebook, whether those sites displace more meaningful interaction, or whether they simply reflect existing ties. Combining server log analysis and longitudinal surveys of 3,649 Facebook users reporting on relationships with 26,134 friends, we find that communication on the site is associated with changes in reported relationship closeness, over and above effects attributable to their face-to-face, phone, and email contact. Tie strength increases with both one-on-one communication, such as posts, comments, and messages, and through reading friends' broadcasted content, such as status updates and photos. The effect is greater for composed pieces, such as comments, posts, and messages than for 'one-click' actions such as 'likes.' Facebook has a greater impact on non-family relationships and ties who do not frequently communicate via other channels.",
        "session": "SESSION: Social Media for Relationships"
    }
]