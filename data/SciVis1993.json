[
  {
    "abstract": "Volume rendering has been proposed as a useful tool for extracting information from large datasets, where non-visual analysis alone may not be feasible. The scale of these applications implies that data management is an important issue that needs to be addressed. Most volume rendering algorithms, however, process data in raw, uncompressed form. In previous work, we introduced a compressed volume format that may be volume rendered directly with minimal impact on rendering time. In this paper, we extend these ideas to a new volume format that not only reduces storage space and transmission time, but is designed for fast volume rendering as well. The volume dataset is represented as indices into a small codebook of representative blocks. With the data structure, volume shading calculations need only be performed on the codebook and image generation is accelerated by reusing precomputed block projections", 
    "authors": "Ning, P.;Hesselink, Lambertus", 
    "title": "Fast volume rendering of compressed data"
  }, 
  {
    "abstract": "Flow volumes are the volumetric equivalent of stream lines. They provide more information about the vector field being visualized than do stream lines or ribbons. Presented is an efficient method for producing flow volumes, composed of transparently rendered tetrahedra, for use in an interactive system. The problems of rendering, subdivision, sorting, composing artifacts, and user interaction are dealt with. Efficiency comes from rendering only the volume of the smoke, and using hardware texturing and compositing", 
    "authors": "Max, N.;Becker, B.;Crawfis, R.", 
    "title": "Flow volumes for interactive vector field visualization"
  }, 
  {
    "abstract": "In this work we focus on one of the key problems of scientific visualization, the object recognition dilemma. The necessity to pre-interpret application data in order to classify object surface voxels prior to rendering has prevented many visualization methods from becoming practical. We propose the concept of vision by visualization which integrates computer vision methods into the visualization process. Based on this, we present the vision camera, a new tool allowing for interactive object recognition during volume data walkthroughs. This camera model is characterized by a flexible front-plane which, under the control of user-specified parameters and image features elastically matches to object surfaces, while shifted through a data volume. Thus, objects are interactively carved out and can be visualized by standard volume visualization methods. Implementation and application of the model are described. Our results suggest that by the integration of human and machine vision new perspectives for data exploration are opened up", 
    "authors": "Ehricke, H.-H.;Daiber, G.;Strasser, W.", 
    "title": "The vision camera: An interactive tool for volume data exploration and navigation"
  }, 
  {
    "abstract": "Presently, there are very few visualization systems available for time-dependent flow fields. Although existing visualization systems for instantaneous flow fields may be used to view time-dependent flow fields at discrete points in time, the time variable is usually not considered in the visualization technique. We present a simple and effective approach for visualizing time-dependent flow fields using streaklines. A system was developed to demonstrate this approach. The system can process many time frames of flow fields without requiring that all the data be in memory simultaneously, and it also handles flow fields with moving grids. We have used the system to visualize streaklines from several large 3-D time-dependent flow fields with moving grids. The system was able to provide useful insights to the physical phenomena in the flow fields", 
    "authors": "Lane, D.A.", 
    "title": "Visualization of time-dependent flow fields"
  }, 
  {
    "abstract": "A probe for the interactive visualization of flow fields is presented. The probe can be used to visualize many characteristics of the flow in detail for a small region in the data set. The velocity and the local change of velocity (the velocity gradient tensor) are visualized by a set of geometric primitives. To this end, the velocity gradient tensor is transformed to a local coordinate frame, and decomposed into components parallel with and perpendicular to the flow. These components are visualized as geometric objects with an intuitively meaningful interpretation. An implementation is presented which shows that this probe is a useful tool for flow visualization", 
    "authors": "de Leeuw, W.C.;van Wijk, J.J.", 
    "title": "A probe for local flow field visualization"
  }, 
  {
    "abstract": "In this work a new method for visualization of three-dimensional turbulent flow using particle motion animation is presented. The method is based on Reynolds decomposition of a turbulent flow field into a convective and a turbulent motion. At each step of particle path generation a stochastic perturbation is added, resulting in random-walk motions of particles. A physical relation is established between the perturbations and the eddy-diffusivity, which is calculated in a turbulent flow simulation. The flow data used is a mean velocity field, and an eddy-diffusivity field. The erratic particle motions are more than just a visual effect, but represent a real physical phenomenon. An implementation of the method is described, and an example of a turbulent channel flow is given, which clearly shows the random particle motions in their context of general fluid motion patterns", 
    "authors": "Hin, A.J.S.;Post, F.H.", 
    "title": "Visualization of turbulent flow with particles"
  }, 
  {
    "abstract": "Digital filtering is a crucial operation in volume reconstruction and visualization. Lowpass filters are needed for subsampling and minification. Interpolation filters are needed for registration and magnification, and to compensate for geometric distortions introduced by scanners. Interpolation filters are also needed in volume rendering for ray-casting and slicing. In this paper, we describe a method for digital filter design of interpolation filters based on weighted Chebyshev minimization. The accuracy of the resulting filters are compared with some commonly used filters defined by piecewise cubic polynomials. A significant finding of this paper is that although piecewise cubic interpolation has some computational advantages and may yield visually satisfactory results for some data, other data result in artifacts such as blurring. Furthermore, piecewise cubic filters are inferior for operations such as registration. Better results are obtained by the filters derived in this papers at only small increases in computation", 
    "authors": "Carlbom, I.", 
    "title": "Optimal filter design for volume reconstruction and visualization"
  }, 
  {
    "abstract": "In this work we present a method for speeding the process of volume animation. It exploits coherency between consecutive images to shorten the path rays take through the volume. Rays are provided with the information needed to leap over the empty space and commence volume traversal at the vicinity of meaningful data. The algorithm starts by projecting the volume onto a C-buffer (coordinates-buffer) which stores the object-space coordinates of the first non-empty voxel visible from a pixel. Following a change in the viewing parameters, the C-buffer is transformed accordingly. Next, coordinates that possibly became hidden are discarded. The remaining values serve as an estimate of the point where the new rays should start their volume traversal. This method does not require 3-D preprocessing and does not suffer from any image degradation. It can be combined with existing acceleration techniques and can support any ray traversal algorithm and material modeling scheme", 
    "authors": "Yagel, R.;Shi, Z.", 
    "title": "Accelerating volume animation by space-leaping"
  }, 
  {
    "abstract": "Fast techniques for direct volume rendering over curvilinear grids (common to computational fluid dynamics and finite element analysis) are developed. Three new projection methods that use polygon-rendering hardware for speed are presented and compared with each other and with previous methods for tetrahedral grids and rectilinear grids. A simplified algorithm for visibility ordering, based on a combination of breadth-first and depth-first searches, is described. A new multi-pass blending method is described that reduces visual artifacts that are introduced by linear interpolation in hardware where exponential interpolation is needed. Visualization tools that permit rapid data banding and cycling through transfer functions, as well as region restriction, are described", 
    "authors": "Van Gelder, A.;Wilhelms, J.", 
    "title": "Rapid exploration of curvilinear grids using direct volume rendering (Extended Abstract)"
  }, 
  {
    "abstract": "We present a 3-D antialiasing algorithm for voxel-based geometric models. The technique band-limits the continuous object before sampling it at the desired 3-D raster resolution. By precomputing tables of filter values for different types and sizes of geometric objects, the algorithm is very efficient and has a complexity that is linear with the number of voxels generated. The algorithm not only creates voxel models which are free from object space aliasing, but it also incorporates the image space antialiasing information as part of the view independent voxel model. The resulting alias-free voxel models have been used to model synthetic scenes, for discrete ray tracing applications. The discrete ray-traced image is superior in quality to the image generated with a conventional surface-based ray tracer, since silhouettes of objects, shadows, and reflections appear smooth (jaggy-less). In addition, the alias-free models are also suitable for intermixing with sampled datasets, since they can be treated uniformly as one common data representation", 
    "authors": "Wang, S.W.;Kaufman, A.E.", 
    "title": "Volume sampled voxelization of geometric primitives"
  }, 
  {
    "abstract": "In the work we present a new architecture for visualization systems that is based on data base management system (DBMS) technology. By building on the mechanisms present in a next-generation DBMS, rather than merely on the capabilities of a standard file manager, we show that a simpler and more powerful visualization system can be constructed. We retain the popular \"boxes and arrows\" programming notation for constructing visualization programs, but add a \"flight simulator\" model of movement to navigate the output of such programs. In addition, we provide a means to specify a hierarchy of abstracts of data of different types and resolutions, so that a \"zoom\" capability can be supported. The underlying DBMS support for this system, Tioga, is briefly described, as well as the current state of the implementation", 
    "authors": "Stonebraker, M.;Chen, J.;Nathan, N.;Paxson, C.;Su, A.;Wu, J.", 
    "title": "Tioga: A database-oriented visualization tool"
  }, 
  {
    "abstract": "A prototype visualization management system is described which merges the capabilities of a database management system with any number of existing visualization packages such as AVS or IDL. The prototype uses the Postgres database management system to store and access Earth science data through a simple graphical browser. Data located in the database is visualized by automatically invoking a desired visualization package and downloading an appropriate script or program. The central idea underlying the system is that information on how to visualize a data set is stored in the database with the data set itself", 
    "authors": "Kochevar, P.;Ahmed, Z.;Shade, J.;Sharp, C.", 
    "title": "Bridging the gap between visualization and data management: A simple visualization management system"
  }, 
  {
    "abstract": "Visualization has proved an efficient tool in the understanding of large data sets in computational science and engineering. There is growing interest today in the development of problem solving environments which integrate both visualization and the computational process which generates the data. The GRASPARC project has looked at some of the issues involved in creating such an environment. An architecture is proposed in which tools for computation and visualization can be embedded in a framework which assists in the management of the problem solving process. This framework has an integral data management facility which allows an audit trail of the experiments to be recorded. This design therefore allows not only steering but also backtracking and more complicated problem solving strategies. A number of demonstrator case studies have been implemented", 
    "authors": "Brodlie, K.;Poon, A.;Wright, H.;Brankin, L.;Banecki, G.;Gay, A.", 
    "title": "GRASPARC-A problem solving environment integrating computation and visualization"
  }, 
  {
    "abstract": "This paper presents an environment for telecollaborative data exploration. It provides the following capabilities essential to data exploration: (1) users can probe the data, defining regions of interest with arbitrary shapes. (2) The selected data can be transformed and displayed in many different ways. (3) Linked cursors can be established between several windows showing data sets with arbitrary relationships. (4) Data can be displayed on any screen across a computer network, allowing for telecollaboration arrangements with linked cursors around the world. (5) Our system is user-extensible, allowing programmers to change any component of it while keeping the remaining functionality. We demonstrate how the system can be used in several applications, such as biomedical imaging, robotics, and wood classification", 
    "authors": "Klinker, G.J.", 
    "title": "An environment for telecollaborative data exploration"
  }, 
  {
    "abstract": "HyperSlice is a new method for the visualization of scalar functions of many variables. With this method the multi-dimensional function is presented in a simple and easy to understand way in which all dimensions are treated identically. The central concept is the representation of a multi-dimensional function as a matrix of orthogonal two-dimensional slices. These two-dimensional slices lend themselves very well to interaction via direct manipulation, due to a one to one relation between screen space and variable space. Several interaction techniques, for navigation, the location of maxima, and the use of user-defined paths, are presented", 
    "authors": "van Wijk, J.J.;van Liere, R.", 
    "title": "HyperSlice - Visualization of Scalar Functions of Many Variables"
  }, 
  {
    "abstract": "Most of the current dataflow visualization systems are based on coarse-grain dataflow computing models. In this paper we propose a fine-grain dataflow model that takes advantage of data locality properties of many visualization algorithms. A fine-grain module works on small chunks of data one at a time by keeping a dynamically adjusted moving window on the input data stream. It is more memory efficient and has the potential of handling very large data sets without taking up all the memory resources. Two popular visualization algorithms, an iso-surface extraction algorithm and a volume rendering algorithm, are implemented using the fine-grain model. The performance measurements showed faster speed, reduced memory usage, and improved CPU utilization over a typical coarse-grain system", 
    "authors": "Song, D.;Golin, E.", 
    "title": "Fine-grain visualization algorithms in dataflow environments"
  }, 
  {
    "abstract": "Modular application builders (MABs), such as AVS and Iris Explorer are increasingly being used in the visualization community. Such systems can already place compute intensive modules on supercomputers in order to utilize their power. This paper details two major projects at EPCC which attempted to fully integrate the MAB concept with a distributed memory MIMD (DM-MIMD) environment. The work presented was driven by two goals, efficient use of the resource and case of use by programmer and end user. We present a model of MABs and describe the major problems faced, giving solutions to them through two case studies", 
    "authors": "Thornborrow, C.;Wilson, A.J.S.;Faigle, C.", 
    "title": "Developing modular application builders to exploit MIMD parallel"
  }, 
  {
    "abstract": "The device unified interface is a generalized and easily expandable protocol for the communication between applications and input devices. The key idea is to unify various device data into the parameters of a so-called \"virtual input device.\" The device information-base, which includes device dependent information, is also incorporated into the virtual input device. Using the device unified interface, system builders are able to design their applications independent of the input devices as well as utilize the capabilities of several devices in the same application", 
    "authors": "Taosong He;Kaufman, A.E.", 
    "title": "Virtual input devices for 3D systems"
  }, 
  {
    "abstract": "This paper introduces a novel representation, called the InfoCrystal, that can be used as a visualization tool as well as a visual query language to help users search for information. The InfoCrystal visualizes all the possible relationships among N concepts. Users can assign relevance weights to the concepts and use thresholding to select relationships of interest. The InfoCrystal allows users to specify Boolean as well as vector-space queries graphically. Arbitrarily complex queries can be created by using the InfoCrystals as building blocks and organizing them in a hierarchical structure. The InfoCrystal enables users to explore and filter information in a flexible, dynamic and interactive way", 
    "authors": "Spoerri, A.", 
    "title": "InfoCrystal: A visual tool for information retrieval"
  }, 
  {
    "abstract": "In this paper, we describe a database query system that provides visual relevance feedback in querying large databases. The goal of our system is to support the query specification process by using each pixel of the display to represent one data item of the database. By arranging and coloring the pixels according to their relevance for the query, the user gets a visual impression of the resulting data set. Using sliders for each condition of the query, the user may change the query dynamically and receives immediate feedback by the visual representation of the resulting data set. By using multiple windows for different parts of a complex query, the user gets visual feedback for each part of the query and, therefore, will easier understand the overall result. The system may be used to query any database that contains tens of thousands to millions of data items, but it is especially helpful to explore large data sets with an unknown distribution of values and to find the interesting hot spots in huge amounts of data. The direct feedback allows to visually display the influence of incremental query refinements and, therefore, allows a better, easier and faster query specification", 
    "authors": "Keim, D.A.;Kriegel, H.-P.;Seidl, T.", 
    "title": "Visual feedback in querying large databases"
  }, 
  {
    "abstract": "The issue of monitoring the execution of asynchronous, distributed algorithms on loosely-coupled parallel processor systems, is important for the purposes of (i) detecting inconsistencies and flaws in the algorithm, (ii) obtaining important performance parameters for the algorithm, and (iii) developing a conceptual understanding of the algorithm's behavior, for given input stimulus, through visualization. For a particular class of asynchronous distributed algorithms that may be characterized by independent and concurrent entities that execute asynchronously on multiple processors and interact with one another through explicit messages, the following reasoning applies. Information about the flow of messages and the activity of the processors may contribute significantly towards the conceptual understanding of the algorithm's behavior and the functional correctness of the implementation. The computation and subsequent display of important parameters, based upon the execution of the algorithm, is an important objective of DIVIDE. For instance, the mean and standard deviation values for the propagation delay of ATM cells between any two given Broadband-ISDN (BISDN) nodes in a simulation of BISDN network under stochastic input stimulus, as a function of time, are important clues to the degree of congestion in the Broadband-ISDN network. Although the execution of the algorithm typically generates high resolution data, often, a coarse-level visual representation of the data may be useful in facilitating the conceptual understanding of the behavior of the algorithm. DIVIDE permits a user to specify a resolution less than that of the data from the execution of the algorithm, which is then utilized to coalesce the data appropriately. Given that this process requires significant computational power, for efficiency, DIVIDE distributes the overall task of visual display into a number of user specified workstations that are configured as a loosely-coupled parallel processor. DIVIDE has been implemented on a heterogeneous network of SUN sparc 1 + , sparc 2, and 3/60 workstations and performance measurements indicate significant improvement over that of a uniprocessor-based visual display", 
    "authors": "Morrow, T.M.;Ghosh, S.", 
    "title": "DIVIDE: Distributed visual display of the execution of asynchronous, distributed algorithms on loosely-coupled parallel processors"
  }, 
  {
    "abstract": "The user of a parallel computer system would like to know the performance of a program in terms of how optimally it uses the system resources. This task is increasingly performed by program performance visualization. The limitations of conventional performance data analysis techniques necessitate better visual analysis methods that are scalable with the problem and system sizes and extensible. They should represent some physical and logical structure of the parallel system and program. The analysis techniques presented here have been motivated by the use of signal and (two- and three-dimensional) image processing techniques being applied in some areas of scientific visualization. Results of applying selected techniques are shown. These techniques and tools have advantages and disadvantages when applied in this area", 
    "authors": "Waheed, A.;Rover, D.T.", 
    "title": "Performance visualization of parallel programs"
  }, 
  {
    "abstract": "The set of possible orientations of a rigid three-dimensional object is a topological space with three degrees of freedom. This paper investigates the suitability of various techniques of visualizing this space. With a good technique the natural distance between orientations will be represented fairly accurately, and distortion to the \"shape\" of a collection of orientations induced by the change of reference orientation will be minor. The traditional Euler-angle parameterization fails on both counts. Less well-known techniques exploit the fact that there is a rotation that takes the reference orientation to a given one. The given orientation is represented as a point along the axis of this rotation. The distance of this point from the origin is determined by some scaling function of the magnitude of that rotation. Free natural scaling functions are studied. None is perfect, but several are satisfactory", 
    "authors": "Alpern, B.;Carter, L.;Grayson, M.;Pelkie, C.", 
    "title": "Orientation maps: Techniques for visualizing rotations (A  Consumer\u2019s Guide)"
  }, 
  {
    "abstract": "An algorithm is presented which describes an application independent method for reducing the number of polygonal primitives required to faithfully represent an object. Reducing polygon count without a corresponding reduction in object detail is important for: achieving interactive frame rates in scientific visualization, reducing mass storage requirements, and facilitating the transmission of large, multi-timestep geometric data sets. This paper shows how coplanar and nearly coplanar polygons can be merged into larger complex polygons and re-triangulated into fewer simple polygons than originally required. The notable contributions of this paper are: (1) a method for quickly grouping polygons into nearly coplanar sets, (2) a fast approach for merging coplanar polygon sets and, (3) a simple, robust triangulation method for polygons created by 1 and 2. The central idea of the algorithm is the notion of treating polygonal data as a collection of segments and removing redundant segments to quickly form polygon hulls which represent the merged coplanar sets", 
    "authors": "Hinker, P.;Hansen, C.", 
    "title": "Geometric optimization"
  }, 
  {
    "abstract": "Making accurate computer graphics representations of surfaces and volumes (2-manifolds and 3-manifolds) embedded in four-dimensional space typically involves complex and time-consuming computations. In order to make simulated worlds that help develop human intuition about the fourth dimensions, we need techniques that permit real-time, interactive manipulation of the most sophisticated depictions available. We propose the following new methods that bring us significantly closer to this goal: an approach to high-speed 4D illuminated surface rendering incorporating 4D shading and occlusion coding; a procedure for rapidly generating 2D screen images of tessellated 3-manifolds illuminated by 4D light. These methods are orders of magnitude faster than previous approaches, enabling the real-time manipulation of high-resolution 4D images on commercial graphics hardware", 
    "authors": "Hanson, A.J.;Cross, R.A.", 
    "title": "Interactive visualization methods for four dimensions"
  }, 
  {
    "abstract": "This paper is aimed at the exploratory visualization of networks where there is a strength or weight associated with each link, and makes use of any hierarchy present on the nodes to aid the investigation of large networks. It describes a method of placing nodes on the plane that gives meaning to their relative positions. The paper discusses how linking and interaction principles aid the user in the exploration. Two examples are given; one of electronic mail communication over eight months within a department, another concerned with changes to a large section of a computer program", 
    "authors": "Eick, S.G.;Wills, G.J.", 
    "title": "Navigating large networks with hierarchies"
  }, 
  {
    "abstract": "New display technologies have begun to provide more innovative and potentially powerful methods to present information to a viewer. However, many of these techniques struggle to deliver accurate full color. In this paper, we address this difficulty by employing the dichromatic theory of color reflection, which implies that many objects can be rendered accurately using only two primaries. Complex display systems with two primaries can be produced with significantly less work than is required for the traditional three primaries. We discuss methods for selecting objects that can be rendered accurately on two-color displays, and we present our experiments with a two-color display using monochromatic primaries", 
    "authors": "Peercy, M.S.;Hesselink, Lambertus", 
    "title": "Dichromatic color representations for complex display systems"
  }, 
  {
    "abstract": "Recently, researchers have started using texture for data visualization. The rationale behind this is to exploit the sensitivity of the human visual system to texture in order to overcome the limitations inherent in the display of multidimensional data. A fundamental issue that must be addressed is what textural features are important in texture perception, and how they are used. We designed an experiment to help identify the relevant higher order features of texture perceived by humans. We used twenty subjects, who were asked to rate 56 pictures from Brodatz's album on 12 nine-point Likert scales. We applied the techniques of hierarchical cluster analysis, non-parametric multidimensional scaling (MDS), classification and regression tree analysis (CART), discriminant analysis, and principal component analysis to data gathered from the subjects. Based on these techniques, we identified three orthogonal dimensions for texture to be repetitive vs. non-repetitive; high-contrast and non-directional vs. low-contrast and directional; granular, coarse and low-complexity vs. non-granular, fine and high-complexity", 
    "authors": "Rao, A.R.;Lohse, G.L.", 
    "title": "Towards a texture naming system: Identifying relevant dimensions of texture"
  }, 
  {
    "abstract": "Designers, implementers, and marketers of data analysis tools typically have different perspectives than end users. Consequently, data analysts often find themselves using tools focused on graphics and programming concepts rather than concepts which reflect their own domain and the context of their work. Some user studies focus on usability tests late in development; others observe work activity, but fail to show how to apply that knowledge in design. This paper describes a methodology for applying observations of data analysis work activity in prototype tool design. The approach can be used both in designing improved data analysis tools, and customizing visualization environments to specific applications. We present an example of user-centered design for a prototype tool to cull large data sets. We revisit the typical graphical approach of animating a large data set from the point of view of an analyst who is culling data. Field evaluations using the prototype tool not only revealed valuable usability information, but initiated in-depth discussions about user's work, tools, technology, and requirements", 
    "authors": "Springmeyer, R.R.", 
    "title": "Applying observations of work activity in designing prototype data analysis tools"
  }, 
  {
    "abstract": "In Rogowitz and Treinish (1993), we introduced an architecture for incorporating perceptual rules into the visualization process. In this architecture, higher-level descriptors of the data, metadata, flow to perceptual rules, which constrain visualization operations. In this paper, we develop a deeper analysis of the rules, the prerequisite metadata, and the system for enabling their operation", 
    "authors": "Rogowitz, B.;Treinish, L.A.", 
    "title": "An architecture for rule-based visualization"
  }, 
  {
    "abstract": "Streamlines and stream surfaces are well known techniques for the visualization of fluid flow. For steady velocity fields, a streamline is the trace of a particle, and a stream surface is the trace of a curve. Here a new method is presented for the construction of stream surfaces. The central concept is the representation of a stream surface as an implicit surface f (x) = C. After the initial calculation of f a family of stream surfaces can be generated efficiently by varying C. The shapes of the originating curves are defined by the value of f at the boundary. Two techniques are presented for the calculation of f: one based on solving the convection equation, the other on backward tracing of the trajectories of grid points. The flow around objects is discussed separately. With this method irregular topologies of the originating curves and of the stream surfaces can be handled easily. Further, it can also be used for other visualization techniques, such as time surfaces and stream volumes. Finally, an effective method for the automatic placement of originating curves is presented", 
    "authors": "van Wijk, J.J.", 
    "title": "Implicit stream surfaces"
  }, 
  {
    "abstract": "The paper describes a highly interactive method for computer visualization of simultaneous three-dimensional vector and scalar flow fields in convection-diffusion systems. This method allows a computational fluid dynamics user to visualize the basic physical process of dispersion and mixing rather than just the vector and scalar values computed by the simulation. It is based on transforming the vector field from a traditionally Eulerian reference frame into a Lagrangian reference frame. Fluid elements are traced through the vector field for the mean path as well as the statistical dispersion of the fluid elements about the mean position by using added scalar information about the root mean square value of the vector field and its Lagrangian time scale. In this way, clouds of fluid elements are traced not just mean paths. We have used this method to visualize the simulation of an industrial incinerator to help identify mechanisms for poor mixing", 
    "authors": "Ma, K.-L.;Smith, P.J.", 
    "title": "Cloud tracing in convection-diffusion systems"
  }, 
  {
    "abstract": "Volume visualization is becoming an important tool for understanding large 3D data sets. A popular technique for volume rendering is known as splatting. With new hardware architectures offering substantial improvements in the performance of rendering texture mapped objects, we present textured splats. An ideal reconstruction function for 3D signals is developed which can be used as a texture map for a splat. Extensions to the basic splatting technique are then developed to additionally represent vector fields", 
    "authors": "Crawfis, R.A.;Max, N.", 
    "title": "Texture splats for 3D scalar and vector field visualization"
  }, 
  {
    "abstract": "Texture mapping is normally used to convey geometric detail without adding geometric complexity. This paper introduces Boolean textures, a texture mapping technique that uses implicit functions to generate texture maps and texture coordinates. These Boolean textures perform clipping during a renderer's scan conversion step. Any implicit function is a candidate Boolean texture clipper. The paper describes how to use quadrics as clippers. Applications from engineering and medicine illustrate the effectiveness of texture as a clipping tool", 
    "authors": "Lorensen, W.F.", 
    "title": "Geometric clipping using Boolean textures"
  }, 
  {
    "abstract": "The process of visualizing a scientific data set requires an extensive knowledge of the domain in which the data set is created. Because an in-depth knowledge of all scientific domains is not available to the creator of visualization software, a flexible and extensible visualization system is essential in providing a productive tool to the scientist. This paper presents a shading language, based on the RenderMan shading language, that extends the shading model used to render volume data sets. Data shaders, written in this shading language, give the users of a volume rendering system a means of specifying how a volume data set is to be rendered. This flexibility is useful both as a visualization tool in the scientific community and as a research tool in the visualization community", 
    "authors": "Corrie, B.;Mackerras, P.", 
    "title": "Data shaders"
  }, 
  {
    "abstract": "We propose a new framework for doing scientific visualization. The basis for this framework is a combination of particle systems and behavioral animation. Here, particles are not only affected by the field that they are in, but can also exhibit different programmed behaviors. An intuitive delivery system, based on virtual cans of spray paint, is also described to introduce the smart particles into the data set. Hence the name spray rendering. Using this metaphor, different types of spray paint are used to highlight different features in the data set. Spray rendering offers several advantages over existing methods: (1) it generalizes the current techniques of surface, volume and flow visualization under one coherent framework; (2) it works with regular and irregular grids as well as sparse and dense data sets; (3) it allows selective progressive refinement; (4) it is modular, extensible and provides scientists with the flexibility for exploring relationships in their data sets in natural and artistic ways", 
    "authors": "Pang, A.;Smith, K.", 
    "title": "Spray rendering: Visualization using smart particles"
  }, 
  {
    "abstract": "Shading is an effective exploratory visualization tool widely used in scientific visualization. Interactive, or close to interactive, shading of images offers significant benefit, but is generally too computationally expensive for graphics workstations. A novel method for providing interactive diffuse and specular shading capability on low-cost graphics workstations is described. Application to digital elevation models, iso-surfaces in volumetric images, and color-coded aspect maps are illustrated and an analysis of artifacts, and of ways of minimizing artifacts, is given", 
    "authors": "Fletcher, P.A.;Robertson, P.K.", 
    "title": "Interactive shading for surface and volume visualization on graphics workstations"
  }, 
  {
    "abstract": "An algorithm for rapid computation of Richards's smooth molecular surface is described. The entire surface is computed analytically, triangulated, and displayed at interactive rates. The faster speeds for our program have been achieved by algorithmic improvements, paralleling the computations, and by taking advantage of the special geometrical properties of such surfaces. Our algorithm is easily parallelable and it has a time complexity of O (k log k) over n processors, where n is the number of atoms of the molecule and k is the average number of neighbors per atom", 
    "authors": "Varshney, A.;Brooks, F.P., Jr.", 
    "title": "Fast analytical computation of Richard's smooth molecular surface"
  }, 
  {
    "abstract": "Human beings find it difficult to analyze local and global oligonucleotide patterns in the linear primary sequences of a genome. In this paper, we present a family of iterated function systems (IFS) that can be used to generate a set of visual models of a DNA sequence. A new visualization function, the W-curve, that is derived from this IFS family is introduced. Using W-curves, a user can readily compare subsequences within a long genomic sequence - or between genomic sequences - and can visually evaluate the effect of local variations (mutations) upon the global genomic information content", 
    "authors": "Wu, D.;Roberge, J.;Cork, D.J.;Nguyen, B.G.;Grace, T.", 
    "title": "Computer visualization of long genomic sequences"
  }, 
  {
    "abstract": "3-dimensional data visualization from any input source involves the study and understanding of several steps. These steps include data acquisition, signal processing, image processing and image generation. Using a forward-looking high frequency sonar system (which focuses sound much like the eye focuses light), standard and non-standard data processing algorithms, and industry \"standard\" visualization algorithms, this project produced accurate 3-dimensional representations of several underwater objects", 
    "authors": "Bladek, A.J.", 
    "title": "Visualization of acoustic lens data"
  }, 
  {
    "abstract": "MRIVIEW is a software system that uses image processing and visualization to provide neuroscience researchers with an integrated environment for combining functional and anatomical information. Key features of the software include semi-automated segmentation of volumetric head data and an interactive coordinate reconciliation method which utilizes surface visualization. The current system is a precursor to a computational brain atlas. We describe features this atlas will incorporate, including methods under development for visualizing brain functional data obtained from several different research modalities", 
    "authors": "Ranken, D.;George, J.", 
    "title": "MRIVIEW: An interactive computational tool for investigation of brain structure and function"
  }, 
  {
    "abstract": "We present the visualization and modeling techniques used in a case study to build feature-based computational models from geophysical data. Visualization was used to inspect the quality of the interpretation of the geophysical data. We describe the geophysical data graphical representation used to support rapid rendering and to enhance the perception differences between the interpretation of the data and the data itself. In addition, we present the modeling techniques used to convert the geophysical data into a feature-based computational model suitable for use by a numerical simulation package", 
    "authors": "Celniker, G.;Chakravarty, I.;Moorman, J.", 
    "title": "Visualization and modelling of geophysical data"
  }, 
  {
    "abstract": "We discuss a system which provides a single, unified model of oil and gas reservoirs that is used across a range of disciplines from geologists to reservoir engineers. It has to store, manipulate and display reservoir phenomena which are observed over several orders of magnitude from 1 mm to 10 km. We propose that the current capabilities of visualization, over this range of scales, can remove perception barriers that have existed between disciplines and provide clear insights into the problems of modeling reservoirs from geological and engineering perspectives", 
    "authors": "Tyson, S.;Williams, B.", 
    "title": "Visualization of oil reservoirs over a large range of scales as a catalyst for multi-disciplinary integration"
  }, 
  {
    "abstract": "Some techniques developed recently at DLR's Institute of Theoretical Fluid Mechanics in order to cope with the demands arising from today's work in aerodynamics are illustrated. Such new demands arise from new aerodynamical problems like the hypersonic flow field around re-entry vehicles, the study of unsteady phenomena which comes more and more within reach due to the increased availability of computing power and the tendency towards enhanced international cooperation especially within Europe which calls for the use of co-operative systems on wide area networks", 
    "authors": "Pagendarm, H.-G.", 
    "title": "Unsteady phenomena, hypersonic flows and co-operative flow visualization in aerospace research"
  }, 
  {
    "abstract": "Progress towards interactive steering of the time-accurate, unsteady finite-element simulation program DYNA3D is reported. Rudimentary steering has been demonstrated in a distributed computational environment encompassing a supercomputer, multiple graphics workstations, and a single frame animation recorder. The coroutine facility of AVS (application visualization system from AVS Inc.) and software produced in-house has been coordinated to prove the concept. This work also applies to other large batch-oriented FORTRAN simulations (\"dusty decks\") presently in production use", 
    "authors": "Kerlick, G.D.;Kirby, E.", 
    "title": "Towards interactive steering, visualization and animation of unsteady finite element simulations"
  }, 
  {
    "abstract": "Some years ago it was established that the muon catalyzed fusion phenomenon could be used for the production of energy. This fact has been causing a rebirth of interest in the universal methods of solving the quantum Coulomb three-body problem. The adiabatic hyperspherical (AHS) approach considered in this joint project has definite advantages in comparison with other methods. The case study proposed focuses on the study of the structure and behavior of the wave function of bound states of a quantum three-body system as well as of the basis functions of the AHS approach. Adapted scientific visualization tools such as surface rendering, volume ray tracing and texturing will be used. Visualization allows to discover interesting features in the behavior of the basis functions and to analyze the convergence of the AHS-expansion for the wave functions", 
    "authors": "Abramov, D.I.;Gusev, V.V.;Klimenko, S.V.;Ponomarev, L.I.;Krueger, W.;Renz, W.", 
    "title": "The quantum Coulomb three-body problem - Visualization of simulation results and numerical methods"
  }, 
  {
    "abstract": "The package described in this paper has been designed for analyzing the data collected in the LEP experiment ALEPH. Its main graphical feature is a deep interplay between the description of the objects manipulated and their relationships, and their graphical representation. The easy access to information through navigation between objects and its display makes possible a thorough study of the events produced by the detector. This has proved to be very powerful in numerous occasions for analyzing data and testing programs. The package provides as well statistical analysis tools and a graphic editor. It is based on the PHIGS graphics standard. It will develop towards a more elaborate usage of the data structure in particular in the geometrical representations and towards object oriented languages to overcome some heaviness linked to the use of Fortran", 
    "authors": "Videau, H.;Mora de Freitas, P.", 
    "title": "Fanal: A relational analysis and visualization package for high energy physics"
  }, 
  {
    "abstract": "Visualization of events in high energy physics is an important tool to check hard- and software and to generate pictures for presentation purposes. The radial pattern of all events suggests the use of predefined projections, especially p/Z and Y/X. The representation can be improved by a \"fish-eye\" transformation and by angular projections, which produce straight track patterns and allow extensive magnifications. Three dimensional data of radial structure are best displayed in the 3D V-Plot, which has optimal track separation and presents all relevant information in a clear way", 
    "authors": "Drevermann, H.;Kuhn, D.;Nilsson, B.S.", 
    "title": "Non conventional methods for the visualization of events from high energy physics"
  }, 
  {
    "abstract": "Direct analysis of spacecraft observations of stratospheric ozone yields information about the morphology of annual austral depletion. Visual correlation of ozone with other atmospheric data illustrates the diurnal dynamics of the polar vortex and contributions from the upper troposphere, including the formation and breakup of the depletion region each spring. These data require care in their presentation to minimize the introduction of visualization artifacts that are erroneously interpreted as data features. Non-geographically registered data of differing mesh structures can be visually correlated via cartographic warping of underlying geometries without interpolation. Since this approach is independent of realization technique, it provides a framework for experimenting with different visualization strategies. This methodology preserves the fidelity of the original data sets in a coordinate system suitable for three-dimensional, dynamic examination of upper atmospheric phenomena", 
    "authors": "Treinish, L.A.", 
    "title": "Visualization of stratospheric ozone depletion and the polar vortex"
  }, 
  {
    "abstract": "A supercomputing-visualization facility for science and engineering applications was used for processing and visualizing supercomputer-generated data. This facility includes a vector-processing supercomputer, a graphics workstation, a general purpose workstation, a high-resolution color printer, a scanner, a film recorder, a video tape recorder, and a video laser disc recorder. The facility is using a network system to connect computers, workstations, and graphical input/output devices. The supercomputer generates time-dependent multivariate data using a global climate simulation model. Visualization software systems are used for visualizing these model-produced data. Visualization techniques including: iso-contouring, iso-surface generation, vectors and streamlines generation are used", 
    "authors": "Chen, P.C.", 
    "title": "A climate simulation case study"
  }, 
  {
    "abstract": "The features of greatest interest in ocean modeling in the Gulf of Mexico and along the Gulf Stream are the fronts and eddies. Resolving, modeling, and tracking these eddies over time is of great importance for climatological studies and economic advancement. In this paper we present a novel technique for automatically locating, contouring, and tracking oceanic features such as eddies and fronts. The models and resultant visualizations exhibit excellent correlation with observed data", 
    "authors": "Moorehead, R.J., II;Zhifan Zhu", 
    "title": "Feature extraction for oceanographic data using a 3D edge operator"
  }, 
  {
    "abstract": "This work briefly describes our approach to visualize results of transient flow simulations in the application areas of groundwater flow and pollutant transport as well as compressible fluid flow in engine parts. The simulations use finite element data structures and can have geometries which change over time. We designed a client-server model to handle the huge amount of data that can be obtained either directly from the simulation process or from files on disk. As standard visualization packages are not able to cope with transient unstructured data, we implemented streamlines, stream surfaces and particle systems as our main visualization methods. Our experiences and results with these techniques are discussed in this paper", 
    "authors": "Mayer, H.F.;Tabatabai, B.", 
    "title": "Visualizing results of transient flow simulations"
  }, 
  {
    "abstract": "Three dimensional computer models of the anatomy generated from volume acquisitions of computed tomography and magnetic resonance imaging are useful adjuncts to 2D images. This paper describes a system that merges the computer generated 3D models with live video to enhance the surgeon's understanding of the anatomy beneath the surface. The system can be used as a planning aid before the operation and provide additional information during an operation. The application of the system to a brain operation is described", 
    "authors": "Lorensen, William;Cline, H.;Nafis, C.;Kikinis, R.;Altobelli, D.;Gleason, L.", 
    "title": "Enhancing reality in the operating room"
  }, 
  {
    "abstract": "We show how to create 3D models of maternal pelvis and fetal head from magnetic resonance images (MRI). The models are used to simulate the progress of delivery in order to give a prognosis of successful labor", 
    "authors": "Boissonnat, J.-D.;Geiger, B.", 
    "title": "3D simulation of delivery"
  }, 
  {
    "abstract": "In the field of computer applications to archaeology, data visualization is one of the most recent and promising activity. The visual reconstruction obtained from partially or totally ruined data is a problem that archaeologists often face with during their work. The case we present here is the simulated reconstruction of a great Egyptian tomb of the VII century B.C. excavated in the rocky cliff of the desert. The visualization method is fundamental for testing the hypotheses made and as a strategic solution in the concrete reconstruction. The hundreds of magnificent decorated blocks saved by museums will never be positioned again on its walls. Moreover, in front of the stress and pollution caused to ancient monuments by a massive tourism, the ever-growing improving of visualization and animation techniques, like the ones presented in this paper, makes of considerable interest the modeling and the exploration inside the virtual monuments through realistic tours", 
    "authors": "Palamidese, P.;Betro, M.;Muccioli, G.", 
    "title": "The virtual restoration of the Visir tomb"
  }
]